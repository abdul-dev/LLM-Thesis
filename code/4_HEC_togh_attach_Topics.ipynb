{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTzc8fGpvDi9",
        "outputId": "fa8992d9-484d-49ad-cb52-033b17fdbee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.4.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.12)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.1.8)\n",
            "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (1.26.4)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.1.0)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from together) (17.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.10.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
            "Downloading together-1.4.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 kB\u001b[0m \u001b[31m463.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: eval-type-backport, together\n",
            "Successfully installed eval-type-backport-0.2.2 together-1.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install together\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re  # For cleaning topic names\n",
        "from together import Together\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Initialize Together API client\n",
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')\n",
        "client = Together(api_key=TOGETHER_API_KEY)\n",
        "\n",
        "# Load input questions from JSON file\n",
        "input_file = \"/content/cleaned_questions-Removed-Pres.json\"\n",
        "output_file = \"updated_questions.json\"\n",
        "\n",
        "with open(input_file, \"r\") as file:\n",
        "    new_questions = json.load(file)\n",
        "\n",
        "trainSize = 0.4\n",
        "total_size = len(new_questions)\n",
        "selected_data = new_questions[:int(trainSize * total_size)]\n",
        "\n",
        "print(f\"Total size of the dataset: {total_size}\")\n",
        "print(f\"Train on size of the dataset {float(trainSize*100)}% : size:{len(selected_data)}\")\n",
        "\n",
        "new_questions = selected_data\n",
        "\n",
        "\n",
        "print(new_questions[1])\n",
        "# Process each question separately\n",
        "updated_questions = []\n",
        "\n",
        "for new_q in new_questions:\n",
        "    prompt = f\"\"\"\n",
        "Analyze the given question and assign:\n",
        "1. **One most suitable Topic** (Use only a **single word or short phrase**. Avoid sentences.)\n",
        "2. **One most suitable CLO (Course Learning Outcome)**\n",
        "\n",
        "Format your response as follows:\n",
        "Topic: [Your assigned topic]\n",
        "CLO: [Your assigned CLO]\n",
        "\n",
        "---\n",
        "\n",
        "**Question:** {new_q[\"Question\"]}\n",
        "**Type:** {new_q[\"Type\"]}\n",
        "**Difficulty:** {new_q[\"Difficulty\"]}\n",
        "\"\"\".strip()\n",
        "\n",
        "    # Making the API request\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"meta-llama/Llama-3.2-3B-Instruct-Turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=100,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        top_k=50,\n",
        "        repetition_penalty=1.0\n",
        "    )\n",
        "\n",
        "    # Extract and parse the response\n",
        "    generated_text = response.choices[0].message.content.strip()\n",
        "    lines = generated_text.split(\"\\n\")\n",
        "\n",
        "    # Default values\n",
        "    topic, clo = \"Unknown\", \"Unknown\"\n",
        "\n",
        "    for line in lines:\n",
        "        if line.lower().startswith(\"topic:\"):\n",
        "            topic = line.split(\":\", 1)[1].strip()\n",
        "            # Ensure topic is concise and not a full sentence\n",
        "            topic = re.sub(r\"[^\\w\\s-]\", \"\", topic)  # Remove unwanted characters\n",
        "            topic = \" \".join(topic.split()[:3])  # Keep max 3 words\n",
        "        elif line.lower().startswith(\"clo:\"):\n",
        "            clo = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "    # Update the question dictionary\n",
        "    updated_q = new_q.copy()\n",
        "    updated_q[\"Topic\"] = topic\n",
        "    updated_q[\"CLO\"] = clo\n",
        "\n",
        "    updated_questions.append(updated_q)\n",
        "\n",
        "# Save the updated dataset to JSON file\n",
        "with open(output_file, \"w\") as file:\n",
        "    json.dump(updated_questions, file, indent=4)\n",
        "\n",
        "print(f\"Updated questions saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unbsPMCYvP-1",
        "outputId": "64350b46-9ed7-49f1-f0dc-998ce7c207d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the dataset: 1042\n",
            "Train on size of the dataset 40.0% : size:416\n",
            "{'Question': 'Write a Prolog program to solve a constraint satisfaction problem using the resolution rule. The problem is defined as follows:\\nImplement a Prolog program to solve a constraint satisfaction problem involving three variables (A, B, and C) with the following constraints:1. A is greater than B.\\n2. B is less than C.\\n3. A is not equal to C.Note: Each task builds upon the previous one, increasing in difficulty, and requires coding-based implementation with structured sub-parts. The question and cover conceptual understanding, critical thinking, and problem-solving.', 'Type': 'code', 'Difficulty': 'medium', 'CLO': 'Understand key components in the field of artificial intelligence', 'Topic': 'Define and solve constraint satisfaction problems with practical examples.', 'chunkNumber': 88, 'text': 'lifts a proof step from ground clauses up to general LIFTING LEMMA first-order clauses. In order to prove his basic lifting lemma, Robinson had to invent unifi- cation and derive all of the properties of most general unifiers. Rather than repeat the proof here, we simply illustrate the lemma: C1 = P(x, F(x, A)) Q(x, A) R(x, B) C2 = N(G(y), z) P(H(y), z) C 1 = P(H(B), F(H(B), A)) Q(H(B), A) R(H(B), B) C 2 = N(G(B), F(H(B), A)) P(H(B), F(H(B), A)) C = N(G(B), F(H(B), A)) Q(H(B), A) R(H(B), B) C = N(G(y), F(H(y), A)) Q(H(y), A) R(H(y), B) . We see that indeed C is a ground instance of C. In general, for C 1 and C 2 to have any resolvents, they must be constructed by first applying to C1 and C2 the most general unifier of a pair of complementary literals in C1 and C2. From the lifting lemma, it is easy to derive a similar statement about any sequence of applications of the resolution rule: For any clause C in the resolution closure of S there is a clause C in the resolu- tion closure of S such that C is a ground instance of C and the derivation of C is the same length as the derivation of C. From this fact, it follows that if the empty clause appears in the resolution closure of S, it must also appear in the resolution closure of S. This is because the empty clause cannot be a ground instance of any other clause. To recap: we have shown that if S is unsatisfiable, then there is a finite derivation of the empty clause using the resolution rule. The lifting of theorem proving from ground clauses to first-order clauses provides a vast increase in power. This increase comes from the fact that the first-order proof need instantiate variables only as far as necessary for the proof, whereas the ground-clause methods were required to examine a huge number of arbitrary instantiations. 9.5.5 Equality None of the inference methods described so far in this chapter handle an assertion of the form x = y. Three distinct approaches can be taken. The first approach is to axiomatize equality to write down sentences about the equality relation in the knowledge base. We need to say that equality is reflexive, symmetric, and transitive, and we also have to say that we can substitute equals for equals in any predicate or function. So we need three basic axioms, and then one 354 Chapter 9. Inference in First-Order Logic for each predicate and function: x x = x x, y x = y y = x x, y, z x = y y = z x = z x, y x = y (P1(x) P1(y)) x, y x = y (P2(x) P2(y)) ... w, x, y, z w = y x = z (F1(w, x) = F1(y, z)) w, x, y, z w = y x = z (F2(w, x) = F2(y, z)) ... Given these sentences, a standard inference procedure such as resolution can perform tasks requiring equality reasoning, such as solving mathematical equations. However, these axioms will generate a lot of conclusions, most of them not helpful to a proof. So there has been a search for more efficient ways of handling equality. One alternative is to add inference rules rather than axioms. The simplest rule, demodulation, takes a unit clause x = y and some clause  that contains the term x, and yields a new clause formed by substituting y for x within . It works if the term within  unifies with x; it need not be exactly equal to x. Note that demodulation is directional; given x = y, the x always gets replaced with y, never vice versa. That means that demodulation can be used for simplifying expressions using demodulators such as x + 0 = x or x1 = x. As another example, given Father(Father(x)) = PaternalGrandfather (x) Birthdate(Father(Father(Bella)), 1926) we can conclude by demodulation Birthdate(PaternalGrandfather (Bella), 1926) . More formally, we have  Demodulation: For any terms x, y, and z, where z appears somewhere in literal mi DEMODULATION and where UNIFY(x, z) = , x = y, m1    mn SUB(SUBST(, x), SUBST(, y), m1    mn) . where SUBST is the usual substitution of a binding list, and SUB(x, y, m) means to replace x with y everywhere that x occurs within m. The rule can also be extended to handle non-unit clauses in which an equality literal appears:  Paramodulation: For any terms x, y, and z, where z appears somewhere in literal mi, PARAMODULATION and where UNIFY(x, z) = , l1    lk x = y, m1    mn SUB(SUBST(, x), SUBST(, y), SUBST(, l1    lk m1    mn) . For example, from P(F(x, B), x) Q(x) and F(A, y) = y R(y) Section 9.5. Resolution 355 we have  = UNIFY(F(A, y), F(x, B)) = {x/A, y/B}, and we can conclude by paramodu- lation the sentence P(B, A) Q(A) R(B) . Paramodulation yields a complete inference procedure for first-order logic with equality. A third approach handles equality reasoning entirely within an extended unification algorithm. That is, terms are unifiable if they are provably equal under some substitution, where provably allows for equality reasoning. For example, the terms 1 + 2 and 2 + 1 normally are not unifiable, but a unification algorithm that knows that x + y = y + x could unify them with the empty substitution. Equational unification of this kind can be done with EQUATIONAL UNIFICATION efficient algorithms designed for the particular axioms used (commutativity, associativity, and so on) rather than through explicit inference with those axioms. Theorem provers using this technique are closely related to the CLP systems described in Section 9.4. 9.5.6 Resolution strategies We know that repeated applications of the resolution inference rule will eventually find a proof if one exists. In this subsection, we examine strategies that help find proofs efficiently. Unit preference: This strategy prefers to do resolutions where one of the sentences is a single UNIT PREFERENCE literal (also known as a unit clause). The idea behind the strategy is that we are trying to produce an empty clause, so it might be a good idea to prefer inferences that produce shorter clauses. Resolving a unit sentence (such as P) with any other sentence (such as P QR) always yields a clause (in this case, Q R) that is shorter than the other clause. When the unit preference strategy was first tried for propositional inference in 1964, it led to a dramatic speedup, making it feasible to prove theorems that could not be handled without the preference. Unit resolution is a restricted form of resolution in which every resolution step must involve a unit clause. Unit resolution is incomplete in general, but complete for Horn clauses. Unit resolution proofs on Horn clauses resemble forward chaining. The OTTER theorem prover (Organized Techniques for Theorem-proving and Effective Research, McCune, 1992), uses a form of best-first search. Its heuristic function measures the weight of each clause, where lighter clauses are preferred. The exact choice of heuristic is up to the user, but generally, the weight of a clause should be correlated with its size or difficulty. Unit clauses are treated as light; the search can thus be seen as a generalization of the unit preference strategy. Set of support: Preferences that try certain resolutions first are helpful, but in general it is SET OF SUPPORT more effective to try to eliminate some potential resolutions altogether. For example, we can insist that every resolution step involve at least one element of a special set of clausesthe set of support. The resolvent is then added into the set of support. If the set of support is small relative to the whole knowledge base, the search space will be reduced dramatically. We have to be careful with this approach because a bad choice for the set of support will make the algorithm incomplete. However, if we choose the set of support S so that the remainder of the sentences are jointly satisfiable, then set-of-support resolution is complete. For example, one can use the negated query as the set of support, on the assumption that the 356 Chapter 9. Inference in First-Order Logic original knowledge base is consistent. (After all, if it is not consistent, then the fact that the query follows from it is vacuous.) The set-of-support strategy has the additional advantage of generating goal-directed proof trees that are often easy for humans to understand. Input resolution: In this strategy, every resolution combines one of the input sentences (from INPUT RESOLUTION the KB or the query) with some other sentence. The proof in Figure 9.11 on page 348 uses only input resolutions and has the characteristic shape of a single spine with single sen- tences combining onto the spine. Clearly, the space of proof trees of this shape is smaller than the space of all proof graphs. In Horn knowledge bases, Modus Ponens is a kind of input resolution strategy, because it combines an implication from the original KB with some other sentences. Thus, it is no surprise that input resolution is complete for knowledge bases that are in Horn form, but incomplete in the general case. The linear resolution strategy is a LINEAR RESOLUTION slight generalization that allows P and Q to be resolved together either if P is in the original KB or if P is an ancestor of Q in the proof tree. Linear resolution is complete. Subsumption: The subsumption method eliminates all sentences that are subsumed by (that SUBSUMPTION is, more specific than) an existing sentence in the KB. For example, if P(x) is in the KB, then there is no sense in adding P(A) and even less sense in adding P(A) Q(B). Subsumption helps keep the KB small and thus helps keep the search space small. Practical uses of resolution theorem provers Theorem provers can be applied to the problems involved in the synthesis and verification SYNTHESIS VERIFICATION of both hardware and software. Thus, theorem-proving research is carried out in the fields of hardware design, programming languages, and software engineeringnot just in AI. In the case of hardware, the axioms describe the interactions between signals and cir- cuit elements. (See Section 8.4.2 on page 309 for an example.) Logical reasoners designed specially for verification have been able to verify entire CPUs, including their timing prop- erties (Srivas and Bickford, 1990). The AURA theorem prover has been applied to design circuits that are more compact than any previous design (Wojciechowski and Wojcik, 1983). In the case of software, reasoning about programs is quite similar to reasoning about actions, as in Chapter 7: axioms describe the preconditions and effects of each statement. The formal synthesis of algorithms was one of the first uses of theorem provers, as outlined by Cordell Green (1969a), who built on earlier ideas by Herbert Simon (1963). The idea is to constructively prove a theorem to the effect that there exists a program p satisfying a certain specification. Although fully automated deductive synthesis, as it is called, has not DEDUCTIVE SYNTHESIS yet become feasible for general-purpose programming, hand-guided deductive synthesis has been successful in designing several novel and sophisticated algorithms. Synthesis of special- purpose programs, such as scientific computing code, is also an active area of research. Similar techniques are now being applied to software verification by systems such as the SPIN model checker (Holzmann, 1997). For example, the Remote Agent spacecraft control program was verified before and after flight (Havelund et al., 2000). The RSA public key encryption algorithm and the BoyerMoore string-matching algorithm have been verified this way (Boyer and Moore, 1984). Section 9.6. Summary 357 9.6 SUMMARY We have presented an analysis of logical inference in first-order logic and a number of algo- rithms for doing it.  A first approach uses'}\n",
            "Updated questions saved to updated_questions.json\n"
          ]
        }
      ]
    }
  ]
}