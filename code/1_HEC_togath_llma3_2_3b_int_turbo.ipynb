{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyQDm6114l6e",
        "outputId": "efabfbb3-fb84-4a2a-8c02-399658629aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.4.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.12)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.1.8)\n",
            "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (1.26.4)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.1.0)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from together) (17.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.10.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
            "Downloading together-1.4.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: eval-type-backport, together\n",
            "Successfully installed eval-type-backport-0.2.2 together-1.4.1\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.3\n"
          ]
        }
      ],
      "source": [
        "!pip install together\n",
        "!pip install --upgrade pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "j9OpGb1F4l6i",
        "outputId": "021adff0-0187-448c-c467-381156fb4e9c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "no such file: 'DataRaw/AI_Russell_Norvig.pdf'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-db114c751de7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mMODEL_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"meta-llama/Llama-3.2-3B-Instruct-Turbo\"\u001b[0m  \u001b[0;31m# Model to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mtext_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDF_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence that enables systems to learn from data, recognize patterns, and make decisions with minimal human intervention.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mgenerate_assignment_questions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-db114c751de7>\u001b[0m in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(pdf_path, chunk_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mExtract\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPDF\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msplit\u001b[0m \u001b[0mit\u001b[0m \u001b[0minto\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mfull_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[1;32m   2916\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"no such file: '{filename}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2918\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2919\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"'{filename}' is no file\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: no such file: 'DataRaw/AI_Russell_Norvig.pdf'"
          ]
        }
      ],
      "source": [
        "import pymupdf\n",
        "from together import Together\n",
        "import os\n",
        "from google.colab import userdata\n",
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')\n",
        "\n",
        "\n",
        "client = Together(api_key=TOGETHER_API_KEY)\n",
        "\n",
        "def extract_text_from_pdf(pdf_path, chunk_size):\n",
        "    \"\"\"\n",
        "    Extract text from a PDF file and split it into chunks of the specified size.\n",
        "    \"\"\"\n",
        "    doc = pymupdf.open(pdf_path)\n",
        "    full_text = \"\"\n",
        "\n",
        "    # Extract text from all pages\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        full_text += page.get_text()\n",
        "\n",
        "    # Split text into chunks of approximately chunk_size words\n",
        "    words = full_text.split()\n",
        "    chunks = [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "def generate_assignment_questions(input_text):\n",
        "    # Preparing the prompt to generate assignment questions\n",
        "    prompt = (\n",
        "        \"Generate a set of 10 questions for an assignment, including both subjective and coding questions, based on the following context:\\n\\n\"\n",
        "        f\"{input_text}\\n\\n\"\n",
        "        \"Provide the following details for each question:\\n\\n\"\n",
        "        \"Question text: Clear and specific wording for each question.\\n\"\n",
        "        \"Type: Specify whether the question is 'subjective' or 'code'.\\n\"\n",
        "        \"Difficulty level: Indicate whether the question is 'easy', 'medium', or 'hard'.\\n\"\n",
        "        # \"Respond in JSON format\"\n",
        "    )\n",
        "\n",
        "    # Making the API request\n",
        "    response = client.chat.completions.create(\n",
        "\n",
        "        api_key=\"23badefb26a5b846b7bcac2ce9db9602c538ba35bf0917c42d0e86e1381a6e72\",\n",
        "        model=\"meta-llama/Llama-3.2-3B-Instruct-Turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=500,  # Adjust as needed\n",
        "        temperature=0.7,\n",
        "        top_p=0.7,\n",
        "        top_k=50,\n",
        "        repetition_penalty=1,\n",
        "        stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    # Streaming the response\n",
        "    for token in response:\n",
        "        if hasattr(token, 'choices'):\n",
        "            print(token.choices[0].delta.content, end='', flush=True)\n",
        "\n",
        "# Example usage\n",
        "# Top-level controllable variables\n",
        "PDF_PATH = \"DataRaw/AI_Russell_Norvig.pdf\"  # Path to the PDF book\n",
        "OUTPUT_JSON_PATH = \"assignment_questions.json\"  # Path to save the output JSON\n",
        "CHUNK_SIZE = 2000  # Number of words per chunk\n",
        "MAX_TOKENS = 500  # Max tokens for the model response\n",
        "TEMPERATURE = 0.7  # Temperature for response variability\n",
        "TOP_P = 0.7  # Top-p sampling parameter\n",
        "TOP_K = 50  # Top-k sampling parameter\n",
        "REPETITION_PENALTY = 1  # Repetition penalty\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct-Turbo\"  # Model to use\n",
        "\n",
        "text_chunks = extract_text_from_pdf(PDF_PATH, CHUNK_SIZE)\n",
        "input_text = \"Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence that enables systems to learn from data, recognize patterns, and make decisions with minimal human intervention.\"\n",
        "generate_assignment_questions(text_chunks)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKuFQHNE6bNq",
        "outputId": "f1d72481-b4ad-4b18-9025-31f31078fcbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Mdky04S44l6m",
        "outputId": "48afad21-1a66-4e52-a328-6a6867245973"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "no such file: 'DataRaw/NLP1.pdf'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-415ebe2d52ff>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# Extract text chunks from the provided PDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mtext_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDF_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Use the first chunk for generating assignment questions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-415ebe2d52ff>\u001b[0m in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(pdf_path, chunk_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mExtract\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPDF\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msplit\u001b[0m \u001b[0mit\u001b[0m \u001b[0minto\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mfull_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[1;32m   2916\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"no such file: '{filename}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2918\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2919\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"'{filename}' is no file\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: no such file: 'DataRaw/NLP1.pdf'"
          ]
        }
      ],
      "source": [
        "import pymupdf  # PyMuPDF\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "# Top-level controllable variables\n",
        "PDF_PATH = \"DataRaw/NLP1.pdf\"  # Path to the PDF book\n",
        "OUTPUT_JSON_PATH = \"assignment_questions.json\"  # Path to save the output JSON\n",
        "OUTPUT_TEXT_PATH = \"assignment_questions.txt\"  # Path to save the output text\n",
        "CHUNK_SIZE = 500  # Number of words per chunk\n",
        "MAX_TOKENS = 500  # Max tokens for the model response\n",
        "TEMPERATURE = 0.7  # Temperature for response variability\n",
        "TOP_P = 0.7  # Top-p sampling parameter\n",
        "TOP_K = 50  # Top-k sampling parameter\n",
        "REPETITION_PENALTY = 1  # Repetition penalty\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct-Turbo\"  # Model to use\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Together client\n",
        "client = Together(api_key=TOGETHER_API_KEY)\n",
        "\n",
        "def extract_text_from_pdf(pdf_path, chunk_size):\n",
        "    \"\"\"\n",
        "    Extract text from a PDF file and split it into chunks of the specified size.\n",
        "    \"\"\"\n",
        "    doc = pymupdf.open(pdf_path)\n",
        "    full_text = \"\"\n",
        "\n",
        "    # Extract text from all pages\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        full_text += page.get_text()\n",
        "\n",
        "    # Split text into chunks of approximately chunk_size words\n",
        "    words = full_text.split()\n",
        "    chunks = [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "def generate_assignment_questions(input_text):\n",
        "    \"\"\"\n",
        "    Generate assignment questions using Together API and save the response as a JSON file and a text file.\n",
        "    \"\"\"\n",
        "    # Preparing the prompt to generate assignment questions\n",
        "    prompt = (\n",
        "        \"Generate a set of 6 questions for an assignment, including both subjective and coding questions, based on the following context:\\n\\n\"\n",
        "        f\"{input_text}\\n\\n\"\n",
        "        \"Provide the following details for each question:\\n\\n\"\n",
        "        \"Question text: Clear and specific wording for each question.\\n\"\n",
        "        \"Type: Specify whether the question is 'subjective' or 'code'.\\n\"\n",
        "        \"Difficulty: Indicate whether the question is 'easy', 'medium', or 'hard'.\\n\"\n",
        "        \"Respond in JSON format\"\n",
        "    )\n",
        "\n",
        "    # Making the API request\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=MAX_TOKENS,\n",
        "        temperature=TEMPERATURE,\n",
        "        top_p=TOP_P,\n",
        "        top_k=TOP_K,\n",
        "        repetition_penalty=REPETITION_PENALTY,\n",
        "        stop=[\"<|eot_id|>\", \"<|eom_id|>\"]\n",
        "    )\n",
        "\n",
        "    # Collecting the response\n",
        "    response_text = response.choices[0].message.content\n",
        "\n",
        "    # Save response as JSON\n",
        "    try:\n",
        "        response_json = json.loads(response_text)\n",
        "        with open(OUTPUT_JSON_PATH, \"w\") as json_file:\n",
        "            json.dump(response_json, json_file, indent=4)\n",
        "        print(f\"Response saved to {OUTPUT_JSON_PATH}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"Failed to decode JSON response:\", e)\n",
        "\n",
        "    # Save response as text\n",
        "    with open(OUTPUT_TEXT_PATH, \"w\") as text_file:\n",
        "        text_file.write(response_text)\n",
        "    print(f\"Response saved to {OUTPUT_TEXT_PATH}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Extract text chunks from the provided PDF\n",
        "    text_chunks = extract_text_from_pdf(PDF_PATH, CHUNK_SIZE)\n",
        "\n",
        "    # Use the first chunk for generating assignment questions\n",
        "    if text_chunks:\n",
        "        generate_assignment_questions(text_chunks[0])\n",
        "    else:\n",
        "        print(\"No text found in the PDF.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "ZTzd7ToK4l6n",
        "outputId": "57bf9820-a061-4eb9-d17a-023f4d52ef72"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f2d843fc0f03>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# Extract text chunks from the provided PDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mtext_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDF_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_chunks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'Chunks Total'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-f2d843fc0f03>\u001b[0m in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(pdf_path, chunk_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mExtract\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPDF\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msplit\u001b[0m \u001b[0mit\u001b[0m \u001b[0minto\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mfull_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encrypted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# we won't init until doc is decrypted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m                 \u001b[0;31m# the following hack detects invalid/empty SVG files, which else may lead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m                 \u001b[0;31m# to interpreter crashes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36minit_doc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encrypted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4489\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot initialize - document still encrypted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4490\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadOutline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4491\u001b[0m         self.metadata = dict(\n\u001b[1;32m   4492\u001b[0m                     [\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36m_loadOutline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3500\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFzDocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3501\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3502\u001b[0;31m             \u001b[0mol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfz_load_outline\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3503\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mg_exceptions_verbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0mexception_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymupdf/mupdf.py\u001b[0m in \u001b[0;36mfz_load_outline\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m  44422\u001b[0m         \u001b[0mShould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfreed\u001b[0m \u001b[0mby\u001b[0m \u001b[0mfz_drop_outline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  44423\u001b[0m     \"\"\"\n\u001b[0;32m> 44424\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_mupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfz_load_outline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  44425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  44426\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfz_load_outline_from_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pymupdf  # PyMuPDF\n",
        "import os\n",
        "import json\n",
        "\n",
        "from together import Together\n",
        "import re\n",
        "from google.colab import userdata\n",
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')\n",
        "\n",
        "# Top-level controllable variables\n",
        "PDF_PATH = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/AI_Russell_Norvig.pdf\"  # Path to the PDF book\n",
        "OUTPUT_DIR = \"output5\"  # Directory to save the output files\n",
        "CHUNK_SIZE = 2000  # Number of words per chunk\n",
        "MAX_TOKENS = 1000  # Max tokens for the model response\n",
        "TEMPERATURE = 0.7  # Temperature for response variability\n",
        "TOP_P = 0.7  # Top-p sampling parameter\n",
        "TOP_K = 50  # Top-k sampling parameter\n",
        "REPETITION_PENALTY = 1  # Repetition penalty\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct-Turbo\"  # Model to use\n",
        "\n",
        "\n",
        "# Initialize Together client\n",
        "client = Together(api_key=TOGETHER_API_KEY)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "clo_array = [\n",
        "\"Understand key components in the field of artificial\"\n",
        "\"Implement classical artificial intelligence techniques\"\n",
        "\"Analyze artificial intelligence techniques for practical problem solving\"\n",
        "]\n",
        "content_array = [\n",
        "    \"Explain the basic components of AI and identify AI systems with real-world examples.\",\n",
        "    \"List and describe the branches of AI, such as Machine Learning, Natural Language Processing, and Robotics.\",\n",
        "    \"Define reasoning and knowledge representation, and demonstrate their applications in AI systems.\",\n",
        "    \"Illustrate propositional logic and first-order logic with examples.\",\n",
        "    \"Simulate and compare informed, uninformed, and local searching algorithms for problem-solving in AI.\",\n",
        "    \"Define and solve constraint satisfaction problems with practical examples.\",\n",
        "    \"Demonstrate adversarial search using the Min-Max algorithm and Alpha-Beta pruning in game-playing scenarios.\",\n",
        "    \"Distinguish between supervised, unsupervised, and reinforcement learning techniques, providing examples of each.\",\n",
        "    \"Explain uncertainty in AI and apply fuzzy logic to handle uncertainty in real-world scenarios.\",\n",
        "    \"Discuss recent trends in AI and analyze case studies of AI systems to identify their strengths and weaknesses.\"\n",
        "]\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path, chunk_size):\n",
        "    \"\"\"\n",
        "    Extract text from a PDF file and split it into chunks of the specified size.\n",
        "    \"\"\"\n",
        "    doc = pymupdf.open(pdf_path)\n",
        "    full_text = \"\"\n",
        "\n",
        "    # Extract text from all pages\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        full_text += page.get_text()\n",
        "\n",
        "    # Split text into chunks of approximately chunk_size words\n",
        "    words = full_text.split()\n",
        "    chunks = [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "\n",
        "\n",
        "def generate_assignment_questions(input_text, chunk_number):\n",
        "    \"\"\"\n",
        "    Generate assignment questions using Together API and save the response as a JSON file and a text file.\n",
        "    \"\"\"\n",
        "    # # Preparing the prompt to generate assignment questions\n",
        "    # prompt = (\n",
        "    #     \"Generate a set of 6 questions for an assignment, including both subjective and coding questions, based on the following context:\\n\\n\"\n",
        "    #     f\"{input_text}\\n\\n\"\n",
        "    #     \"Provide the following details for each question:\\n\\n\"\n",
        "    #     \"Question: Clear and specific wording for each question.\\n\"\n",
        "    #     \"Type: Specify whether the question is 'subjective' or 'code'.\\n\"\n",
        "    #     \"Difficulty: Indicate whether the question is 'easy', 'medium', or 'hard'.\\n\"\n",
        "    #     \"Respond in JSON format always Array which consist of Questions objects\"\n",
        "    # )\n",
        "    prompt = (\n",
        "    \"Generate 6 questions for an assignment, including both 3 subjective and 3 coding questions, \"\n",
        "    \"based on the following context:\\n\\n\"\n",
        "    f\"{input_text}\\n\\n\"\n",
        "    \"For each question, provide the following details:\\n\\n\"\n",
        "    \"1) Question: A clear and specific wording for the question.\\n\"\n",
        "    \"2) Type: Indicate whether the question is 'subjective' or 'code'.\\n\"\n",
        "    \"3) Difficulty: Indicate whether the question is 'easy', 'medium', or 'hard'.\\n\"\n",
        "    \"4) CLO: Select and include the most appropriate CLO from the clo_array:\\n\"\n",
        "    f\"{clo_array}\\n\\n\"\n",
        "    \"5) Topic: Select and include one or more relevant topics from the content_array:\\n\"\n",
        "    f\"{content_array}\\n\\n\"\n",
        "    \"Respond in JSON format as an array of objects Nothing Else only JSON Array, where each object has the keys:\\n\"\n",
        "    \"['Question', 'Type', 'Difficulty', 'CLO', 'Topic'].\"\n",
        ")\n",
        "\n",
        "\n",
        "    # Making the API request\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=MAX_TOKENS,\n",
        "        temperature=TEMPERATURE,\n",
        "        top_p=TOP_P,\n",
        "        top_k=TOP_K,\n",
        "        repetition_penalty=REPETITION_PENALTY,\n",
        "        stop=[\"<|eot_id|>\", \"<|eom_id|>\"]\n",
        "    )\n",
        "\n",
        "    # Collecting the response\n",
        "    response_text = response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "    # Save response as text\n",
        "    output_text_path = os.path.join(OUTPUT_DIR, f\"assignment_questions_chunk_{chunk_number}.txt\")\n",
        "    with open(output_text_path, \"w\") as text_file:\n",
        "        text_file.write(response_text)\n",
        "    print(f\"Response saved to {output_text_path}\")\n",
        "\n",
        "def merge_chunks_to_single_file(output_dir):\n",
        "    \"\"\"\n",
        "    Read all chunk files from the output directory and merge them into a single file.\n",
        "    \"\"\"\n",
        "    merged_data = []\n",
        "    for filename in os.listdir(output_dir):\n",
        "        if filename.endswith(\".json\"):\n",
        "            file_path = os.path.join(output_dir, filename)\n",
        "            with open(file_path, \"r\") as json_file:\n",
        "                data = json.load(json_file)\n",
        "                merged_data.append(data)\n",
        "\n",
        "    # Save merged data to a new JSON file\n",
        "    merged_output_path = os.path.join(output_dir, \"merged_assignment_questions.json\")\n",
        "    with open(merged_output_path, \"w\") as merged_file:\n",
        "        json.dump(merged_data, merged_file, indent=4)\n",
        "    print(f\"Merged data saved to {merged_output_path}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Extract text chunks from the provided PDF\n",
        "    text_chunks = extract_text_from_pdf(PDF_PATH, CHUNK_SIZE)\n",
        "    print(len(text_chunks) , 'Chunks Total')\n",
        "\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    # Generate assignment questions for all chunks\n",
        "    if text_chunks:\n",
        "        for i, chunk in enumerate(text_chunks):\n",
        "            generate_assignment_questions(chunk, i)\n",
        "        # Merge all chunk files into a single file\n",
        "        # merge_chunks_to_single_file(OUTPUT_DIR)\n",
        "    else:\n",
        "        print(\"No text found in the PDF.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uV5zwqL1YqFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merging All Questions in 1 File**"
      ],
      "metadata": {
        "id": "vLLn-nhGYq-2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ECJTb9f4l6p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "6836ecd4-ca12-4d41-e124-b421ec5eb210"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'OUTPUT_DIR' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e91847429525>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/merged_output.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'OUTPUT_DIR' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "def merge_txt_files_to_json(folder_path, output_file):\n",
        "    merged_data = []\n",
        "\n",
        "    # Iterate over all files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            with open(file_path, 'r+', encoding='utf-8') as file:\n",
        "                try:\n",
        "                    # Remove block markers before loading JSON\n",
        "                    content = file.read().strip('`')\n",
        "                    file.seek(0)\n",
        "                    file.truncate()\n",
        "                    file.write(content)\n",
        "                    file.seek(0)\n",
        "                    # Load JSON content from the file\n",
        "                    data = json.load(file)\n",
        "                    merged_data.extend(data) if isinstance(data, list) else merged_data.append(data)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Error decoding JSON from file {filename}: {e}\")\n",
        "\n",
        "    # Write the merged data to the output JSON file\n",
        "    with open(output_file, 'w', encoding='utf-8') as output:\n",
        "        json.dump(merged_data, output, indent=4)\n",
        "\n",
        "# Example usage\n",
        "folder_path = OUTPUT_DIR\n",
        "output_file = OUTPUT_DIR+'/merged_output.json'\n",
        "\n",
        "merge_txt_files_to_json(folder_path, output_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attaching Metadata Chunk Text used for Generating Question and Chunk number**"
      ],
      "metadata": {
        "id": "v85CYPZXYc1V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myun3Jsn4l6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "88483b3a-622c-4838-fc68-a394104ec290"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'extract_text_from_pdf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ec2c10885429>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtext_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDF_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmerge_txt_files_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'extract_text_from_pdf' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "text_chunks = extract_text_from_pdf(PDF_PATH, CHUNK_SIZE)\n",
        "\n",
        "def merge_txt_files_to_json(folder_path, output_file):\n",
        "    merged_data = []\n",
        "\n",
        "    # Iterate over all files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            with open(file_path, 'r+', encoding='utf-8') as file:\n",
        "                try:\n",
        "                    # Remove block markers before loading JSON\n",
        "                    content = file.read().strip('`')\n",
        "                    file.seek(0)\n",
        "                    file.truncate()\n",
        "                    file.write(content)\n",
        "                    file.seek(0)\n",
        "                    # Load JSON content from the file\n",
        "                    data = json.load(file)\n",
        "\n",
        "                    # Add chunk number and text to each object\n",
        "                    chunk_number = filename.split('_')[-1].replace('.txt', '')\n",
        "                    print(chunk_number)\n",
        "                    if isinstance(data, list):\n",
        "                        for obj in data:\n",
        "                            obj['chunkNumber'] = int(chunk_number)\n",
        "                            obj['text'] = text_chunks[int(chunk_number)]\n",
        "                        merged_data.extend(data)\n",
        "                    else:\n",
        "                        data['chunkNumber'] = int(chunk_number)\n",
        "                        data['text'] = content\n",
        "                        merged_data.append(data)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Error decoding JSON from file {filename}: {e}\")\n",
        "\n",
        "    # Write the merged data to the output JSON file\n",
        "    with open(output_file, 'w', encoding='utf-8') as output:\n",
        "        json.dump(merged_data, output, indent=4)\n",
        "\n",
        "# Example usage\n",
        "# folder_path = 'output'\n",
        "# output_file = 'output/merged_output_meta.json'\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/\"\n",
        "folder_path = OUTPUT_DIR\n",
        "output_file = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/merged_output_meta.json\"\n",
        "merge_txt_files_to_json(folder_path, output_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming merged_output_meta.json is in the OUTPUT_DIR\n",
        "file_path = os.path.join(OUTPUT_DIR, \"merged_output_meta.json\")\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "        print(len(data))\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File '{file_path}' not found.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Invalid JSON format in '{file_path}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gtTaJIJ1iAS",
        "outputId": "952e8c54-76de-419e-e1b9-f7f6f6635825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reviewing Dataset on Argilla"
      ],
      "metadata": {
        "id": "d-nFeAyLLBot"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffcbrHyV4l6r",
        "outputId": "e9a4ff5a-6805-4b52-f686-1cb4c2626075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting argilla\n",
            "  Downloading argilla-2.7.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: httpx>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from argilla) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from argilla) (2.10.6)\n",
            "Requirement already satisfied: huggingface_hub>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from argilla) (0.27.1)\n",
            "Requirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.11/dist-packages (from argilla) (4.67.1)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from argilla) (13.9.4)\n",
            "Collecting datasets>=2.0.0 (from argilla)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pillow>=9.5.0 in /usr/local/lib/python3.11/dist-packages (from argilla) (11.1.0)\n",
            "Collecting standardwebhooks>=1.0.0 (from argilla)\n",
            "  Downloading standardwebhooks-1.0.0.tar.gz (4.9 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->argilla) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->argilla) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->argilla) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.0.0->argilla)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->argilla) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->argilla) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.0.0->argilla)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.0.0->argilla)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.0.0->argilla)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->argilla) (3.11.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->argilla) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->argilla) (6.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.26.0->argilla) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.26.0->argilla) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.26.0->argilla) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.26.0->argilla) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.26.0->argilla) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.22.0->argilla) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.0->argilla) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.0->argilla) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.0.0->argilla) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.0.0->argilla) (2.18.0)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.11/dist-packages (from standardwebhooks>=1.0.0->argilla) (25.1.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from standardwebhooks>=1.0.0->argilla) (2.8.2)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from standardwebhooks>=1.0.0->argilla) (1.2.18)\n",
            "Collecting types-python-dateutil (from standardwebhooks>=1.0.0->argilla)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting types-Deprecated (from standardwebhooks>=1.0.0->argilla)\n",
            "  Downloading types_Deprecated-1.2.15.20241117-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->argilla) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->argilla) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->argilla) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->argilla) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->argilla) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->argilla) (1.18.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->argilla) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.0.0->argilla) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.0.0->argilla) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.26.0->argilla) (1.3.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->standardwebhooks>=1.0.0->argilla) (1.17.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.0.0->argilla) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.0.0->argilla) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->standardwebhooks>=1.0.0->argilla) (1.17.0)\n",
            "Downloading argilla-2.7.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_Deprecated-1.2.15.20241117-py3-none-any.whl (3.8 kB)\n",
            "Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: standardwebhooks\n",
            "  Building wheel for standardwebhooks (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for standardwebhooks: filename=standardwebhooks-1.0.0-py3-none-any.whl size=3571 sha256=67c54467bd2892f4d5e1bffdf9988fc04dba7ad1d5f49fc060d1e5a672400c60\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/17/f8/98974cdeee2274890763a7b982693beefb973b33164fd971cc\n",
            "Successfully built standardwebhooks\n",
            "Installing collected packages: xxhash, types-python-dateutil, types-Deprecated, fsspec, dill, multiprocess, standardwebhooks, datasets, argilla\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed argilla-2.7.0 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 standardwebhooks-1.0.0 types-Deprecated-1.2.15.20241117 types-python-dateutil-2.9.0.20241206 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install argilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WF0itzE4l6s",
        "outputId": "8a9abade-1073-4922-a0f0-eeb0693c5c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sending records...: 5batch [00:17,  3.53s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Records from '/content/cleaned_output.json' have been successfully logged to the 'ExpertOpinion' dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import argilla as rg\n",
        "import json\n",
        "\n",
        "# Initialize the Argilla client\n",
        "client = rg.Argilla(\n",
        "    api_url=\"https://abdul110-expertopnionondataset2.hf.space\",\n",
        "    api_key=\"zdpBR7Hg3Q56AtcmZ1AceRkb8V5wo_4LK7JwAG2_WiuLZFxy3MS2kDDFRG3aGlqumZrokBdmOGUsnZ5PXoO-_6OimcNyUxBIVrAUIt6N3lE\",\n",
        ")\n",
        "\n",
        "# Define settings for the dataset\n",
        "settings = rg.Settings(\n",
        "    guidelines=\"Please provide feedback on the following aspects:\\n\"\n",
        "              \"1. Is the question relevant to the given text?\\n\"\n",
        "              \"2. Is the difficulty level appropriate?\\n\"\n",
        "              \"3. Is the question subjective or code-related?\\n\"\n",
        "              \"4. Does the question align with the specified topic?\",\n",
        "    fields=[\n",
        "        rg.TextField(\n",
        "            name=\"Question\",\n",
        "            title=\"Question Text\",\n",
        "            required=True,\n",
        "        ),\n",
        "        rg.TextField(\n",
        "            name=\"Type\",\n",
        "            title=\"Question Type\",\n",
        "            required=True,\n",
        "        ),\n",
        "        rg.TextField(\n",
        "            name=\"Difficulty\",\n",
        "            title=\"Difficulty Level\",\n",
        "            required=True,\n",
        "        ),\n",
        "        rg.TextField(\n",
        "            name=\"Topic\",\n",
        "            title=\"Topic\",\n",
        "            required=True,\n",
        "        ),\n",
        "        rg.TextField(\n",
        "            name=\"CLO\",\n",
        "            title=\"Course Learning Outcome\",\n",
        "            required=True,\n",
        "        ),\n",
        "        rg.TextField(\n",
        "            name=\"text\",\n",
        "            title=\"Context/Text\",\n",
        "            required=True,\n",
        "        ),\n",
        "    ],\n",
        "    questions=[\n",
        "        rg.LabelQuestion(\n",
        "            name=\"question_relevance\",\n",
        "            title=\"Is the question relevant to the given text?\",\n",
        "            labels=[\"yes\", \"no\"],\n",
        "            required=True,\n",
        "        ),\n",
        "        rg.LabelQuestion(\n",
        "            name=\"difficulty_level\",\n",
        "            title=\"Is the difficulty level appropriate?\",\n",
        "            labels=[\"easy\", \"medium\", \"hard\"],\n",
        "            required=True,\n",
        "        ),\n",
        "        rg.LabelQuestion(\n",
        "            name=\"question_type\",\n",
        "            title=\"Is the question subjective or code-related?\",\n",
        "            labels=[\"subjective\", \"code\"],\n",
        "            required=True,\n",
        "        ),\n",
        "        rg.LabelQuestion(\n",
        "            name=\"topic_alignment\",\n",
        "            title=\"Does the question align with the specified topic?\",\n",
        "            labels=[\"yes\", \"no\"],\n",
        "            required=True,\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Create Argilla dataset\n",
        "dataset = rg.Dataset(\n",
        "    name=\"ExpertOpinion\",\n",
        "    settings=settings,\n",
        ")\n",
        "\n",
        "dataset.create()\n",
        "\n",
        "# Load records from a JSON file\n",
        "json_file_path = \"/content/cleaned_output.json\"\n",
        "\n",
        "try:\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
        "        records = json.load(json_file)\n",
        "\n",
        "    # Prepare records for logging\n",
        "    argilla_records = []\n",
        "    for record in records:\n",
        "        argilla_records.append(\n",
        "            rg.Record(\n",
        "                fields={\n",
        "                    \"Question\": record.get(\"Question\", \"\"),\n",
        "                    \"Type\": record.get(\"Type\", \"\"),\n",
        "                    \"Difficulty\": record.get(\"Difficulty\", \"\"),\n",
        "                    \"Topic\": record.get(\"Topic\", \"\"),\n",
        "                    \"CLO\": record.get(\"CLO\", \"\"),\n",
        "                    \"text\": record.get(\"text\", \"\"),\n",
        "                }\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Log records to the dataset\n",
        "    dataset.records.log(argilla_records)\n",
        "\n",
        "    print(f\"Records from '{json_file_path}' have been successfully logged to the 'ExpertOpinion' dataset.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File '{json_file_path}' not found.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: File '{json_file_path}' is not a valid JSON file.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your dataset name\n",
        "dataset_name = \"ExpertOpinion\"\n",
        "\n",
        "\n",
        "# Load the dataset with annotations\n",
        "reviewed_dataset = rg.load_dataset(name=dataset_name)\n",
        "\n",
        "# Convert to a pandas DataFrame for easier manipulation\n",
        "import pandas as pd\n",
        "df = pd.DataFrame([record.dict() for record in reviewed_dataset])\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "THmCVq-EAVPy",
        "outputId": "9672d969-e7a4-4991-fb7e-30271633d3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'argilla' has no attribute 'load_dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f5c4545172a9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the dataset with annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mreviewed_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Convert to a pandas DataFrame for easier manipulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'argilla' has no attribute 'load_dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = client.datasets(\"ExpertOpinion\")\n",
        "dataset.progress(with_users_distribution=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpqMhu8mE7Bw",
        "outputId": "d6933f79-1481-45f1-f9da-6029db5bf53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'total': 24,\n",
              " 'completed': 24,\n",
              " 'pending': 0,\n",
              " 'users': {'AiTester110': {'completed': {'submitted': 24,\n",
              "    'draft': 0,\n",
              "    'discarded': 0},\n",
              "   'pending': {'submitted': 0, 'draft': 0, 'discarded': 0}}}}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = client.datasets(\"ExpertOpinion\")\n",
        "dataset.progress(with_users_distribution=True)"
      ],
      "metadata": {
        "id": "Gra4jRHjGTal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmF20q3lG0qC",
        "outputId": "9960411c-eec1-4cf1-d55e-2521c7c2b9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(id=UUID('682a2592-0220-46fc-ba00-19c271d1f044') inserted_at=datetime.datetime(2024, 12, 28, 6, 34, 21, 545365) updated_at=datetime.datetime(2024, 12, 28, 6, 34, 22, 134127) name='ExpertOpinion' status='ready' guidelines='Please provide feedback on the following aspects: :\\n Is the question relevant to the given text? :\\n Is the difficulty level appropriate? :\\n Is the question subjective or code-related?' allow_extra_metadata=False distribution=OverlapTaskDistributionModel(strategy='overlap', min_submitted=1) workspace_id=UUID('84f35e77-5da7-4eb9-879e-835e614e3dc5') last_activity_at=datetime.datetime(2024, 12, 28, 6, 38, 3, 874410))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for record in dataset.records(\n",
        "\n",
        "    with_responses=True,\n",
        "\n",
        "    ):\n",
        "    print(record.fields)\n",
        "    print(record.responses)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNTEH0pRHABk",
        "outputId": "7969ae79-6638-456e-ea48-917c58293856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'Implement the scaled dot-product attention mechanism using the formula: attention(Q, K, V) = softmax(Q * K^T / sqrt(d)) * V, where d is the dimensionality of the key vectors. Provide the output of the attention mechanism for a given set of queries, keys, and values.', 'type': 'code', 'difficulty': 'medium', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Compare the performance of a transformer-based model with a traditional recurrent neural network (RNN) on the IMDb movie review dataset for sentiment analysis. Which model performs better and why?', 'type': 'subjective', 'difficulty': 'hard', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Write a Python function to preprocess the IMDb movie review dataset, including tokenization, padding, and truncation. The function should handle special characters and return a list of token IDs for each review.', 'type': 'code', 'difficulty': 'easy', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'medium'}], 'question_type': [{'value': 'code'}]}\n",
            "{'question': 'Design a simplified version of the Transformer encoder for sentiment analysis, including an embedding layer, multi-head self-attention layer, and feed-forward network. Explain the purpose of each component and how they contribute to the overall model.', 'type': 'subjective', 'difficulty': 'medium', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Train a transformer-based model on the IMDb training dataset for sentiment analysis, optimizing for binary cross-entropy loss. Monitor accuracy and F1-score during training and report the final results.', 'type': 'code', 'difficulty': 'hard', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'hard'}], 'question_type': [{'value': 'code'}]}\n",
            "{'question': 'Implement a technique to handle out-of-vocabulary (OOV) words in the transformer-based model, such as using a subword tokenizer or a learned embedding. Explain the advantages and disadvantages of each approach.', 'type': 'subjective', 'difficulty': 'hard', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'What are some potential applications of NLP in real-world industries, and how can researchers and practitioners collaborate to drive innovation?', 'type': 'subjective', 'difficulty': 'medium', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'medium'}], 'question_type': [{'value': 'code'}]}\n",
            "{'question': 'Write a Python function to implement the wordpiece tokenization technique used in BERT, given a list of words and a maximum sequence length.', 'type': 'code', 'difficulty': 'hard', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': \"How does the concept of 'understanding' in NLP differ from human understanding, and what are the implications for AI development?\", 'type': 'subjective', 'difficulty': 'medium', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Implement a simple sentiment analysis model using a Naive Bayes classifier and evaluate its performance on a given dataset.', 'type': 'code', 'difficulty': 'medium', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Discuss the trade-offs between using pre-trained language models versus training your own language model from scratch, and when each approach might be more suitable.', 'type': 'subjective', 'difficulty': 'hard', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Write a Python script to generate a list of synonyms for a given word using the WordNet lexical database.', 'type': 'code', 'difficulty': 'easy', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'What is the primary advantage of using the Transformer architecture over traditional Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks in Natural Language Processing (NLP)?', 'type': 'subjective', 'difficulty': 'medium', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Implement a basic Transformer model in Python using the PyTorch library, including the multi-head self-attention mechanism and feed-forward networks. The input sequence should be a list of words, and the output should be a list of predicted words.', 'type': 'code', 'difficulty': 'hard', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Explain the concept of positional encoding in the Transformer architecture and its purpose in capturing the position of each token in a sequence.', 'type': 'subjective', 'difficulty': 'easy', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Derive the formula for the self-attention mechanism in the Transformer model, including the query (Q), key (K), and value (V) vectors. Explain the mathematical operations involved in computing the weighted sum of the token representations.', 'type': 'code', 'difficulty': 'hard', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Compare and contrast the Transformer architecture with traditional sequence-to-sequence models, highlighting its strengths and weaknesses in capturing context and handling long-range dependencies.', 'type': 'subjective', 'difficulty': 'medium', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Write a Python function to calculate the attention scores for a given input sequence using the self-attention mechanism. The input sequence should be a list of vectors, and the output should be a 2D matrix of attention scores.', 'type': 'code', 'difficulty': 'medium', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'medium'}], 'question_type': [{'value': 'code'}]}\n",
            "{'question': \"What is the primary challenge associated with the Transformer model's self-attention mechanism, and how can it be mitigated?\", 'type': 'subjective', 'difficulty': 'medium', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Implement a simplified Transformer architecture in PyTorch to classify movie reviews as positive or negative. Provide a brief explanation of your implementation.', 'type': 'code', 'difficulty': 'hard', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'code'}]}\n",
            "{'question': 'How does positional encoding address the lack of inherent order in the Transformer model, and what are some alternative techniques being explored?', 'type': 'subjective', 'difficulty': 'medium', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Compare and contrast the use of dropout and label smoothing as regularization techniques in Transformer-based models. Provide examples of when to use each.', 'type': 'subjective', 'difficulty': 'medium', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Design an experiment to evaluate the effectiveness of early stopping in a Transformer-based sentiment classifier. What metrics will you use to measure performance?', 'type': 'subjective', 'difficulty': 'hard', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "{'question': 'Implement a sparse attention mechanism in a simplified Transformer architecture using PyTorch. Explain the benefits of this approach.', 'type': 'code', 'difficulty': 'hard', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argilla as rg\n",
        "\n",
        "\n",
        "\n",
        "# Loop through records to display relevant details\n",
        "for record in dataset.records(\n",
        "    with_suggestions=True,\n",
        "    with_responses=True,\n",
        "    with_vectors=True\n",
        "):\n",
        "    print(\"Record Text:\")\n",
        "    print(record.fields)\n",
        "    print(\"\\nResponses:\")\n",
        "    print(record.responses)\n",
        "\n",
        "    print(\"-\" * 80)  # Separator for readability\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG1GuYc-IFJJ",
        "outputId": "c981a38b-a8fb-4746-a852-e1993eb84e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record Text:\n",
            "{'question': 'Implement the scaled dot-product attention mechanism using the formula: attention(Q, K, V) = softmax(Q * K^T / sqrt(d)) * V, where d is the dimensionality of the key vectors. Provide the output of the attention mechanism for a given set of queries, keys, and values.', 'type': 'code', 'difficulty': 'medium', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Compare the performance of a transformer-based model with a traditional recurrent neural network (RNN) on the IMDb movie review dataset for sentiment analysis. Which model performs better and why?', 'type': 'subjective', 'difficulty': 'hard', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Write a Python function to preprocess the IMDb movie review dataset, including tokenization, padding, and truncation. The function should handle special characters and return a list of token IDs for each review.', 'type': 'code', 'difficulty': 'easy', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'medium'}], 'question_type': [{'value': 'code'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Design a simplified version of the Transformer encoder for sentiment analysis, including an embedding layer, multi-head self-attention layer, and feed-forward network. Explain the purpose of each component and how they contribute to the overall model.', 'type': 'subjective', 'difficulty': 'medium', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Train a transformer-based model on the IMDb training dataset for sentiment analysis, optimizing for binary cross-entropy loss. Monitor accuracy and F1-score during training and report the final results.', 'type': 'code', 'difficulty': 'hard', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'hard'}], 'question_type': [{'value': 'code'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Implement a technique to handle out-of-vocabulary (OOV) words in the transformer-based model, such as using a subword tokenizer or a learned embedding. Explain the advantages and disadvantages of each approach.', 'type': 'subjective', 'difficulty': 'hard', 'text': 'Key (K): A vector representation that provides context for the attention score calculation. • Value (V): A vector that contains the information to be aggregated. The attention score for each pair of tokens is calculated by taking the dot product between the query and key vectors, scaled by the square root of the dimension size, and applying a softmax function to obtain the weights. Mathematically, this is given by: where is the dimensionality of the key vectors. This scaling helps to maintain stable gradients, which is crucial when dealing with large sequences. The softmax function is used to normalize the scores into probabilities, which are then used as weights to compute a weighted sum of the value vectors. This allows the model to emphasize relevant parts of the sequence while downplaying less important ones. Multi-Head Attention extends the idea of self-attention by computing multiple attention functions in parallel, each with different learned weights, allowing the model to capture diverse types of relationships within the data. The outputs from these heads are concatenated and linearly transformed to form the final output. This approach provides the model with multiple “views” of the sequence, enhancing its ability to learn rich contextual representations. Problem: Implementing Scaled Dot-Product Attention Problem Statement: Implement the scaled dot-product attention mechanism. Given matrices Q (queries), K (keys), and V (values), compute the output of the attention mechanism. Steps to Solve: 1. Compute the dot product of Q and K^T to obtain the raw attention scores. 2. Scale the result by to prevent the dot products from growing too large. 3. Apply the softmax function to get the attention weights, ensuring that the weights sum to one for each query. 4. Multiply the weights by the value matrix V to get the final output, which represents the weighted aggregation of the values. Hands-On Challenge: Building a Transformer-Based Model Objective: Construct a simple transformer-based model to solve a text classification problem. Dataset: Use the IMDb movie review dataset, which consists of labeled reviews for sentiment analysis (positive/negative). The dataset is well-suited for demonstrating the effectiveness of Transformers in capturing sentiment due to the complexity and variability of movie reviews. Steps: 1. Data Preprocessing: Tokenize the movie reviews and convert them to token IDs. You can use the Hugging Face Tokenizer for this step. The preprocessing should handle common tasks such as removing special characters, padding sequences to the same length, and truncating overly long reviews. 2. Model Architecture: Implement a simplified version of the Transformer encoder that takes token IDs as input and outputs a sentiment label. This model should consist of an embedding layer, a multi-head self-attention layer, and a feed-forward network. The model should be designed to capture the relationships between different words in a review, helping to understand the overall sentiment. 3. Training: Use the IMDb training dataset to train the model, optimizing for binary cross- entropy loss. During training, monitor metrics like accuracy and F1-score to ensure that the model is learning effectively. Use techniques such as'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'What are some potential applications of NLP in real-world industries, and how can researchers and practitioners collaborate to drive innovation?', 'type': 'subjective', 'difficulty': 'medium', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'medium'}], 'question_type': [{'value': 'code'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Write a Python function to implement the wordpiece tokenization technique used in BERT, given a list of words and a maximum sequence length.', 'type': 'code', 'difficulty': 'hard', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': \"How does the concept of 'understanding' in NLP differ from human understanding, and what are the implications for AI development?\", 'type': 'subjective', 'difficulty': 'medium', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Implement a simple sentiment analysis model using a Naive Bayes classifier and evaluate its performance on a given dataset.', 'type': 'code', 'difficulty': 'medium', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Discuss the trade-offs between using pre-trained language models versus training your own language model from scratch, and when each approach might be more suitable.', 'type': 'subjective', 'difficulty': 'hard', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Write a Python script to generate a list of synonyms for a given word using the WordNet lexical database.', 'type': 'code', 'difficulty': 'easy', 'text': 'equipped to contribute to cutting-edge research and practical applications in NLP, pushing the boundaries of what machines can understand and generate in human language.'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'What is the primary advantage of using the Transformer architecture over traditional Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks in Natural Language Processing (NLP)?', 'type': 'subjective', 'difficulty': 'medium', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Implement a basic Transformer model in Python using the PyTorch library, including the multi-head self-attention mechanism and feed-forward networks. The input sequence should be a list of words, and the output should be a list of predicted words.', 'type': 'code', 'difficulty': 'hard', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Explain the concept of positional encoding in the Transformer architecture and its purpose in capturing the position of each token in a sequence.', 'type': 'subjective', 'difficulty': 'easy', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Derive the formula for the self-attention mechanism in the Transformer model, including the query (Q), key (K), and value (V) vectors. Explain the mathematical operations involved in computing the weighted sum of the token representations.', 'type': 'code', 'difficulty': 'hard', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Compare and contrast the Transformer architecture with traditional sequence-to-sequence models, highlighting its strengths and weaknesses in capturing context and handling long-range dependencies.', 'type': 'subjective', 'difficulty': 'medium', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Write a Python function to calculate the attention scores for a given input sequence using the self-attention mechanism. The input sequence should be a list of vectors, and the output should be a 2D matrix of attention scores.', 'type': 'code', 'difficulty': 'medium', 'text': 'Natural Language Processing (NLP) is a rapidly evolving field, blending linguistics, artificial intelligence, and computer science. This book aims to provide an in-depth understanding of advanced NLP topics tailored for master-level students, helping them build a solid foundation while diving into practical applications. Throughout the chapters, you will encounter coding problems that challenge you to implement the concepts, ensuring both theoretical and hands-on learning. Chapter 1: Transformers and Self-Attention Mechanisms Overview of Transformer Architecture The Transformer architecture, introduced by Vaswani et al. in 2017, revolutionized the field of NLP by eliminating the need for recurrence, which was previously central to sequence modeling. Transformers leverage an attention mechanism to capture relationships between all tokens in a sequence, allowing for much greater parallelization and scalability compared to Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The architecture consists of an encoder-decoder structure, where both the encoder and decoder are composed of layers of self-attention and feed-forward networks. The encoder is responsible for understanding the input sequence, while the decoder generates the output sequence. Unlike traditional models, the Transformer uses self-attention to relate each word to every other word in the input sequence, making it highly effective in capturing context, both locally and globally. Key components of the Transformer include: 1. Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of a sequence simultaneously, capturing various contextual relationships. By using multiple heads, the model can attend to information from different representation subspaces, which improves the quality of the learned context. 2. Feed-Forward Networks: Each encoder and decoder layer includes a fully connected feed-forward network, applied independently to each position. These layers transform the attended information into a more abstract representation, contributing to the model’s ability to understand complex linguistic patterns. 3. Positional Encoding: Since Transformers do not have a sense of token order inherently, positional encoding is used to inject information about the position of each token in the sequence. The positional encoding is added to the input embeddings, allowing the model to distinguish between different positions in the input. The Transformer model is highly scalable and can handle much longer sequences compared to RNNs and LSTMs. This scalability, combined with its ability to parallelize computation, makes it suitable for training on large datasets, leading to powerful pre-trained language models like BERT, GPT, and T5. Self-Attention Mathematics The core of the Transformer model is the self-attention mechanism, which allows each token in a sequence to interact with every other token, effectively capturing dependencies regardless of their distance. This mechanism is particularly powerful because it provides a dynamic and context-aware representation for each token, allowing the model to adapt its focus based on the entire sequence. Consider a sequence of tokens represented by vectors: ο1, ο2, ..., οn. The self-attention mechanism computes a weighted sum of all the token representations to determine the output for each token. This involves three key vectors: • Query (Q): A vector representation that determines which part of the sequence to focus on. •'}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'medium'}], 'question_type': [{'value': 'code'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': \"What is the primary challenge associated with the Transformer model's self-attention mechanism, and how can it be mitigated?\", 'type': 'subjective', 'difficulty': 'medium', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Implement a simplified Transformer architecture in PyTorch to classify movie reviews as positive or negative. Provide a brief explanation of your implementation.', 'type': 'code', 'difficulty': 'hard', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'code'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'How does positional encoding address the lack of inherent order in the Transformer model, and what are some alternative techniques being explored?', 'type': 'subjective', 'difficulty': 'medium', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Compare and contrast the use of dropout and label smoothing as regularization techniques in Transformer-based models. Provide examples of when to use each.', 'type': 'subjective', 'difficulty': 'medium', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Design an experiment to evaluate the effectiveness of early stopping in a Transformer-based sentiment classifier. What metrics will you use to measure performance?', 'type': 'subjective', 'difficulty': 'hard', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n",
            "Record Text:\n",
            "{'question': 'Implement a sparse attention mechanism in a simplified Transformer architecture using PyTorch. Explain the benefits of this approach.', 'type': 'code', 'difficulty': 'hard', 'text': \"learning rate scheduling and early stopping to improve training stability. Problem: Building a Transformer-Based Sentiment Classifier Problem Statement: Build a sentiment classifier using a simplified Transformer architecture. The classifier should be able to predict whether a given movie review is positive or negative. Steps to Solve: 1. Embedding Layer: Initialize an embedding layer to convert input token IDs to vector representations. This layer will convert each token ID into a fixed-size vector that captures its semantic meaning. 2. Multi-Head Attention Layer: Implement a multi-head attention layer to capture relationships within the input sequence. This layer allows the model to attend to different parts of the input simultaneously, capturing complex dependencies. 3. Feed-Forward Layer: Apply a fully connected feed-forward layer to map the contextualized representations to the output classes (positive/negative). This layer will take the output from the attention layer and transform it into a form suitable for classification. 4. Output Layer: Use a softmax activation function to produce probabilities for the two sentiment classes, enabling the model to make predictions. 5. Training Strategy: Train the model using an appropriate optimizer like Adam, and use dropout to prevent overfitting. Split the data into training and validation sets to evaluate the model's generalization performance. Advanced Discussion: Challenges and Techniques The Transformer model, while powerful, has several challenges associated with it: • Computational Complexity: Self-attention requires computing scores between all token pairs, resulting in quadratic complexity with respect to the sequence length. This can be computationally expensive for long sequences. Techniques such as sparse attention and efficient Transformers (like Longformer and Reformer) have been proposed to mitigate this issue. • Positional Understanding: Unlike RNNs, Transformers lack an inherent sense of order. Although positional encoding addresses this to some extent, researchers are actively exploring other ways to improve the model's understanding of sequence order, such as relative positional encodings. • Overfitting and Generalization: Due to the large number of parameters, Transformers are prone to overfitting, especially when trained on small datasets. Regularization techniques, such as dropout and label smoothing, can help improve generalization. Applications Beyond Sentiment Analysis Transformers are not limited to sentiment analysis; they are used in a wide range of NLP tasks, including: • Machine Translation: Models like T5 and mBART use Transformer architectures to translate between languages with remarkable accuracy. • Text Summarization: The ability to attend to different parts of a document makes Transformers well-suited for extracting the most important information and generating coherent summaries. • Question Answering: Transformers form the backbone of models like BERT, which can understand context and provide precise answers to questions posed in natural language. Conclusion The Transformer architecture and self-attention mechanism are the foundation of most modern NLP models. Understanding how these components work, both mathematically and in implementation, will provide you with the tools necessary to tackle a wide range of NLP challenges. The hands-on exercises will help reinforce these concepts and prepare you for more complex tasks, such as building full-fledged language models or question-answering systems. By mastering Transformers, you will be\"}\n",
            "\n",
            "Responses:\n",
            "{'question_relevance': [{'value': 'yes'}], 'difficulty_level': [{'value': 'easy'}], 'question_type': [{'value': 'subjective'}]}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: move output folde to my goolge drve\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the source and destination paths\n",
        "source_folder = \"/content/output5\"  # Replace with the actual path to your output folder\n",
        "destination_folder = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks\"  # Replace with your desired destination in Google Drive\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Move the output folder to Google Drive\n",
        "try:\n",
        "    shutil.move(source_folder, destination_folder)\n",
        "    print(f\"Successfully moved '{source_folder}' to '{destination_folder}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Source folder '{source_folder}' not found.\")\n",
        "except OSError as e:\n",
        "    print(f\"An error occurred while moving the folder: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DhvixFylyf6",
        "outputId": "e1f93a7a-3bc4-4859-f544-6164a2b7ed50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Successfully moved '/content/output5' to '/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install json-repair\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1Hy2AbpNOaK",
        "outputId": "328d05a5-edd4-43fa-acc3-841e1b672e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: json-repair in /usr/local/lib/python3.11/dist-packages (0.36.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Code Repair and Merge"
      ],
      "metadata": {
        "id": "sA-mWQZvPu2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from json_repair import repair_json\n",
        "\n",
        "import json\n",
        "\n",
        "def fix_and_update_json(file_path):\n",
        "    \"\"\"\n",
        "    Reads a potentially malformed JSON file, attempts to repair it,\n",
        "    and updates the file with the corrected JSON content.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the file was successfully updated, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            raw_data = file.read()\n",
        "\n",
        "        # Repair the JSON\n",
        "        repaired_json = repair_json(raw_data)\n",
        "        json_data = json.loads(repaired_json)\n",
        "\n",
        "        # Write the repaired JSON back to the file\n",
        "        with open(file_path, 'w', encoding='utf-8') as file:\n",
        "            json.dump(json_data, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(f\"✅ JSON successfully repaired and updated: {file_path}\")\n",
        "        return True\n",
        "\n",
        "    except OSError as e:\n",
        "        print(f\"❌ File error: {e}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ JSON decoding failed: {e}\")\n",
        "\n",
        "    return False\n",
        "\n",
        "# Example usage\n",
        "file_path = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_7.txt\"\n",
        "success = fix_and_update_json(file_path)\n",
        "\n",
        "if success:\n",
        "    print(\"🎉 File successfully updated!\")\n",
        "else:\n",
        "    print(\"⚠️ Failed to update the file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTL-TcRgRR09",
        "outputId": "741771fb-91c6-43bd-b0b3-85cc5aec5aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_7.txt\n",
            "🎉 File successfully updated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Repairing JSON"
      ],
      "metadata": {
        "id": "x9kbVdW-SKU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from json_repair import repair_json\n",
        "\n",
        "import json\n",
        "\n",
        "def fix_and_update_json(file_path):\n",
        "    \"\"\"\n",
        "    Reads a potentially malformed JSON file, attempts to repair it,\n",
        "    and updates the file with the corrected JSON content.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the file was successfully updated, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            raw_data = file.read()\n",
        "\n",
        "        # Repair the JSON\n",
        "        repaired_json = repair_json(raw_data)\n",
        "        json_data = json.loads(repaired_json)\n",
        "\n",
        "        # Write the repaired JSON back to the file\n",
        "        with open(file_path, 'w', encoding='utf-8') as file:\n",
        "            json.dump(json_data, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(f\"✅ JSON successfully repaired and updated: {file_path}\")\n",
        "        return True\n",
        "\n",
        "    except OSError as e:\n",
        "        print(f\"❌ File error: {e}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ JSON decoding failed: {e}\")\n",
        "\n",
        "    return False\n",
        "\n",
        "def process_json_files(folder_path, start_index, end_index):\n",
        "    \"\"\"\n",
        "    Loops through files from start_index to end_index in a given folder,\n",
        "    repairing and updating each JSON file.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to the folder containing .txt files.\n",
        "        start_index (int): Start index for filenames.\n",
        "        end_index (int): End index for filenames.\n",
        "    \"\"\"\n",
        "    for i in range(start_index, end_index + 1):\n",
        "        file_name = f\"assignment_questions_chunk_{i}.txt\"\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"🔄 Processing: {file_name}\")\n",
        "            success = fix_and_update_json(file_path)\n",
        "\n",
        "            if success:\n",
        "                print(f\"🎉 Successfully updated {file_name}!\")\n",
        "            else:\n",
        "                print(f\"⚠️ Failed to update {file_name}.\")\n",
        "        else:\n",
        "            print(f\"⚠️ File not found: {file_name}\")\n",
        "\n",
        "# Example usage\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5\"\n",
        "START_INDEX = 0  # Change this based on your dataset\n",
        "END_INDEX = 288  # Provide the actual end index\n",
        "\n",
        "process_json_files(OUTPUT_DIR, START_INDEX, END_INDEX)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjK1B7orR-Dx",
        "outputId": "7af82125-891b-45bd-f485-2c8e51ab0cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing: assignment_questions_chunk_0.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_0.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_0.txt!\n",
            "🔄 Processing: assignment_questions_chunk_1.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_1.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_1.txt!\n",
            "🔄 Processing: assignment_questions_chunk_2.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_2.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_2.txt!\n",
            "🔄 Processing: assignment_questions_chunk_3.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_3.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_3.txt!\n",
            "🔄 Processing: assignment_questions_chunk_4.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_4.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_4.txt!\n",
            "🔄 Processing: assignment_questions_chunk_5.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_5.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_5.txt!\n",
            "🔄 Processing: assignment_questions_chunk_6.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_6.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_6.txt!\n",
            "🔄 Processing: assignment_questions_chunk_7.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_7.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_7.txt!\n",
            "🔄 Processing: assignment_questions_chunk_8.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_8.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_8.txt!\n",
            "🔄 Processing: assignment_questions_chunk_9.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_9.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_9.txt!\n",
            "🔄 Processing: assignment_questions_chunk_10.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_10.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_10.txt!\n",
            "🔄 Processing: assignment_questions_chunk_11.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_11.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_11.txt!\n",
            "🔄 Processing: assignment_questions_chunk_12.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_12.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_12.txt!\n",
            "🔄 Processing: assignment_questions_chunk_13.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_13.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_13.txt!\n",
            "🔄 Processing: assignment_questions_chunk_14.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_14.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_14.txt!\n",
            "🔄 Processing: assignment_questions_chunk_15.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_15.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_15.txt!\n",
            "🔄 Processing: assignment_questions_chunk_16.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_16.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_16.txt!\n",
            "🔄 Processing: assignment_questions_chunk_17.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_17.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_17.txt!\n",
            "🔄 Processing: assignment_questions_chunk_18.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_18.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_18.txt!\n",
            "🔄 Processing: assignment_questions_chunk_19.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_19.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_19.txt!\n",
            "🔄 Processing: assignment_questions_chunk_20.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_20.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_20.txt!\n",
            "🔄 Processing: assignment_questions_chunk_21.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_21.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_21.txt!\n",
            "🔄 Processing: assignment_questions_chunk_22.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_22.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_22.txt!\n",
            "🔄 Processing: assignment_questions_chunk_23.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_23.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_23.txt!\n",
            "🔄 Processing: assignment_questions_chunk_24.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_24.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_24.txt!\n",
            "🔄 Processing: assignment_questions_chunk_25.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_25.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_25.txt!\n",
            "🔄 Processing: assignment_questions_chunk_26.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_26.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_26.txt!\n",
            "🔄 Processing: assignment_questions_chunk_27.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_27.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_27.txt!\n",
            "🔄 Processing: assignment_questions_chunk_28.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_28.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_28.txt!\n",
            "🔄 Processing: assignment_questions_chunk_29.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_29.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_29.txt!\n",
            "🔄 Processing: assignment_questions_chunk_30.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_30.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_30.txt!\n",
            "🔄 Processing: assignment_questions_chunk_31.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_31.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_31.txt!\n",
            "🔄 Processing: assignment_questions_chunk_32.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_32.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_32.txt!\n",
            "🔄 Processing: assignment_questions_chunk_33.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_33.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_33.txt!\n",
            "🔄 Processing: assignment_questions_chunk_34.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_34.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_34.txt!\n",
            "🔄 Processing: assignment_questions_chunk_35.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_35.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_35.txt!\n",
            "🔄 Processing: assignment_questions_chunk_36.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_36.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_36.txt!\n",
            "🔄 Processing: assignment_questions_chunk_37.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_37.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_37.txt!\n",
            "🔄 Processing: assignment_questions_chunk_38.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_38.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_38.txt!\n",
            "🔄 Processing: assignment_questions_chunk_39.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_39.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_39.txt!\n",
            "🔄 Processing: assignment_questions_chunk_40.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_40.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_40.txt!\n",
            "🔄 Processing: assignment_questions_chunk_41.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_41.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_41.txt!\n",
            "🔄 Processing: assignment_questions_chunk_42.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_42.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_42.txt!\n",
            "🔄 Processing: assignment_questions_chunk_43.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_43.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_43.txt!\n",
            "🔄 Processing: assignment_questions_chunk_44.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_44.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_44.txt!\n",
            "🔄 Processing: assignment_questions_chunk_45.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_45.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_45.txt!\n",
            "🔄 Processing: assignment_questions_chunk_46.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_46.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_46.txt!\n",
            "🔄 Processing: assignment_questions_chunk_47.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_47.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_47.txt!\n",
            "🔄 Processing: assignment_questions_chunk_48.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_48.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_48.txt!\n",
            "🔄 Processing: assignment_questions_chunk_49.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_49.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_49.txt!\n",
            "🔄 Processing: assignment_questions_chunk_50.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_50.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_50.txt!\n",
            "🔄 Processing: assignment_questions_chunk_51.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_51.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_51.txt!\n",
            "🔄 Processing: assignment_questions_chunk_52.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_52.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_52.txt!\n",
            "🔄 Processing: assignment_questions_chunk_53.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_53.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_53.txt!\n",
            "🔄 Processing: assignment_questions_chunk_54.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_54.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_54.txt!\n",
            "🔄 Processing: assignment_questions_chunk_55.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_55.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_55.txt!\n",
            "🔄 Processing: assignment_questions_chunk_56.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_56.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_56.txt!\n",
            "🔄 Processing: assignment_questions_chunk_57.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_57.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_57.txt!\n",
            "🔄 Processing: assignment_questions_chunk_58.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_58.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_58.txt!\n",
            "🔄 Processing: assignment_questions_chunk_59.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_59.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_59.txt!\n",
            "🔄 Processing: assignment_questions_chunk_60.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_60.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_60.txt!\n",
            "🔄 Processing: assignment_questions_chunk_61.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_61.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_61.txt!\n",
            "🔄 Processing: assignment_questions_chunk_62.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_62.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_62.txt!\n",
            "🔄 Processing: assignment_questions_chunk_63.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_63.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_63.txt!\n",
            "🔄 Processing: assignment_questions_chunk_64.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_64.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_64.txt!\n",
            "🔄 Processing: assignment_questions_chunk_65.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_65.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_65.txt!\n",
            "🔄 Processing: assignment_questions_chunk_66.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_66.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_66.txt!\n",
            "🔄 Processing: assignment_questions_chunk_67.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_67.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_67.txt!\n",
            "🔄 Processing: assignment_questions_chunk_68.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_68.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_68.txt!\n",
            "🔄 Processing: assignment_questions_chunk_69.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_69.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_69.txt!\n",
            "🔄 Processing: assignment_questions_chunk_70.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_70.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_70.txt!\n",
            "🔄 Processing: assignment_questions_chunk_71.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_71.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_71.txt!\n",
            "🔄 Processing: assignment_questions_chunk_72.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_72.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_72.txt!\n",
            "🔄 Processing: assignment_questions_chunk_73.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_73.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_73.txt!\n",
            "🔄 Processing: assignment_questions_chunk_74.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_74.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_74.txt!\n",
            "🔄 Processing: assignment_questions_chunk_75.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_75.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_75.txt!\n",
            "🔄 Processing: assignment_questions_chunk_76.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_76.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_76.txt!\n",
            "🔄 Processing: assignment_questions_chunk_77.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_77.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_77.txt!\n",
            "🔄 Processing: assignment_questions_chunk_78.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_78.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_78.txt!\n",
            "🔄 Processing: assignment_questions_chunk_79.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_79.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_79.txt!\n",
            "🔄 Processing: assignment_questions_chunk_80.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_80.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_80.txt!\n",
            "🔄 Processing: assignment_questions_chunk_81.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_81.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_81.txt!\n",
            "🔄 Processing: assignment_questions_chunk_82.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_82.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_82.txt!\n",
            "🔄 Processing: assignment_questions_chunk_83.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_83.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_83.txt!\n",
            "🔄 Processing: assignment_questions_chunk_84.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_84.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_84.txt!\n",
            "🔄 Processing: assignment_questions_chunk_85.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_85.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_85.txt!\n",
            "🔄 Processing: assignment_questions_chunk_86.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_86.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_86.txt!\n",
            "🔄 Processing: assignment_questions_chunk_87.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_87.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_87.txt!\n",
            "🔄 Processing: assignment_questions_chunk_88.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_88.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_88.txt!\n",
            "🔄 Processing: assignment_questions_chunk_89.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_89.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_89.txt!\n",
            "🔄 Processing: assignment_questions_chunk_90.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_90.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_90.txt!\n",
            "🔄 Processing: assignment_questions_chunk_91.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_91.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_91.txt!\n",
            "🔄 Processing: assignment_questions_chunk_92.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_92.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_92.txt!\n",
            "🔄 Processing: assignment_questions_chunk_93.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_93.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_93.txt!\n",
            "🔄 Processing: assignment_questions_chunk_94.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_94.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_94.txt!\n",
            "🔄 Processing: assignment_questions_chunk_95.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_95.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_95.txt!\n",
            "🔄 Processing: assignment_questions_chunk_96.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_96.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_96.txt!\n",
            "🔄 Processing: assignment_questions_chunk_97.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_97.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_97.txt!\n",
            "🔄 Processing: assignment_questions_chunk_98.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_98.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_98.txt!\n",
            "🔄 Processing: assignment_questions_chunk_99.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_99.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_99.txt!\n",
            "🔄 Processing: assignment_questions_chunk_100.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_100.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_100.txt!\n",
            "🔄 Processing: assignment_questions_chunk_101.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_101.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_101.txt!\n",
            "🔄 Processing: assignment_questions_chunk_102.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_102.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_102.txt!\n",
            "🔄 Processing: assignment_questions_chunk_103.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_103.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_103.txt!\n",
            "🔄 Processing: assignment_questions_chunk_104.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_104.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_104.txt!\n",
            "🔄 Processing: assignment_questions_chunk_105.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_105.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_105.txt!\n",
            "🔄 Processing: assignment_questions_chunk_106.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_106.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_106.txt!\n",
            "🔄 Processing: assignment_questions_chunk_107.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_107.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_107.txt!\n",
            "🔄 Processing: assignment_questions_chunk_108.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_108.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_108.txt!\n",
            "🔄 Processing: assignment_questions_chunk_109.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_109.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_109.txt!\n",
            "🔄 Processing: assignment_questions_chunk_110.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_110.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_110.txt!\n",
            "🔄 Processing: assignment_questions_chunk_111.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_111.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_111.txt!\n",
            "🔄 Processing: assignment_questions_chunk_112.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_112.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_112.txt!\n",
            "🔄 Processing: assignment_questions_chunk_113.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_113.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_113.txt!\n",
            "🔄 Processing: assignment_questions_chunk_114.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_114.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_114.txt!\n",
            "🔄 Processing: assignment_questions_chunk_115.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_115.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_115.txt!\n",
            "🔄 Processing: assignment_questions_chunk_116.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_116.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_116.txt!\n",
            "🔄 Processing: assignment_questions_chunk_117.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_117.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_117.txt!\n",
            "🔄 Processing: assignment_questions_chunk_118.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_118.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_118.txt!\n",
            "🔄 Processing: assignment_questions_chunk_119.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_119.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_119.txt!\n",
            "🔄 Processing: assignment_questions_chunk_120.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_120.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_120.txt!\n",
            "🔄 Processing: assignment_questions_chunk_121.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_121.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_121.txt!\n",
            "🔄 Processing: assignment_questions_chunk_122.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_122.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_122.txt!\n",
            "🔄 Processing: assignment_questions_chunk_123.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_123.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_123.txt!\n",
            "🔄 Processing: assignment_questions_chunk_124.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_124.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_124.txt!\n",
            "🔄 Processing: assignment_questions_chunk_125.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_125.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_125.txt!\n",
            "🔄 Processing: assignment_questions_chunk_126.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_126.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_126.txt!\n",
            "🔄 Processing: assignment_questions_chunk_127.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_127.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_127.txt!\n",
            "🔄 Processing: assignment_questions_chunk_128.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_128.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_128.txt!\n",
            "🔄 Processing: assignment_questions_chunk_129.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_129.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_129.txt!\n",
            "🔄 Processing: assignment_questions_chunk_130.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_130.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_130.txt!\n",
            "🔄 Processing: assignment_questions_chunk_131.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_131.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_131.txt!\n",
            "🔄 Processing: assignment_questions_chunk_132.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_132.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_132.txt!\n",
            "🔄 Processing: assignment_questions_chunk_133.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_133.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_133.txt!\n",
            "🔄 Processing: assignment_questions_chunk_134.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_134.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_134.txt!\n",
            "🔄 Processing: assignment_questions_chunk_135.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_135.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_135.txt!\n",
            "🔄 Processing: assignment_questions_chunk_136.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_136.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_136.txt!\n",
            "🔄 Processing: assignment_questions_chunk_137.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_137.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_137.txt!\n",
            "🔄 Processing: assignment_questions_chunk_138.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_138.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_138.txt!\n",
            "🔄 Processing: assignment_questions_chunk_139.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_139.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_139.txt!\n",
            "🔄 Processing: assignment_questions_chunk_140.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_140.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_140.txt!\n",
            "🔄 Processing: assignment_questions_chunk_141.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_141.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_141.txt!\n",
            "🔄 Processing: assignment_questions_chunk_142.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_142.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_142.txt!\n",
            "🔄 Processing: assignment_questions_chunk_143.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_143.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_143.txt!\n",
            "🔄 Processing: assignment_questions_chunk_144.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_144.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_144.txt!\n",
            "🔄 Processing: assignment_questions_chunk_145.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_145.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_145.txt!\n",
            "🔄 Processing: assignment_questions_chunk_146.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_146.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_146.txt!\n",
            "🔄 Processing: assignment_questions_chunk_147.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_147.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_147.txt!\n",
            "🔄 Processing: assignment_questions_chunk_148.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_148.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_148.txt!\n",
            "🔄 Processing: assignment_questions_chunk_149.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_149.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_149.txt!\n",
            "🔄 Processing: assignment_questions_chunk_150.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_150.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_150.txt!\n",
            "🔄 Processing: assignment_questions_chunk_151.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_151.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_151.txt!\n",
            "🔄 Processing: assignment_questions_chunk_152.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_152.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_152.txt!\n",
            "🔄 Processing: assignment_questions_chunk_153.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_153.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_153.txt!\n",
            "🔄 Processing: assignment_questions_chunk_154.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_154.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_154.txt!\n",
            "🔄 Processing: assignment_questions_chunk_155.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_155.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_155.txt!\n",
            "🔄 Processing: assignment_questions_chunk_156.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_156.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_156.txt!\n",
            "🔄 Processing: assignment_questions_chunk_157.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_157.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_157.txt!\n",
            "🔄 Processing: assignment_questions_chunk_158.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_158.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_158.txt!\n",
            "🔄 Processing: assignment_questions_chunk_159.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_159.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_159.txt!\n",
            "🔄 Processing: assignment_questions_chunk_160.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_160.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_160.txt!\n",
            "🔄 Processing: assignment_questions_chunk_161.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_161.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_161.txt!\n",
            "🔄 Processing: assignment_questions_chunk_162.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_162.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_162.txt!\n",
            "🔄 Processing: assignment_questions_chunk_163.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_163.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_163.txt!\n",
            "🔄 Processing: assignment_questions_chunk_164.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_164.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_164.txt!\n",
            "🔄 Processing: assignment_questions_chunk_165.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_165.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_165.txt!\n",
            "🔄 Processing: assignment_questions_chunk_166.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_166.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_166.txt!\n",
            "🔄 Processing: assignment_questions_chunk_167.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_167.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_167.txt!\n",
            "🔄 Processing: assignment_questions_chunk_168.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_168.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_168.txt!\n",
            "🔄 Processing: assignment_questions_chunk_169.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_169.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_169.txt!\n",
            "🔄 Processing: assignment_questions_chunk_170.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_170.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_170.txt!\n",
            "🔄 Processing: assignment_questions_chunk_171.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_171.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_171.txt!\n",
            "🔄 Processing: assignment_questions_chunk_172.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_172.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_172.txt!\n",
            "🔄 Processing: assignment_questions_chunk_173.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_173.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_173.txt!\n",
            "🔄 Processing: assignment_questions_chunk_174.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_174.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_174.txt!\n",
            "🔄 Processing: assignment_questions_chunk_175.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_175.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_175.txt!\n",
            "🔄 Processing: assignment_questions_chunk_176.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_176.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_176.txt!\n",
            "🔄 Processing: assignment_questions_chunk_177.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_177.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_177.txt!\n",
            "🔄 Processing: assignment_questions_chunk_178.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_178.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_178.txt!\n",
            "🔄 Processing: assignment_questions_chunk_179.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_179.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_179.txt!\n",
            "🔄 Processing: assignment_questions_chunk_180.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_180.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_180.txt!\n",
            "🔄 Processing: assignment_questions_chunk_181.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_181.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_181.txt!\n",
            "🔄 Processing: assignment_questions_chunk_182.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_182.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_182.txt!\n",
            "🔄 Processing: assignment_questions_chunk_183.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_183.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_183.txt!\n",
            "🔄 Processing: assignment_questions_chunk_184.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_184.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_184.txt!\n",
            "🔄 Processing: assignment_questions_chunk_185.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_185.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_185.txt!\n",
            "🔄 Processing: assignment_questions_chunk_186.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_186.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_186.txt!\n",
            "🔄 Processing: assignment_questions_chunk_187.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_187.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_187.txt!\n",
            "🔄 Processing: assignment_questions_chunk_188.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_188.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_188.txt!\n",
            "🔄 Processing: assignment_questions_chunk_189.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_189.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_189.txt!\n",
            "🔄 Processing: assignment_questions_chunk_190.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_190.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_190.txt!\n",
            "🔄 Processing: assignment_questions_chunk_191.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_191.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_191.txt!\n",
            "🔄 Processing: assignment_questions_chunk_192.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_192.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_192.txt!\n",
            "🔄 Processing: assignment_questions_chunk_193.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_193.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_193.txt!\n",
            "🔄 Processing: assignment_questions_chunk_194.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_194.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_194.txt!\n",
            "🔄 Processing: assignment_questions_chunk_195.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_195.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_195.txt!\n",
            "🔄 Processing: assignment_questions_chunk_196.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_196.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_196.txt!\n",
            "🔄 Processing: assignment_questions_chunk_197.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_197.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_197.txt!\n",
            "🔄 Processing: assignment_questions_chunk_198.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_198.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_198.txt!\n",
            "🔄 Processing: assignment_questions_chunk_199.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_199.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_199.txt!\n",
            "🔄 Processing: assignment_questions_chunk_200.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_200.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_200.txt!\n",
            "🔄 Processing: assignment_questions_chunk_201.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_201.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_201.txt!\n",
            "🔄 Processing: assignment_questions_chunk_202.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_202.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_202.txt!\n",
            "🔄 Processing: assignment_questions_chunk_203.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_203.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_203.txt!\n",
            "🔄 Processing: assignment_questions_chunk_204.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_204.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_204.txt!\n",
            "🔄 Processing: assignment_questions_chunk_205.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_205.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_205.txt!\n",
            "🔄 Processing: assignment_questions_chunk_206.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_206.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_206.txt!\n",
            "🔄 Processing: assignment_questions_chunk_207.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_207.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_207.txt!\n",
            "🔄 Processing: assignment_questions_chunk_208.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_208.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_208.txt!\n",
            "🔄 Processing: assignment_questions_chunk_209.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_209.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_209.txt!\n",
            "🔄 Processing: assignment_questions_chunk_210.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_210.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_210.txt!\n",
            "🔄 Processing: assignment_questions_chunk_211.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_211.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_211.txt!\n",
            "🔄 Processing: assignment_questions_chunk_212.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_212.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_212.txt!\n",
            "🔄 Processing: assignment_questions_chunk_213.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_213.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_213.txt!\n",
            "🔄 Processing: assignment_questions_chunk_214.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_214.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_214.txt!\n",
            "🔄 Processing: assignment_questions_chunk_215.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_215.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_215.txt!\n",
            "🔄 Processing: assignment_questions_chunk_216.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_216.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_216.txt!\n",
            "🔄 Processing: assignment_questions_chunk_217.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_217.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_217.txt!\n",
            "🔄 Processing: assignment_questions_chunk_218.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_218.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_218.txt!\n",
            "🔄 Processing: assignment_questions_chunk_219.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_219.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_219.txt!\n",
            "🔄 Processing: assignment_questions_chunk_220.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_220.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_220.txt!\n",
            "🔄 Processing: assignment_questions_chunk_221.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_221.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_221.txt!\n",
            "🔄 Processing: assignment_questions_chunk_222.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_222.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_222.txt!\n",
            "🔄 Processing: assignment_questions_chunk_223.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_223.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_223.txt!\n",
            "🔄 Processing: assignment_questions_chunk_224.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_224.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_224.txt!\n",
            "🔄 Processing: assignment_questions_chunk_225.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_225.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_225.txt!\n",
            "🔄 Processing: assignment_questions_chunk_226.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_226.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_226.txt!\n",
            "🔄 Processing: assignment_questions_chunk_227.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_227.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_227.txt!\n",
            "🔄 Processing: assignment_questions_chunk_228.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_228.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_228.txt!\n",
            "🔄 Processing: assignment_questions_chunk_229.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_229.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_229.txt!\n",
            "🔄 Processing: assignment_questions_chunk_230.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_230.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_230.txt!\n",
            "🔄 Processing: assignment_questions_chunk_231.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_231.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_231.txt!\n",
            "🔄 Processing: assignment_questions_chunk_232.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_232.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_232.txt!\n",
            "🔄 Processing: assignment_questions_chunk_233.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_233.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_233.txt!\n",
            "🔄 Processing: assignment_questions_chunk_234.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_234.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_234.txt!\n",
            "🔄 Processing: assignment_questions_chunk_235.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_235.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_235.txt!\n",
            "🔄 Processing: assignment_questions_chunk_236.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_236.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_236.txt!\n",
            "🔄 Processing: assignment_questions_chunk_237.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_237.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_237.txt!\n",
            "🔄 Processing: assignment_questions_chunk_238.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_238.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_238.txt!\n",
            "🔄 Processing: assignment_questions_chunk_239.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_239.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_239.txt!\n",
            "🔄 Processing: assignment_questions_chunk_240.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_240.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_240.txt!\n",
            "🔄 Processing: assignment_questions_chunk_241.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_241.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_241.txt!\n",
            "🔄 Processing: assignment_questions_chunk_242.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_242.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_242.txt!\n",
            "🔄 Processing: assignment_questions_chunk_243.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_243.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_243.txt!\n",
            "🔄 Processing: assignment_questions_chunk_244.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_244.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_244.txt!\n",
            "🔄 Processing: assignment_questions_chunk_245.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_245.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_245.txt!\n",
            "🔄 Processing: assignment_questions_chunk_246.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_246.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_246.txt!\n",
            "🔄 Processing: assignment_questions_chunk_247.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_247.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_247.txt!\n",
            "🔄 Processing: assignment_questions_chunk_248.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_248.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_248.txt!\n",
            "🔄 Processing: assignment_questions_chunk_249.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_249.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_249.txt!\n",
            "🔄 Processing: assignment_questions_chunk_250.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_250.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_250.txt!\n",
            "🔄 Processing: assignment_questions_chunk_251.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_251.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_251.txt!\n",
            "🔄 Processing: assignment_questions_chunk_252.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_252.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_252.txt!\n",
            "🔄 Processing: assignment_questions_chunk_253.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_253.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_253.txt!\n",
            "🔄 Processing: assignment_questions_chunk_254.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_254.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_254.txt!\n",
            "🔄 Processing: assignment_questions_chunk_255.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_255.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_255.txt!\n",
            "🔄 Processing: assignment_questions_chunk_256.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_256.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_256.txt!\n",
            "🔄 Processing: assignment_questions_chunk_257.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_257.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_257.txt!\n",
            "🔄 Processing: assignment_questions_chunk_258.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_258.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_258.txt!\n",
            "🔄 Processing: assignment_questions_chunk_259.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_259.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_259.txt!\n",
            "🔄 Processing: assignment_questions_chunk_260.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_260.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_260.txt!\n",
            "🔄 Processing: assignment_questions_chunk_261.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_261.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_261.txt!\n",
            "🔄 Processing: assignment_questions_chunk_262.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_262.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_262.txt!\n",
            "🔄 Processing: assignment_questions_chunk_263.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_263.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_263.txt!\n",
            "🔄 Processing: assignment_questions_chunk_264.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_264.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_264.txt!\n",
            "🔄 Processing: assignment_questions_chunk_265.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_265.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_265.txt!\n",
            "🔄 Processing: assignment_questions_chunk_266.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_266.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_266.txt!\n",
            "🔄 Processing: assignment_questions_chunk_267.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_267.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_267.txt!\n",
            "🔄 Processing: assignment_questions_chunk_268.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_268.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_268.txt!\n",
            "🔄 Processing: assignment_questions_chunk_269.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_269.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_269.txt!\n",
            "🔄 Processing: assignment_questions_chunk_270.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_270.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_270.txt!\n",
            "🔄 Processing: assignment_questions_chunk_271.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_271.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_271.txt!\n",
            "🔄 Processing: assignment_questions_chunk_272.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_272.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_272.txt!\n",
            "🔄 Processing: assignment_questions_chunk_273.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_273.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_273.txt!\n",
            "🔄 Processing: assignment_questions_chunk_274.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_274.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_274.txt!\n",
            "🔄 Processing: assignment_questions_chunk_275.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_275.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_275.txt!\n",
            "🔄 Processing: assignment_questions_chunk_276.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_276.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_276.txt!\n",
            "🔄 Processing: assignment_questions_chunk_277.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_277.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_277.txt!\n",
            "🔄 Processing: assignment_questions_chunk_278.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_278.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_278.txt!\n",
            "🔄 Processing: assignment_questions_chunk_279.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_279.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_279.txt!\n",
            "🔄 Processing: assignment_questions_chunk_280.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_280.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_280.txt!\n",
            "🔄 Processing: assignment_questions_chunk_281.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_281.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_281.txt!\n",
            "🔄 Processing: assignment_questions_chunk_282.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_282.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_282.txt!\n",
            "🔄 Processing: assignment_questions_chunk_283.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_283.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_283.txt!\n",
            "🔄 Processing: assignment_questions_chunk_284.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_284.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_284.txt!\n",
            "🔄 Processing: assignment_questions_chunk_285.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_285.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_285.txt!\n",
            "🔄 Processing: assignment_questions_chunk_286.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_286.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_286.txt!\n",
            "🔄 Processing: assignment_questions_chunk_287.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_287.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_287.txt!\n",
            "🔄 Processing: assignment_questions_chunk_288.txt\n",
            "✅ JSON successfully repaired and updated: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5/assignment_questions_chunk_288.txt\n",
            "🎉 Successfully updated assignment_questions_chunk_288.txt!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Take Chunks Questions Repaire JSON and Merge them"
      ],
      "metadata": {
        "id": "jmUkyaBcQkeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from json_repair import repair_json\n",
        "\n",
        "# Define base folder and filename format\n",
        "FOLDER_PATH = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5\"\n",
        "FILE_PREFIX = \"assignment_questions_chunk_\"\n",
        "\n",
        "text_chunks = extract_text_from_pdf(PDF_PATH, CHUNK_SIZE)\n",
        "\n",
        "# Function to flatten JSON\n",
        "def flatten_json(nested_json, prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Recursively flattens a nested JSON object.\n",
        "    Example: {\"metadata\": {\"difficulty\": \"easy\"}} → {\"metadata.difficulty\": \"easy\"}\n",
        "\n",
        "    Args:\n",
        "        nested_json (dict): JSON object to flatten.\n",
        "        prefix (str): Prefix for keys during recursion.\n",
        "\n",
        "    Returns:\n",
        "        dict: Flattened JSON object.\n",
        "    \"\"\"\n",
        "    flattened_dict = {}\n",
        "    if isinstance(nested_json, dict):\n",
        "        for key, value in nested_json.items():\n",
        "            new_key = f\"{prefix}{key}\" if prefix else key  # Add prefix if nested\n",
        "            if isinstance(value, dict):  # If it's a dictionary, recurse\n",
        "                flattened_dict.update(flatten_json(value, new_key + \".\"))\n",
        "            elif isinstance(value, list) and all(isinstance(i, dict) for i in value):\n",
        "                # If it's a list of dicts, flatten each item\n",
        "                for idx, item in enumerate(value):\n",
        "                    flattened_dict.update(flatten_json(item, f\"{new_key}[{idx}].\"))\n",
        "            else:\n",
        "                flattened_dict[new_key] = value\n",
        "    return flattened_dict\n",
        "\n",
        "# Function to load and repair JSON files if necessary\n",
        "def load_json_file(file_path):\n",
        "    \"\"\"\n",
        "    Reads a JSON file, attempts to repair it if malformed.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        list/dict: Parsed JSON object, or None if repair fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            raw_data = file.read().strip()  # Remove unnecessary block markers\n",
        "            try:\n",
        "                return json.loads(raw_data)  # Normal JSON parsing\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"🔄 Repairing corrupted JSON: {file_path}...\")\n",
        "                repaired_data = repair_json(raw_data)  # Attempt to repair\n",
        "                return json.loads(repaired_data)  # Load repaired JSON\n",
        "    except (OSError, json.JSONDecodeError) as e:\n",
        "        print(f\"❌ Skipping {file_path} due to error: {e}\")\n",
        "        return None  # Skip files that cannot be read\n",
        "\n",
        "# List to store all flattened JSON objects\n",
        "merged_flattened_data = []\n",
        "\n",
        "# Loop through files from 0 to 288\n",
        "for i in range(289):  # 0 to 288\n",
        "    file_name = f\"{FILE_PREFIX}{i}.txt\"\n",
        "    file_path = os.path.join(FOLDER_PATH, file_name)\n",
        "\n",
        "    if os.path.exists(file_path):  # Check if file exists\n",
        "        print(f\"📂 Processing: {file_name}\")\n",
        "        data = load_json_file(file_path)\n",
        "\n",
        "        if data is None:  # Skip if file is unreadable\n",
        "            continue\n",
        "\n",
        "        # Flatten and store the JSON data\n",
        "        if isinstance(data, list):\n",
        "            for item in data:\n",
        "                if isinstance(item, dict):  # Ensure valid structure\n",
        "                    merged_flattened_data.append(flatten_json(item))\n",
        "        elif isinstance(data, dict):\n",
        "            merged_flattened_data.append(flatten_json(data))\n",
        "        else:\n",
        "            print(f\"⚠️ Unexpected JSON format in {file_name}, skipping.\")\n",
        "\n",
        "# Save the combined and flattened JSON output\n",
        "output_file = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/merged_flattened_questions.json\"\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
        "    json.dump(merged_flattened_data, file, indent=4)\n",
        "\n",
        "# Print final output\n",
        "print(f\"✅ Merged and flattened JSON saved to: {output_file}\")\n",
        "print(json.dumps(merged_flattened_data[:5], indent=4))  # Print first 5 results for verification\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkSiGwjROeeI",
        "outputId": "c75ba644-8dca-47b5-ac96-b18a3b93fb4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Processing: assignment_questions_chunk_0.txt\n",
            "📂 Processing: assignment_questions_chunk_1.txt\n",
            "📂 Processing: assignment_questions_chunk_2.txt\n",
            "📂 Processing: assignment_questions_chunk_3.txt\n",
            "📂 Processing: assignment_questions_chunk_4.txt\n",
            "📂 Processing: assignment_questions_chunk_5.txt\n",
            "📂 Processing: assignment_questions_chunk_6.txt\n",
            "📂 Processing: assignment_questions_chunk_7.txt\n",
            "📂 Processing: assignment_questions_chunk_8.txt\n",
            "📂 Processing: assignment_questions_chunk_9.txt\n",
            "📂 Processing: assignment_questions_chunk_10.txt\n",
            "📂 Processing: assignment_questions_chunk_11.txt\n",
            "📂 Processing: assignment_questions_chunk_12.txt\n",
            "📂 Processing: assignment_questions_chunk_13.txt\n",
            "📂 Processing: assignment_questions_chunk_14.txt\n",
            "📂 Processing: assignment_questions_chunk_15.txt\n",
            "📂 Processing: assignment_questions_chunk_16.txt\n",
            "📂 Processing: assignment_questions_chunk_17.txt\n",
            "📂 Processing: assignment_questions_chunk_18.txt\n",
            "📂 Processing: assignment_questions_chunk_19.txt\n",
            "📂 Processing: assignment_questions_chunk_20.txt\n",
            "📂 Processing: assignment_questions_chunk_21.txt\n",
            "📂 Processing: assignment_questions_chunk_22.txt\n",
            "📂 Processing: assignment_questions_chunk_23.txt\n",
            "📂 Processing: assignment_questions_chunk_24.txt\n",
            "📂 Processing: assignment_questions_chunk_25.txt\n",
            "📂 Processing: assignment_questions_chunk_26.txt\n",
            "📂 Processing: assignment_questions_chunk_27.txt\n",
            "📂 Processing: assignment_questions_chunk_28.txt\n",
            "📂 Processing: assignment_questions_chunk_29.txt\n",
            "📂 Processing: assignment_questions_chunk_30.txt\n",
            "📂 Processing: assignment_questions_chunk_31.txt\n",
            "📂 Processing: assignment_questions_chunk_32.txt\n",
            "📂 Processing: assignment_questions_chunk_33.txt\n",
            "📂 Processing: assignment_questions_chunk_34.txt\n",
            "📂 Processing: assignment_questions_chunk_35.txt\n",
            "📂 Processing: assignment_questions_chunk_36.txt\n",
            "📂 Processing: assignment_questions_chunk_37.txt\n",
            "📂 Processing: assignment_questions_chunk_38.txt\n",
            "📂 Processing: assignment_questions_chunk_39.txt\n",
            "📂 Processing: assignment_questions_chunk_40.txt\n",
            "📂 Processing: assignment_questions_chunk_41.txt\n",
            "📂 Processing: assignment_questions_chunk_42.txt\n",
            "📂 Processing: assignment_questions_chunk_43.txt\n",
            "📂 Processing: assignment_questions_chunk_44.txt\n",
            "📂 Processing: assignment_questions_chunk_45.txt\n",
            "📂 Processing: assignment_questions_chunk_46.txt\n",
            "📂 Processing: assignment_questions_chunk_47.txt\n",
            "📂 Processing: assignment_questions_chunk_48.txt\n",
            "📂 Processing: assignment_questions_chunk_49.txt\n",
            "📂 Processing: assignment_questions_chunk_50.txt\n",
            "📂 Processing: assignment_questions_chunk_51.txt\n",
            "📂 Processing: assignment_questions_chunk_52.txt\n",
            "📂 Processing: assignment_questions_chunk_53.txt\n",
            "📂 Processing: assignment_questions_chunk_54.txt\n",
            "📂 Processing: assignment_questions_chunk_55.txt\n",
            "📂 Processing: assignment_questions_chunk_56.txt\n",
            "📂 Processing: assignment_questions_chunk_57.txt\n",
            "📂 Processing: assignment_questions_chunk_58.txt\n",
            "📂 Processing: assignment_questions_chunk_59.txt\n",
            "📂 Processing: assignment_questions_chunk_60.txt\n",
            "📂 Processing: assignment_questions_chunk_61.txt\n",
            "📂 Processing: assignment_questions_chunk_62.txt\n",
            "📂 Processing: assignment_questions_chunk_63.txt\n",
            "📂 Processing: assignment_questions_chunk_64.txt\n",
            "📂 Processing: assignment_questions_chunk_65.txt\n",
            "📂 Processing: assignment_questions_chunk_66.txt\n",
            "📂 Processing: assignment_questions_chunk_67.txt\n",
            "📂 Processing: assignment_questions_chunk_68.txt\n",
            "📂 Processing: assignment_questions_chunk_69.txt\n",
            "📂 Processing: assignment_questions_chunk_70.txt\n",
            "📂 Processing: assignment_questions_chunk_71.txt\n",
            "📂 Processing: assignment_questions_chunk_72.txt\n",
            "📂 Processing: assignment_questions_chunk_73.txt\n",
            "📂 Processing: assignment_questions_chunk_74.txt\n",
            "📂 Processing: assignment_questions_chunk_75.txt\n",
            "📂 Processing: assignment_questions_chunk_76.txt\n",
            "📂 Processing: assignment_questions_chunk_77.txt\n",
            "📂 Processing: assignment_questions_chunk_78.txt\n",
            "📂 Processing: assignment_questions_chunk_79.txt\n",
            "📂 Processing: assignment_questions_chunk_80.txt\n",
            "📂 Processing: assignment_questions_chunk_81.txt\n",
            "📂 Processing: assignment_questions_chunk_82.txt\n",
            "📂 Processing: assignment_questions_chunk_83.txt\n",
            "📂 Processing: assignment_questions_chunk_84.txt\n",
            "📂 Processing: assignment_questions_chunk_85.txt\n",
            "📂 Processing: assignment_questions_chunk_86.txt\n",
            "📂 Processing: assignment_questions_chunk_87.txt\n",
            "📂 Processing: assignment_questions_chunk_88.txt\n",
            "📂 Processing: assignment_questions_chunk_89.txt\n",
            "📂 Processing: assignment_questions_chunk_90.txt\n",
            "📂 Processing: assignment_questions_chunk_91.txt\n",
            "📂 Processing: assignment_questions_chunk_92.txt\n",
            "📂 Processing: assignment_questions_chunk_93.txt\n",
            "📂 Processing: assignment_questions_chunk_94.txt\n",
            "📂 Processing: assignment_questions_chunk_95.txt\n",
            "📂 Processing: assignment_questions_chunk_96.txt\n",
            "📂 Processing: assignment_questions_chunk_97.txt\n",
            "📂 Processing: assignment_questions_chunk_98.txt\n",
            "📂 Processing: assignment_questions_chunk_99.txt\n",
            "📂 Processing: assignment_questions_chunk_100.txt\n",
            "📂 Processing: assignment_questions_chunk_101.txt\n",
            "📂 Processing: assignment_questions_chunk_102.txt\n",
            "📂 Processing: assignment_questions_chunk_103.txt\n",
            "📂 Processing: assignment_questions_chunk_104.txt\n",
            "📂 Processing: assignment_questions_chunk_105.txt\n",
            "📂 Processing: assignment_questions_chunk_106.txt\n",
            "📂 Processing: assignment_questions_chunk_107.txt\n",
            "📂 Processing: assignment_questions_chunk_108.txt\n",
            "📂 Processing: assignment_questions_chunk_109.txt\n",
            "📂 Processing: assignment_questions_chunk_110.txt\n",
            "📂 Processing: assignment_questions_chunk_111.txt\n",
            "📂 Processing: assignment_questions_chunk_112.txt\n",
            "📂 Processing: assignment_questions_chunk_113.txt\n",
            "📂 Processing: assignment_questions_chunk_114.txt\n",
            "📂 Processing: assignment_questions_chunk_115.txt\n",
            "📂 Processing: assignment_questions_chunk_116.txt\n",
            "📂 Processing: assignment_questions_chunk_117.txt\n",
            "📂 Processing: assignment_questions_chunk_118.txt\n",
            "📂 Processing: assignment_questions_chunk_119.txt\n",
            "📂 Processing: assignment_questions_chunk_120.txt\n",
            "📂 Processing: assignment_questions_chunk_121.txt\n",
            "📂 Processing: assignment_questions_chunk_122.txt\n",
            "📂 Processing: assignment_questions_chunk_123.txt\n",
            "📂 Processing: assignment_questions_chunk_124.txt\n",
            "📂 Processing: assignment_questions_chunk_125.txt\n",
            "📂 Processing: assignment_questions_chunk_126.txt\n",
            "📂 Processing: assignment_questions_chunk_127.txt\n",
            "📂 Processing: assignment_questions_chunk_128.txt\n",
            "📂 Processing: assignment_questions_chunk_129.txt\n",
            "📂 Processing: assignment_questions_chunk_130.txt\n",
            "📂 Processing: assignment_questions_chunk_131.txt\n",
            "📂 Processing: assignment_questions_chunk_132.txt\n",
            "📂 Processing: assignment_questions_chunk_133.txt\n",
            "📂 Processing: assignment_questions_chunk_134.txt\n",
            "📂 Processing: assignment_questions_chunk_135.txt\n",
            "📂 Processing: assignment_questions_chunk_136.txt\n",
            "📂 Processing: assignment_questions_chunk_137.txt\n",
            "📂 Processing: assignment_questions_chunk_138.txt\n",
            "📂 Processing: assignment_questions_chunk_139.txt\n",
            "📂 Processing: assignment_questions_chunk_140.txt\n",
            "📂 Processing: assignment_questions_chunk_141.txt\n",
            "📂 Processing: assignment_questions_chunk_142.txt\n",
            "📂 Processing: assignment_questions_chunk_143.txt\n",
            "📂 Processing: assignment_questions_chunk_144.txt\n",
            "📂 Processing: assignment_questions_chunk_145.txt\n",
            "📂 Processing: assignment_questions_chunk_146.txt\n",
            "📂 Processing: assignment_questions_chunk_147.txt\n",
            "📂 Processing: assignment_questions_chunk_148.txt\n",
            "📂 Processing: assignment_questions_chunk_149.txt\n",
            "📂 Processing: assignment_questions_chunk_150.txt\n",
            "📂 Processing: assignment_questions_chunk_151.txt\n",
            "📂 Processing: assignment_questions_chunk_152.txt\n",
            "📂 Processing: assignment_questions_chunk_153.txt\n",
            "📂 Processing: assignment_questions_chunk_154.txt\n",
            "📂 Processing: assignment_questions_chunk_155.txt\n",
            "📂 Processing: assignment_questions_chunk_156.txt\n",
            "📂 Processing: assignment_questions_chunk_157.txt\n",
            "📂 Processing: assignment_questions_chunk_158.txt\n",
            "📂 Processing: assignment_questions_chunk_159.txt\n",
            "📂 Processing: assignment_questions_chunk_160.txt\n",
            "📂 Processing: assignment_questions_chunk_161.txt\n",
            "📂 Processing: assignment_questions_chunk_162.txt\n",
            "📂 Processing: assignment_questions_chunk_163.txt\n",
            "📂 Processing: assignment_questions_chunk_164.txt\n",
            "📂 Processing: assignment_questions_chunk_165.txt\n",
            "📂 Processing: assignment_questions_chunk_166.txt\n",
            "📂 Processing: assignment_questions_chunk_167.txt\n",
            "📂 Processing: assignment_questions_chunk_168.txt\n",
            "📂 Processing: assignment_questions_chunk_169.txt\n",
            "📂 Processing: assignment_questions_chunk_170.txt\n",
            "📂 Processing: assignment_questions_chunk_171.txt\n",
            "📂 Processing: assignment_questions_chunk_172.txt\n",
            "📂 Processing: assignment_questions_chunk_173.txt\n",
            "📂 Processing: assignment_questions_chunk_174.txt\n",
            "📂 Processing: assignment_questions_chunk_175.txt\n",
            "📂 Processing: assignment_questions_chunk_176.txt\n",
            "📂 Processing: assignment_questions_chunk_177.txt\n",
            "📂 Processing: assignment_questions_chunk_178.txt\n",
            "📂 Processing: assignment_questions_chunk_179.txt\n",
            "📂 Processing: assignment_questions_chunk_180.txt\n",
            "📂 Processing: assignment_questions_chunk_181.txt\n",
            "📂 Processing: assignment_questions_chunk_182.txt\n",
            "📂 Processing: assignment_questions_chunk_183.txt\n",
            "📂 Processing: assignment_questions_chunk_184.txt\n",
            "📂 Processing: assignment_questions_chunk_185.txt\n",
            "📂 Processing: assignment_questions_chunk_186.txt\n",
            "📂 Processing: assignment_questions_chunk_187.txt\n",
            "📂 Processing: assignment_questions_chunk_188.txt\n",
            "📂 Processing: assignment_questions_chunk_189.txt\n",
            "📂 Processing: assignment_questions_chunk_190.txt\n",
            "📂 Processing: assignment_questions_chunk_191.txt\n",
            "📂 Processing: assignment_questions_chunk_192.txt\n",
            "📂 Processing: assignment_questions_chunk_193.txt\n",
            "📂 Processing: assignment_questions_chunk_194.txt\n",
            "📂 Processing: assignment_questions_chunk_195.txt\n",
            "📂 Processing: assignment_questions_chunk_196.txt\n",
            "📂 Processing: assignment_questions_chunk_197.txt\n",
            "📂 Processing: assignment_questions_chunk_198.txt\n",
            "📂 Processing: assignment_questions_chunk_199.txt\n",
            "📂 Processing: assignment_questions_chunk_200.txt\n",
            "📂 Processing: assignment_questions_chunk_201.txt\n",
            "📂 Processing: assignment_questions_chunk_202.txt\n",
            "📂 Processing: assignment_questions_chunk_203.txt\n",
            "📂 Processing: assignment_questions_chunk_204.txt\n",
            "📂 Processing: assignment_questions_chunk_205.txt\n",
            "📂 Processing: assignment_questions_chunk_206.txt\n",
            "📂 Processing: assignment_questions_chunk_207.txt\n",
            "📂 Processing: assignment_questions_chunk_208.txt\n",
            "📂 Processing: assignment_questions_chunk_209.txt\n",
            "📂 Processing: assignment_questions_chunk_210.txt\n",
            "📂 Processing: assignment_questions_chunk_211.txt\n",
            "📂 Processing: assignment_questions_chunk_212.txt\n",
            "📂 Processing: assignment_questions_chunk_213.txt\n",
            "📂 Processing: assignment_questions_chunk_214.txt\n",
            "📂 Processing: assignment_questions_chunk_215.txt\n",
            "📂 Processing: assignment_questions_chunk_216.txt\n",
            "📂 Processing: assignment_questions_chunk_217.txt\n",
            "📂 Processing: assignment_questions_chunk_218.txt\n",
            "📂 Processing: assignment_questions_chunk_219.txt\n",
            "📂 Processing: assignment_questions_chunk_220.txt\n",
            "📂 Processing: assignment_questions_chunk_221.txt\n",
            "📂 Processing: assignment_questions_chunk_222.txt\n",
            "📂 Processing: assignment_questions_chunk_223.txt\n",
            "📂 Processing: assignment_questions_chunk_224.txt\n",
            "📂 Processing: assignment_questions_chunk_225.txt\n",
            "📂 Processing: assignment_questions_chunk_226.txt\n",
            "📂 Processing: assignment_questions_chunk_227.txt\n",
            "📂 Processing: assignment_questions_chunk_228.txt\n",
            "📂 Processing: assignment_questions_chunk_229.txt\n",
            "📂 Processing: assignment_questions_chunk_230.txt\n",
            "📂 Processing: assignment_questions_chunk_231.txt\n",
            "📂 Processing: assignment_questions_chunk_232.txt\n",
            "📂 Processing: assignment_questions_chunk_233.txt\n",
            "📂 Processing: assignment_questions_chunk_234.txt\n",
            "📂 Processing: assignment_questions_chunk_235.txt\n",
            "📂 Processing: assignment_questions_chunk_236.txt\n",
            "📂 Processing: assignment_questions_chunk_237.txt\n",
            "📂 Processing: assignment_questions_chunk_238.txt\n",
            "📂 Processing: assignment_questions_chunk_239.txt\n",
            "📂 Processing: assignment_questions_chunk_240.txt\n",
            "📂 Processing: assignment_questions_chunk_241.txt\n",
            "📂 Processing: assignment_questions_chunk_242.txt\n",
            "📂 Processing: assignment_questions_chunk_243.txt\n",
            "📂 Processing: assignment_questions_chunk_244.txt\n",
            "📂 Processing: assignment_questions_chunk_245.txt\n",
            "📂 Processing: assignment_questions_chunk_246.txt\n",
            "📂 Processing: assignment_questions_chunk_247.txt\n",
            "📂 Processing: assignment_questions_chunk_248.txt\n",
            "📂 Processing: assignment_questions_chunk_249.txt\n",
            "📂 Processing: assignment_questions_chunk_250.txt\n",
            "📂 Processing: assignment_questions_chunk_251.txt\n",
            "📂 Processing: assignment_questions_chunk_252.txt\n",
            "📂 Processing: assignment_questions_chunk_253.txt\n",
            "📂 Processing: assignment_questions_chunk_254.txt\n",
            "📂 Processing: assignment_questions_chunk_255.txt\n",
            "📂 Processing: assignment_questions_chunk_256.txt\n",
            "📂 Processing: assignment_questions_chunk_257.txt\n",
            "📂 Processing: assignment_questions_chunk_258.txt\n",
            "📂 Processing: assignment_questions_chunk_259.txt\n",
            "📂 Processing: assignment_questions_chunk_260.txt\n",
            "📂 Processing: assignment_questions_chunk_261.txt\n",
            "📂 Processing: assignment_questions_chunk_262.txt\n",
            "📂 Processing: assignment_questions_chunk_263.txt\n",
            "📂 Processing: assignment_questions_chunk_264.txt\n",
            "📂 Processing: assignment_questions_chunk_265.txt\n",
            "📂 Processing: assignment_questions_chunk_266.txt\n",
            "📂 Processing: assignment_questions_chunk_267.txt\n",
            "📂 Processing: assignment_questions_chunk_268.txt\n",
            "📂 Processing: assignment_questions_chunk_269.txt\n",
            "📂 Processing: assignment_questions_chunk_270.txt\n",
            "📂 Processing: assignment_questions_chunk_271.txt\n",
            "📂 Processing: assignment_questions_chunk_272.txt\n",
            "📂 Processing: assignment_questions_chunk_273.txt\n",
            "📂 Processing: assignment_questions_chunk_274.txt\n",
            "📂 Processing: assignment_questions_chunk_275.txt\n",
            "📂 Processing: assignment_questions_chunk_276.txt\n",
            "📂 Processing: assignment_questions_chunk_277.txt\n",
            "📂 Processing: assignment_questions_chunk_278.txt\n",
            "📂 Processing: assignment_questions_chunk_279.txt\n",
            "📂 Processing: assignment_questions_chunk_280.txt\n",
            "📂 Processing: assignment_questions_chunk_281.txt\n",
            "📂 Processing: assignment_questions_chunk_282.txt\n",
            "📂 Processing: assignment_questions_chunk_283.txt\n",
            "📂 Processing: assignment_questions_chunk_284.txt\n",
            "📂 Processing: assignment_questions_chunk_285.txt\n",
            "📂 Processing: assignment_questions_chunk_286.txt\n",
            "📂 Processing: assignment_questions_chunk_287.txt\n",
            "📂 Processing: assignment_questions_chunk_288.txt\n",
            "✅ Merged and flattened JSON saved to: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/merged_flattened_questions.json\n",
            "[\n",
            "    {\n",
            "        \"Question\": \"Describe the key components of classical artificial intelligence and provide examples of AI systems that utilize these components.\",\n",
            "        \"Type\": \"subjective\",\n",
            "        \"Difficulty\": \"easy\",\n",
            "        \"CLO\": \"Understand key components in the field of artificial intelligence\",\n",
            "        \"Topic\": [\n",
            "            \"Explain the basic components of AI and identify AI systems with real-world examples.\"\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"Question\": \"Simulate and compare the performance of informed, uninformed, and local searching algorithms for problem-solving in AI.\",\n",
            "        \"Type\": \"code\",\n",
            "        \"Difficulty\": \"medium\",\n",
            "        \"CLO\": \"Understand key components in the field of artificial intelligence\",\n",
            "        \"Topic\": [\n",
            "            \"Simulate and compare informed, uninformed, and local searching algorithms for problem-solving in AI.\"\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"Question\": \"Implement a basic decision-theoretic system using a programming language of your choice and demonstrate its application in a real-world scenario.\",\n",
            "        \"Type\": \"code\",\n",
            "        \"Difficulty\": \"hard\",\n",
            "        \"CLO\": \"Understand key components in the field of artificial intelligence\",\n",
            "        \"Topic\": [\n",
            "            \"Implement a basic decision-theoretic system using a programming language of your choice and demonstrate its application in a real-world scenario.\"\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"Question\": \"Analyze the strengths and weaknesses of a real-world AI system, such as AlphaGo or DeepMind, and discuss recent trends in AI research.\",\n",
            "        \"Type\": \"subjective\",\n",
            "        \"Difficulty\": \"medium\",\n",
            "        \"CLO\": \"Understand key components in the field of artificial intelligence\",\n",
            "        \"Topic\": [\n",
            "            \"Discuss recent trends in AI and analyze case studies of AI systems to identify their strengths and weaknesses.\"\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"Question\": \"Design and implement a simple expert system using a programming language of your choice and demonstrate its application in a real-world scenario.\",\n",
            "        \"Type\": \"code\",\n",
            "        \"Difficulty\": \"hard\",\n",
            "        \"CLO\": \"Understand key components in the field of artificial intelligence\",\n",
            "        \"Topic\": [\n",
            "            \"Design and implement a simple expert system using a programming language of your choice and demonstrate its application in a real-world scenario.\"\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total records: {len(merged_flattened_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB3UcANTQdtp",
        "outputId": "8fa92966-54eb-4394-9a10-3db2150a1526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total records: 2144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "text_chunks = extract_text_from_pdf(PDF_PATH, CHUNK_SIZE)\n",
        "\n",
        "def merge_txt_files_to_json(folder_path, output_file):\n",
        "    merged_data = []\n",
        "\n",
        "    # Iterate over all files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            with open(file_path, 'r+', encoding='utf-8') as file:\n",
        "                try:\n",
        "                    # Remove block markers before loading JSON\n",
        "                    content = file.read().strip('`')\n",
        "                    file.seek(0)\n",
        "                    file.truncate()\n",
        "                    file.write(content)\n",
        "                    file.seek(0)\n",
        "                    # Load JSON content from the file\n",
        "                    data = json.load(file)\n",
        "\n",
        "                    # Add chunk number and text to each object\n",
        "                    chunk_number = filename.split('_')[-1].replace('.txt', '')\n",
        "                    print(chunk_number)\n",
        "                    if isinstance(data, list):\n",
        "                        for obj in data:\n",
        "                            obj['chunkNumber'] = int(chunk_number)\n",
        "                            obj['text'] = text_chunks[int(chunk_number)]\n",
        "                        merged_data.extend(data)\n",
        "                    else:\n",
        "                        data['chunkNumber'] = int(chunk_number)\n",
        "                        data['text'] = content\n",
        "                        merged_data.append(data)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Error decoding JSON from file {filename}: {e}\")\n",
        "\n",
        "    # Write the merged data to the output JSON file\n",
        "    with open(output_file, 'w', encoding='utf-8') as output:\n",
        "        json.dump(merged_data, output, indent=4)\n",
        "\n",
        "# Example usage\n",
        "# folder_path = 'output'\n",
        "# output_file = 'output/merged_output_meta.json'\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/\"\n",
        "folder_path = OUTPUT_DIR\n",
        "output_file = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/merged_output_meta.json\"\n",
        "merge_txt_files_to_json(folder_path, output_file)\n"
      ],
      "metadata": {
        "id": "3LfNAO_NRHbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from json_repair import repair_json\n",
        "\n",
        "# Define base folder and filename format\n",
        "FOLDER_PATH = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/output5\"\n",
        "FILE_PREFIX = \"assignment_questions_chunk_\"\n",
        "\n",
        "# Extract text chunks from PDF (Assuming this function is defined elsewhere)\n",
        "text_chunks = extract_text_from_pdf(PDF_PATH, CHUNK_SIZE)  # text_chunks is an array\n",
        "\n",
        "# Function to flatten JSON\n",
        "def flatten_json(nested_json, prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Recursively flattens a nested JSON object.\n",
        "    Example: {\"metadata\": {\"difficulty\": \"easy\"}} → {\"metadata.difficulty\": \"easy\"}\n",
        "\n",
        "    Args:\n",
        "        nested_json (dict): JSON object to flatten.\n",
        "        prefix (str): Prefix for keys during recursion.\n",
        "\n",
        "    Returns:\n",
        "        dict: Flattened JSON object.\n",
        "    \"\"\"\n",
        "    flattened_dict = {}\n",
        "    if isinstance(nested_json, dict):\n",
        "        for key, value in nested_json.items():\n",
        "            new_key = f\"{prefix}{key}\" if prefix else key  # Add prefix if nested\n",
        "            if isinstance(value, dict):  # If it's a dictionary, recurse\n",
        "                flattened_dict.update(flatten_json(value, new_key + \".\"))\n",
        "            elif isinstance(value, list) and all(isinstance(i, dict) for i in value):\n",
        "                # If it's a list of dicts, flatten each item\n",
        "                for idx, item in enumerate(value):\n",
        "                    flattened_dict.update(flatten_json(item, f\"{new_key}[{idx}].\"))\n",
        "            else:\n",
        "                flattened_dict[new_key] = value\n",
        "    return flattened_dict\n",
        "\n",
        "# Function to load and repair JSON files if necessary\n",
        "def load_json_file(file_path):\n",
        "    \"\"\"\n",
        "    Reads a JSON file, attempts to repair it if malformed.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        list/dict: Parsed JSON object, or None if repair fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            raw_data = file.read().strip()  # Remove unnecessary block markers\n",
        "            try:\n",
        "                return json.loads(raw_data)  # Normal JSON parsing\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"🔄 Repairing corrupted JSON: {file_path}...\")\n",
        "                repaired_data = repair_json(raw_data)  # Attempt to repair\n",
        "                return json.loads(repaired_data)  # Load repaired JSON\n",
        "    except (OSError, json.JSONDecodeError) as e:\n",
        "        print(f\"❌ Skipping {file_path} due to error: {e}\")\n",
        "        return None  # Skip files that cannot be read\n",
        "\n",
        "# List to store all flattened JSON objects\n",
        "merged_flattened_data = []\n",
        "\n",
        "# Loop through files from 0 to 288\n",
        "for i in range(289):  # 0 to 288\n",
        "    file_name = f\"{FILE_PREFIX}{i}.txt\"\n",
        "    file_path = os.path.join(FOLDER_PATH, file_name)\n",
        "\n",
        "    if os.path.exists(file_path):  # Check if file exists\n",
        "        print(f\"📂 Processing: {file_name}\")\n",
        "        data = load_json_file(file_path)\n",
        "\n",
        "        if data is None:  # Skip if file is unreadable\n",
        "            continue\n",
        "\n",
        "        # Get the text chunk for this file ID\n",
        "        text_content = text_chunks[i] if i < len(text_chunks) else \"No text available\"\n",
        "\n",
        "        # Flatten and store the JSON data\n",
        "        if isinstance(data, list):\n",
        "            for item in data:\n",
        "                if isinstance(item, dict):  # Ensure valid structure\n",
        "                    flattened_obj = flatten_json(item)\n",
        "                    flattened_obj[\"text_chunk_ID\"] = i  # Add fileID\n",
        "                    flattened_obj[\"text_chunk\"] = text_content  # Add text chunk\n",
        "                    merged_flattened_data.append(flattened_obj)\n",
        "        elif isinstance(data, dict):\n",
        "            flattened_obj = flatten_json(data)\n",
        "            flattened_obj[\"text_chunk_ID\"] = i  # Add fileID\n",
        "            flattened_obj[\"text_chunk\"] = text_content  # Add text chunk\n",
        "            merged_flattened_data.append(flattened_obj)\n",
        "        else:\n",
        "            print(f\"⚠️ Unexpected JSON format in {file_name}, skipping.\")\n",
        "\n",
        "# Save the combined and flattened JSON output\n",
        "output_file = \"/content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/metaXmerged_flattened_questions.json\"\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
        "    json.dump(merged_flattened_data, file, indent=4)\n",
        "\n",
        "# Print final output\n",
        "print(f\"✅ Merged and flattened JSON saved to: {output_file}\")\n",
        "print(json.dumps(merged_flattened_data[:5], indent=4))  # Print first 5 results for verification\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR74l9ikSslo",
        "outputId": "7c95d573-92b5-4e7c-b4b6-17ca46d7c2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Processing: assignment_questions_chunk_0.txt\n",
            "📂 Processing: assignment_questions_chunk_1.txt\n",
            "📂 Processing: assignment_questions_chunk_2.txt\n",
            "📂 Processing: assignment_questions_chunk_3.txt\n",
            "📂 Processing: assignment_questions_chunk_4.txt\n",
            "📂 Processing: assignment_questions_chunk_5.txt\n",
            "📂 Processing: assignment_questions_chunk_6.txt\n",
            "📂 Processing: assignment_questions_chunk_7.txt\n",
            "📂 Processing: assignment_questions_chunk_8.txt\n",
            "📂 Processing: assignment_questions_chunk_9.txt\n",
            "📂 Processing: assignment_questions_chunk_10.txt\n",
            "📂 Processing: assignment_questions_chunk_11.txt\n",
            "📂 Processing: assignment_questions_chunk_12.txt\n",
            "📂 Processing: assignment_questions_chunk_13.txt\n",
            "📂 Processing: assignment_questions_chunk_14.txt\n",
            "📂 Processing: assignment_questions_chunk_15.txt\n",
            "📂 Processing: assignment_questions_chunk_16.txt\n",
            "📂 Processing: assignment_questions_chunk_17.txt\n",
            "📂 Processing: assignment_questions_chunk_18.txt\n",
            "📂 Processing: assignment_questions_chunk_19.txt\n",
            "📂 Processing: assignment_questions_chunk_20.txt\n",
            "📂 Processing: assignment_questions_chunk_21.txt\n",
            "📂 Processing: assignment_questions_chunk_22.txt\n",
            "📂 Processing: assignment_questions_chunk_23.txt\n",
            "📂 Processing: assignment_questions_chunk_24.txt\n",
            "📂 Processing: assignment_questions_chunk_25.txt\n",
            "📂 Processing: assignment_questions_chunk_26.txt\n",
            "📂 Processing: assignment_questions_chunk_27.txt\n",
            "📂 Processing: assignment_questions_chunk_28.txt\n",
            "📂 Processing: assignment_questions_chunk_29.txt\n",
            "📂 Processing: assignment_questions_chunk_30.txt\n",
            "📂 Processing: assignment_questions_chunk_31.txt\n",
            "📂 Processing: assignment_questions_chunk_32.txt\n",
            "📂 Processing: assignment_questions_chunk_33.txt\n",
            "📂 Processing: assignment_questions_chunk_34.txt\n",
            "📂 Processing: assignment_questions_chunk_35.txt\n",
            "📂 Processing: assignment_questions_chunk_36.txt\n",
            "📂 Processing: assignment_questions_chunk_37.txt\n",
            "📂 Processing: assignment_questions_chunk_38.txt\n",
            "📂 Processing: assignment_questions_chunk_39.txt\n",
            "📂 Processing: assignment_questions_chunk_40.txt\n",
            "📂 Processing: assignment_questions_chunk_41.txt\n",
            "📂 Processing: assignment_questions_chunk_42.txt\n",
            "📂 Processing: assignment_questions_chunk_43.txt\n",
            "📂 Processing: assignment_questions_chunk_44.txt\n",
            "📂 Processing: assignment_questions_chunk_45.txt\n",
            "📂 Processing: assignment_questions_chunk_46.txt\n",
            "📂 Processing: assignment_questions_chunk_47.txt\n",
            "📂 Processing: assignment_questions_chunk_48.txt\n",
            "📂 Processing: assignment_questions_chunk_49.txt\n",
            "📂 Processing: assignment_questions_chunk_50.txt\n",
            "📂 Processing: assignment_questions_chunk_51.txt\n",
            "📂 Processing: assignment_questions_chunk_52.txt\n",
            "📂 Processing: assignment_questions_chunk_53.txt\n",
            "📂 Processing: assignment_questions_chunk_54.txt\n",
            "📂 Processing: assignment_questions_chunk_55.txt\n",
            "📂 Processing: assignment_questions_chunk_56.txt\n",
            "📂 Processing: assignment_questions_chunk_57.txt\n",
            "📂 Processing: assignment_questions_chunk_58.txt\n",
            "📂 Processing: assignment_questions_chunk_59.txt\n",
            "📂 Processing: assignment_questions_chunk_60.txt\n",
            "📂 Processing: assignment_questions_chunk_61.txt\n",
            "📂 Processing: assignment_questions_chunk_62.txt\n",
            "📂 Processing: assignment_questions_chunk_63.txt\n",
            "📂 Processing: assignment_questions_chunk_64.txt\n",
            "📂 Processing: assignment_questions_chunk_65.txt\n",
            "📂 Processing: assignment_questions_chunk_66.txt\n",
            "📂 Processing: assignment_questions_chunk_67.txt\n",
            "📂 Processing: assignment_questions_chunk_68.txt\n",
            "📂 Processing: assignment_questions_chunk_69.txt\n",
            "📂 Processing: assignment_questions_chunk_70.txt\n",
            "📂 Processing: assignment_questions_chunk_71.txt\n",
            "📂 Processing: assignment_questions_chunk_72.txt\n",
            "📂 Processing: assignment_questions_chunk_73.txt\n",
            "📂 Processing: assignment_questions_chunk_74.txt\n",
            "📂 Processing: assignment_questions_chunk_75.txt\n",
            "📂 Processing: assignment_questions_chunk_76.txt\n",
            "📂 Processing: assignment_questions_chunk_77.txt\n",
            "📂 Processing: assignment_questions_chunk_78.txt\n",
            "📂 Processing: assignment_questions_chunk_79.txt\n",
            "📂 Processing: assignment_questions_chunk_80.txt\n",
            "📂 Processing: assignment_questions_chunk_81.txt\n",
            "📂 Processing: assignment_questions_chunk_82.txt\n",
            "📂 Processing: assignment_questions_chunk_83.txt\n",
            "📂 Processing: assignment_questions_chunk_84.txt\n",
            "📂 Processing: assignment_questions_chunk_85.txt\n",
            "📂 Processing: assignment_questions_chunk_86.txt\n",
            "📂 Processing: assignment_questions_chunk_87.txt\n",
            "📂 Processing: assignment_questions_chunk_88.txt\n",
            "📂 Processing: assignment_questions_chunk_89.txt\n",
            "📂 Processing: assignment_questions_chunk_90.txt\n",
            "📂 Processing: assignment_questions_chunk_91.txt\n",
            "📂 Processing: assignment_questions_chunk_92.txt\n",
            "📂 Processing: assignment_questions_chunk_93.txt\n",
            "📂 Processing: assignment_questions_chunk_94.txt\n",
            "📂 Processing: assignment_questions_chunk_95.txt\n",
            "📂 Processing: assignment_questions_chunk_96.txt\n",
            "📂 Processing: assignment_questions_chunk_97.txt\n",
            "📂 Processing: assignment_questions_chunk_98.txt\n",
            "📂 Processing: assignment_questions_chunk_99.txt\n",
            "📂 Processing: assignment_questions_chunk_100.txt\n",
            "📂 Processing: assignment_questions_chunk_101.txt\n",
            "📂 Processing: assignment_questions_chunk_102.txt\n",
            "📂 Processing: assignment_questions_chunk_103.txt\n",
            "📂 Processing: assignment_questions_chunk_104.txt\n",
            "📂 Processing: assignment_questions_chunk_105.txt\n",
            "📂 Processing: assignment_questions_chunk_106.txt\n",
            "📂 Processing: assignment_questions_chunk_107.txt\n",
            "📂 Processing: assignment_questions_chunk_108.txt\n",
            "📂 Processing: assignment_questions_chunk_109.txt\n",
            "📂 Processing: assignment_questions_chunk_110.txt\n",
            "📂 Processing: assignment_questions_chunk_111.txt\n",
            "📂 Processing: assignment_questions_chunk_112.txt\n",
            "📂 Processing: assignment_questions_chunk_113.txt\n",
            "📂 Processing: assignment_questions_chunk_114.txt\n",
            "📂 Processing: assignment_questions_chunk_115.txt\n",
            "📂 Processing: assignment_questions_chunk_116.txt\n",
            "📂 Processing: assignment_questions_chunk_117.txt\n",
            "📂 Processing: assignment_questions_chunk_118.txt\n",
            "📂 Processing: assignment_questions_chunk_119.txt\n",
            "📂 Processing: assignment_questions_chunk_120.txt\n",
            "📂 Processing: assignment_questions_chunk_121.txt\n",
            "📂 Processing: assignment_questions_chunk_122.txt\n",
            "📂 Processing: assignment_questions_chunk_123.txt\n",
            "📂 Processing: assignment_questions_chunk_124.txt\n",
            "📂 Processing: assignment_questions_chunk_125.txt\n",
            "📂 Processing: assignment_questions_chunk_126.txt\n",
            "📂 Processing: assignment_questions_chunk_127.txt\n",
            "📂 Processing: assignment_questions_chunk_128.txt\n",
            "📂 Processing: assignment_questions_chunk_129.txt\n",
            "📂 Processing: assignment_questions_chunk_130.txt\n",
            "📂 Processing: assignment_questions_chunk_131.txt\n",
            "📂 Processing: assignment_questions_chunk_132.txt\n",
            "📂 Processing: assignment_questions_chunk_133.txt\n",
            "📂 Processing: assignment_questions_chunk_134.txt\n",
            "📂 Processing: assignment_questions_chunk_135.txt\n",
            "📂 Processing: assignment_questions_chunk_136.txt\n",
            "📂 Processing: assignment_questions_chunk_137.txt\n",
            "📂 Processing: assignment_questions_chunk_138.txt\n",
            "📂 Processing: assignment_questions_chunk_139.txt\n",
            "📂 Processing: assignment_questions_chunk_140.txt\n",
            "📂 Processing: assignment_questions_chunk_141.txt\n",
            "📂 Processing: assignment_questions_chunk_142.txt\n",
            "📂 Processing: assignment_questions_chunk_143.txt\n",
            "📂 Processing: assignment_questions_chunk_144.txt\n",
            "📂 Processing: assignment_questions_chunk_145.txt\n",
            "📂 Processing: assignment_questions_chunk_146.txt\n",
            "📂 Processing: assignment_questions_chunk_147.txt\n",
            "📂 Processing: assignment_questions_chunk_148.txt\n",
            "📂 Processing: assignment_questions_chunk_149.txt\n",
            "📂 Processing: assignment_questions_chunk_150.txt\n",
            "📂 Processing: assignment_questions_chunk_151.txt\n",
            "📂 Processing: assignment_questions_chunk_152.txt\n",
            "📂 Processing: assignment_questions_chunk_153.txt\n",
            "📂 Processing: assignment_questions_chunk_154.txt\n",
            "📂 Processing: assignment_questions_chunk_155.txt\n",
            "📂 Processing: assignment_questions_chunk_156.txt\n",
            "📂 Processing: assignment_questions_chunk_157.txt\n",
            "📂 Processing: assignment_questions_chunk_158.txt\n",
            "📂 Processing: assignment_questions_chunk_159.txt\n",
            "📂 Processing: assignment_questions_chunk_160.txt\n",
            "📂 Processing: assignment_questions_chunk_161.txt\n",
            "📂 Processing: assignment_questions_chunk_162.txt\n",
            "📂 Processing: assignment_questions_chunk_163.txt\n",
            "📂 Processing: assignment_questions_chunk_164.txt\n",
            "📂 Processing: assignment_questions_chunk_165.txt\n",
            "📂 Processing: assignment_questions_chunk_166.txt\n",
            "📂 Processing: assignment_questions_chunk_167.txt\n",
            "📂 Processing: assignment_questions_chunk_168.txt\n",
            "📂 Processing: assignment_questions_chunk_169.txt\n",
            "📂 Processing: assignment_questions_chunk_170.txt\n",
            "📂 Processing: assignment_questions_chunk_171.txt\n",
            "📂 Processing: assignment_questions_chunk_172.txt\n",
            "📂 Processing: assignment_questions_chunk_173.txt\n",
            "📂 Processing: assignment_questions_chunk_174.txt\n",
            "📂 Processing: assignment_questions_chunk_175.txt\n",
            "📂 Processing: assignment_questions_chunk_176.txt\n",
            "📂 Processing: assignment_questions_chunk_177.txt\n",
            "📂 Processing: assignment_questions_chunk_178.txt\n",
            "📂 Processing: assignment_questions_chunk_179.txt\n",
            "📂 Processing: assignment_questions_chunk_180.txt\n",
            "📂 Processing: assignment_questions_chunk_181.txt\n",
            "📂 Processing: assignment_questions_chunk_182.txt\n",
            "📂 Processing: assignment_questions_chunk_183.txt\n",
            "📂 Processing: assignment_questions_chunk_184.txt\n",
            "📂 Processing: assignment_questions_chunk_185.txt\n",
            "📂 Processing: assignment_questions_chunk_186.txt\n",
            "📂 Processing: assignment_questions_chunk_187.txt\n",
            "📂 Processing: assignment_questions_chunk_188.txt\n",
            "📂 Processing: assignment_questions_chunk_189.txt\n",
            "📂 Processing: assignment_questions_chunk_190.txt\n",
            "📂 Processing: assignment_questions_chunk_191.txt\n",
            "📂 Processing: assignment_questions_chunk_192.txt\n",
            "📂 Processing: assignment_questions_chunk_193.txt\n",
            "📂 Processing: assignment_questions_chunk_194.txt\n",
            "📂 Processing: assignment_questions_chunk_195.txt\n",
            "📂 Processing: assignment_questions_chunk_196.txt\n",
            "📂 Processing: assignment_questions_chunk_197.txt\n",
            "📂 Processing: assignment_questions_chunk_198.txt\n",
            "📂 Processing: assignment_questions_chunk_199.txt\n",
            "📂 Processing: assignment_questions_chunk_200.txt\n",
            "📂 Processing: assignment_questions_chunk_201.txt\n",
            "📂 Processing: assignment_questions_chunk_202.txt\n",
            "📂 Processing: assignment_questions_chunk_203.txt\n",
            "📂 Processing: assignment_questions_chunk_204.txt\n",
            "📂 Processing: assignment_questions_chunk_205.txt\n",
            "📂 Processing: assignment_questions_chunk_206.txt\n",
            "📂 Processing: assignment_questions_chunk_207.txt\n",
            "📂 Processing: assignment_questions_chunk_208.txt\n",
            "📂 Processing: assignment_questions_chunk_209.txt\n",
            "📂 Processing: assignment_questions_chunk_210.txt\n",
            "📂 Processing: assignment_questions_chunk_211.txt\n",
            "📂 Processing: assignment_questions_chunk_212.txt\n",
            "📂 Processing: assignment_questions_chunk_213.txt\n",
            "📂 Processing: assignment_questions_chunk_214.txt\n",
            "📂 Processing: assignment_questions_chunk_215.txt\n",
            "📂 Processing: assignment_questions_chunk_216.txt\n",
            "📂 Processing: assignment_questions_chunk_217.txt\n",
            "📂 Processing: assignment_questions_chunk_218.txt\n",
            "📂 Processing: assignment_questions_chunk_219.txt\n",
            "📂 Processing: assignment_questions_chunk_220.txt\n",
            "📂 Processing: assignment_questions_chunk_221.txt\n",
            "📂 Processing: assignment_questions_chunk_222.txt\n",
            "📂 Processing: assignment_questions_chunk_223.txt\n",
            "📂 Processing: assignment_questions_chunk_224.txt\n",
            "📂 Processing: assignment_questions_chunk_225.txt\n",
            "📂 Processing: assignment_questions_chunk_226.txt\n",
            "📂 Processing: assignment_questions_chunk_227.txt\n",
            "📂 Processing: assignment_questions_chunk_228.txt\n",
            "📂 Processing: assignment_questions_chunk_229.txt\n",
            "📂 Processing: assignment_questions_chunk_230.txt\n",
            "📂 Processing: assignment_questions_chunk_231.txt\n",
            "📂 Processing: assignment_questions_chunk_232.txt\n",
            "📂 Processing: assignment_questions_chunk_233.txt\n",
            "📂 Processing: assignment_questions_chunk_234.txt\n",
            "📂 Processing: assignment_questions_chunk_235.txt\n",
            "📂 Processing: assignment_questions_chunk_236.txt\n",
            "📂 Processing: assignment_questions_chunk_237.txt\n",
            "📂 Processing: assignment_questions_chunk_238.txt\n",
            "📂 Processing: assignment_questions_chunk_239.txt\n",
            "📂 Processing: assignment_questions_chunk_240.txt\n",
            "📂 Processing: assignment_questions_chunk_241.txt\n",
            "📂 Processing: assignment_questions_chunk_242.txt\n",
            "📂 Processing: assignment_questions_chunk_243.txt\n",
            "📂 Processing: assignment_questions_chunk_244.txt\n",
            "📂 Processing: assignment_questions_chunk_245.txt\n",
            "📂 Processing: assignment_questions_chunk_246.txt\n",
            "📂 Processing: assignment_questions_chunk_247.txt\n",
            "📂 Processing: assignment_questions_chunk_248.txt\n",
            "📂 Processing: assignment_questions_chunk_249.txt\n",
            "📂 Processing: assignment_questions_chunk_250.txt\n",
            "📂 Processing: assignment_questions_chunk_251.txt\n",
            "📂 Processing: assignment_questions_chunk_252.txt\n",
            "📂 Processing: assignment_questions_chunk_253.txt\n",
            "📂 Processing: assignment_questions_chunk_254.txt\n",
            "📂 Processing: assignment_questions_chunk_255.txt\n",
            "📂 Processing: assignment_questions_chunk_256.txt\n",
            "📂 Processing: assignment_questions_chunk_257.txt\n",
            "📂 Processing: assignment_questions_chunk_258.txt\n",
            "📂 Processing: assignment_questions_chunk_259.txt\n",
            "📂 Processing: assignment_questions_chunk_260.txt\n",
            "📂 Processing: assignment_questions_chunk_261.txt\n",
            "📂 Processing: assignment_questions_chunk_262.txt\n",
            "📂 Processing: assignment_questions_chunk_263.txt\n",
            "📂 Processing: assignment_questions_chunk_264.txt\n",
            "📂 Processing: assignment_questions_chunk_265.txt\n",
            "📂 Processing: assignment_questions_chunk_266.txt\n",
            "📂 Processing: assignment_questions_chunk_267.txt\n",
            "📂 Processing: assignment_questions_chunk_268.txt\n",
            "📂 Processing: assignment_questions_chunk_269.txt\n",
            "📂 Processing: assignment_questions_chunk_270.txt\n",
            "📂 Processing: assignment_questions_chunk_271.txt\n",
            "📂 Processing: assignment_questions_chunk_272.txt\n",
            "📂 Processing: assignment_questions_chunk_273.txt\n",
            "📂 Processing: assignment_questions_chunk_274.txt\n",
            "📂 Processing: assignment_questions_chunk_275.txt\n",
            "📂 Processing: assignment_questions_chunk_276.txt\n",
            "📂 Processing: assignment_questions_chunk_277.txt\n",
            "📂 Processing: assignment_questions_chunk_278.txt\n",
            "📂 Processing: assignment_questions_chunk_279.txt\n",
            "📂 Processing: assignment_questions_chunk_280.txt\n",
            "📂 Processing: assignment_questions_chunk_281.txt\n",
            "📂 Processing: assignment_questions_chunk_282.txt\n",
            "📂 Processing: assignment_questions_chunk_283.txt\n",
            "📂 Processing: assignment_questions_chunk_284.txt\n",
            "📂 Processing: assignment_questions_chunk_285.txt\n",
            "📂 Processing: assignment_questions_chunk_286.txt\n",
            "📂 Processing: assignment_questions_chunk_287.txt\n",
            "📂 Processing: assignment_questions_chunk_288.txt\n",
            "✅ Merged and flattened JSON saved to: /content/drive/MyDrive/ThesisDataRaw/AI-Book/chunks/metaXmerged_flattened_questions.json\n",
            "[\n",
            "    {\n",
            "        \"Question\": \"Describe the key components of classical artificial intelligence and provide examples of AI systems that utilize these components.\",\n",
            "        \"Type\": \"subjective\",\n",
            "        \"Difficulty\": \"easy\",\n",
            "        \"CLO\": \"Understand key components in the field of artificial intelligence\",\n",
            "        \"Topic\": [\n",
            "            \"Explain the basic components of AI and identify AI systems with real-world examples.\"\n",
            "        ],\n",
            "        \"text_chunk_ID\": 0,\n",
            "        \"text_chunk\": \"Arti\\ufb01cial Intelligence A Modern Approach Third Edition PRENTICE HALL SERIES IN ARTIFICIAL INTELLIGENCE Stuart Russell and Peter Norvig, Editors FORSYTH & PONCE Computer Vision: A Modern Approach GRAHAM ANSI Common Lisp JURAFSKY & MARTIN Speech and Language Processing, 2nd ed. NEAPOLITAN Learning Bayesian Networks RUSSELL & NORVIG Arti\\ufb01cial Intelligence: A Modern Approach, 3rd ed. Arti\\ufb01cial Intelligence A Modern Approach Third Edition Stuart J. Russell and Peter Norvig Contributing writers: Ernest Davis Douglas D. Edwards David Forsyth Nicholas J. Hay Jitendra M. Malik Vibhu Mittal Mehran Sahami Sebastian Thrun Upper Saddle River Boston Columbus San Francisco New York Indianapolis London Toronto Sydney Singapore Tokyo Montreal Dubai Madrid Hong Kong Mexico City Munich Paris Amsterdam Cape Town Vice President and Editorial Director, ECS: Marcia J. Horton Editor-in-Chief: Michael Hirsch Executive Editor: Tracy Dunkelberger Assistant Editor: Melinda Haggerty Editorial Assistant: Allison Michael Vice President, Production: Vince O\\u2019Brien Senior Managing Editor: Scott Disanno Production Editor: Jane Bonnell Senior Operations Supervisor: Alan Fischer Operations Specialist: Lisa McDowell Marketing Manager: Erin Davis Marketing Assistant: Mack Patterson Cover Designers: Kirsten Sims and Geoffrey Cassar Cover Images: Stan Honda/Getty, Library of Congress, NASA, National Museum of Rome, Peter Norvig, Ian Parker, Shutterstock, Time Life/Getty Interior Designers: Stuart Russell and Peter Norvig Copy Editor: Mary Lou Nohr Art Editor: Greg Dulles Media Editor: Daniel Sandin Media Project Manager: Danielle Leone Copyright c\\u20dd2010, 2003, 1995 by Pearson Education, Inc., Upper Saddle River, New Jersey 07458. All rights reserved. Manufactured in the United States of America. This publication is protected by Copyright and permissions should be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or likewise. To obtain permission(s) to use materials from this work, please submit a written request to Pearson Higher Education, Permissions Department, 1 Lake Street, Upper Saddle River, NJ 07458. The author and publisher of this book have used their best efforts in preparing this book. These efforts include the development, research, and testing of the theories and programs to determine their effectiveness. The author and publisher make no warranty of any kind, expressed or implied, with regard to these programs or the documentation contained in this book. The author and publisher shall not be liable in any event for incidental or consequential damages in connection with, or arising out of, the furnishing, performance, or use of these programs. Library of Congress Cataloging-in-Publication Data on File 10 9 8 7 6 5 4 3 2 1 ISBN-13: 978-0-13-604259-4 ISBN-10: 0-13-604259-7 For Loy, Gordon, Lucy, George, and Isaac \\u2014 S.J.R. For Kris, Isabella, and Juliet \\u2014 P.N. This page intentionally left blank Preface Arti\\ufb01cial Intelligence (AI) is a big \\ufb01eld, and this is a big book. We have tried to explore the full breadth of the \\ufb01eld, which encompasses logic, probability, and continuous mathematics; perception, reasoning, learning, and action; and everything from microelectronic devices to robotic planetary explorers. The book is also big because we go into some depth. The subtitle of this book is \\u201cA Modern Approach.\\u201d The intended meaning of this rather empty phrase is that we have tried to synthesize what is now known into a common frame- work, rather than trying to explain each sub\\ufb01eld of AI in its own historical context. We apologize to those whose sub\\ufb01elds are, as a result, less recognizable. New to this edition This edition captures the changes in AI that have taken place since the last edition in 2003. There have been important applications of AI technology, such as the widespread deploy- ment of practical speech recognition, machine translation, autonomous vehicles, and house- hold robotics. There have been algorithmic landmarks, such as the solution of the game of checkers. And there has been a great deal of theoretical progress, particularly in areas such as probabilistic reasoning, machine learning, and computer vision. Most important from our point of view is the continued evolution in how we think about the \\ufb01eld, and thus how we organize the book. The major changes are as follows: \\u2022 We place more emphasis on partially observable and nondeterministic environments, especially in the nonprobabilistic settings of search and planning. The concepts of belief state (a set of possible worlds) and state estimation (maintaining the belief state) are introduced in these settings; later in the book, we add probabilities. \\u2022 In addition to discussing the types of environments and types of agents, we now cover in more depth the types of representations that an agent can use. We distinguish among atomic representations (in which each state of the world is treated as a black box), factored representations (in which a state is a set of attribute/value pairs), and structured representations (in which the world consists of objects and relations between them). \\u2022 Our coverage of planning goes into more depth on contingent planning in partially observable environments and includes a new approach to hierarchical planning. \\u2022 We have added new material on \\ufb01rst-order probabilistic models, including open-universe models for cases where there is uncertainty as to what objects exist. \\u2022 We have completely rewritten the introductory machine-learning chapter, stressing a wider variety of more modern learning algorithms and placing them on a \\ufb01rmer theo- retical footing. \\u2022 We have expanded coverage of Web search and information extraction, and of tech- niques for learning from very large data sets. \\u2022 20% of the citations in this edition are to works published after 2003. \\u2022 We estimate that about 20% of the material is brand new. The remaining 80% re\\ufb02ects older work but has been largely rewritten to present a more uni\\ufb01ed picture of the \\ufb01eld. vii viii Preface Overview of the book The main unifying theme is the idea of an intelligent agent. We de\\ufb01ne AI as the study of agents that receive percepts from the environment and perform actions. Each such agent im- plements a function that maps percept sequences to actions, and we cover different ways to represent these functions, such as reactive agents, real-time planners, and decision-theoretic systems. We explain the role of learning as extending the reach of the designer into unknown environments, and we show how that role constrains agent design, favoring explicit knowl- edge representation and reasoning. We treat robotics and vision not as independently de\\ufb01ned problems, but as occurring in the service of achieving goals. We stress the importance of the task environment in determining the appropriate agent design. Our primary aim is to convey the ideas that have emerged over the past \\ufb01fty years of AI research and the past two millennia of related work. We have tried to avoid excessive formal- ity in the presentation of these ideas while retaining precision. We have included pseudocode algorithms to make the key ideas concrete; our pseudocode is described in Appendix B. This book is primarily intended for use in an undergraduate course or course sequence. The book has 27 chapters, each requiring about a week\\u2019s worth of lectures, so working through the whole book requires a two-semester sequence. A one-semester course can use selected chapters to suit the interests of the instructor and students. The book can also be used in a graduate-level course (perhaps with the addition of some of the primary sources suggested in the bibliographical notes). Sample syllabi are available at the book\\u2019s Web site, aima.cs.berkeley.edu. The only prerequisite is familiarity with basic concepts of computer science (algorithms, data structures, complexity) at a sophomore level. Freshman calculus and linear algebra are useful for some of the topics; the required mathematical back- ground is supplied in Appendix A. Exercises are given at the end of each chapter. Exercises requiring signi\\ufb01cant pro- gramming are marked with a keyboard icon. These exercises can best be solved by taking advantage of the code repository at aima.cs.berkeley.edu. Some of them are large enough to be considered term projects. A number of exercises require some investigation of the literature; these are marked with a book icon. Throughout the book, important points are marked with a pointing icon. We have in- cluded an extensive index of around 6,000 items to make it easy to \\ufb01nd things in the book. Wherever a new term is \\ufb01rst de\\ufb01ned, it is also marked in the margin. NEW TERM About the Web site aima.cs.berkeley.edu, the Web site for the book, contains \\u2022 implementations of the algorithms in the book in several programming languages, \\u2022 a list of over 1000 schools that have used the book, many with links to online course materials and syllabi, \\u2022 an annotated list of over 800 links to sites around the Web with useful AI content, \\u2022 a chapter-by-chapter list of supplementary material and links, \\u2022 instructions on how to join a discussion group for the book, Preface ix \\u2022 instructions on how to contact the authors with questions or comments, \\u2022 instructions on how to report errors in the book, in the likely event that some exist, and \\u2022 slides and other materials for instructors. About the cover The cover depicts the \\ufb01nal position from the decisive game 6 of the 1997 match between chess champion Garry Kasparov and program DEEP BLUE. Kasparov, playing Black, was forced to resign, making this the \\ufb01rst time a computer had beaten a world champion in a chess match. Kasparov is shown at the top. To his left is the Asimo humanoid robot and to his right is Thomas Bayes (1702\\u20131761), whose ideas about probability as a measure of belief underlie much of modern AI technology. Below that we see a Mars Exploration Rover, a robot that landed on Mars in 2004 and has been exploring the planet ever since. To the right is Alan Turing (1912\\u20131954), whose fundamental work de\\ufb01ned the \\ufb01elds of computer science in general and arti\\ufb01cial intelligence in particular. At the bottom is Shakey (1966\\u2013 1972), the \\ufb01rst robot to combine perception, world-modeling, planning, and learning. With Shakey is project leader Charles Rosen (1917\\u20132002). At the bottom right is Aristotle (384 B.C.\\u2013322 B.C.), who pioneered the study of logic; his work was state of the art until the 19th century (copy of a bust by Lysippos). At the bottom left, lightly screened behind the authors\\u2019 names, is a planning algorithm by Aristotle from De Motu Animalium in the original Greek. Behind the title is a portion of the CPSC Bayesian network for medical diagnosis (Pradhan et al., 1994). Behind the chess board is part of a Bayesian logic model for detecting nuclear explosions from seismic signals. Credits: Stan Honda/Getty (Kasparaov), Library of Congress (Bayes), NASA (Mars rover), National Museum of Rome (Aristotle), Peter Norvig (book), Ian Parker (Berkeley skyline), Shutterstock (Asimo, Chess pieces), Time Life/Getty (Shakey, Turing). Acknowledgments This book would not have been possible without the many contributors whose names did not make it to the cover. Jitendra Malik and David Forsyth wrote Chapter 24 (computer vision) and Sebastian Thrun wrote Chapter 25 (robotics). Vibhu Mittal wrote part of Chapter 22 (natural language). Nick Hay, Mehran Sahami, and Ernest Davis wrote some of the exercises. Zoran Duric (George Mason), Thomas C. Henderson (Utah), Leon Reznik (RIT), Michael Gourley (Central Oklahoma) and Ernest Davis (NYU) reviewed the manuscript and made helpful suggestions. We thank Ernie Davis in particular for his tireless ability to read multiple drafts and help improve the book. Nick Hay whipped the bibliography into shape and on deadline stayed up to 5:30 AM writing code to make the book better. Jon Barron formatted and improved the diagrams in this edition, while Tim Huang, Mark Paskin, and Cynthia Bruyns helped with diagrams and algorithms in previous editions. Ravi Mohan and Ciaran O\\u2019Reilly wrote and maintain the Java code examples on the Web site. John Canny wrote the robotics chapter for the \\ufb01rst edition and Douglas Edwards researched the historical notes. Tracy Dunkelberger, Allison Michael, Scott Disanno, and Jane Bonnell at Pearson tried their best to keep us on schedule and made many helpful suggestions. Most helpful of all has x Preface been Julie Sussman, P.P.A., who read every chapter and provided\"\n",
            "    },\n",
            "    {\n",
            "        \"Question\": \"Simulate and compare the performance of informed, uninformed, and local searching algorithms for problem-solving in AI.\",\n",
            "        \"Type\": \"code\",\n",
            "        \"Difficulty\": \"medium\",\n",
            "        \"CLO\": \"Understand key components in the field of artificial intelligence\",\n",
            "        \"Topic\": [\n",
            "            \"Simulate and compare informed, uninformed, and local searching algorithms for problem-solving in AI.\"\n",
            "        ],\n",
            "        \"text_chunk_ID\": 0,\n",
            "        \"text_chunk\": \"Arti\\ufb01cial Intelligence A Modern Approach Third Edition PRENTICE HALL SERIES IN ARTIFICIAL INTELLIGENCE Stuart Russell and Peter Norvig, Editors FORSYTH & PONCE Computer Vision: A Modern Approach GRAHAM ANSI Common Lisp JURAFSKY & MARTIN Speech and Language Processing, 2nd ed. NEAPOLITAN Learning Bayesian Networks RUSSELL & NORVIG Arti\\ufb01cial Intelligence: A Modern Approach, 3rd ed. Arti\\ufb01cial Intelligence A Modern Approach Third Edition Stuart J. Russell and Peter Norvig Contributing writers: Ernest Davis Douglas D. Edwards David Forsyth Nicholas J. Hay Jitendra M. Malik Vibhu Mittal Mehran Sahami Sebastian Thrun Upper Saddle River Boston Columbus San Francisco New York Indianapolis London Toronto Sydney Singapore Tokyo Montreal Dubai Madrid Hong Kong Mexico City Munich Paris Amsterdam Cape Town Vice President and Editorial Director, ECS: Marcia J. Horton Editor-in-Chief: Michael Hirsch Executive Editor: Tracy Dunkelberger Assistant Editor: Melinda Haggerty Editorial Assistant: Allison Michael Vice President, Production: Vince O\\u2019Brien Senior Managing Editor: Scott Disanno Production Editor: Jane Bonnell Senior Operations Supervisor: Alan Fischer Operations Specialist: Lisa McDowell Marketing Manager: Erin Davis Marketing Assistant: Mack Patterson Cover Designers: Kirsten Sims and Geoffrey Cassar Cover Images: Stan Honda/Getty, Library of Congress, NASA, National Museum of Rome, Peter Norvig, Ian Parker, Shutterstock, Time Life/Getty Interior Designers: Stuart Russell and Peter Norvig Copy Editor: Mary Lou Nohr Art Editor: Greg Dulles Media Editor: Daniel Sandin Media Project Manager: Danielle Leone Copyright c\\u20dd2010, 2003, 1995 by Pearson Education, Inc., Upper Saddle River, New Jersey 07458. All rights reserved. Manufactured in the United States of America. This publication is protected by Copyright and permissions should be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or likewise. To obtain permission(s) to use materials from this work, please submit a written request to Pearson Higher Education, Permissions Department, 1 Lake Street, Upper Saddle River, NJ 07458. The author and publisher of this book have used their best efforts in preparing this book. These efforts include the development, research, and testing of the theories and programs to determine their effectiveness. The author and publisher make no warranty of any kind, expressed or implied, with regard to these programs or the documentation contained in this book. The author and publisher shall not be liable in any event for incidental or consequential damages in connection with, or arising out of, the furnishing, performance, or use of these programs. Library of Congress Cataloging-in-Publication Data on File 10 9 8 7 6 5 4 3 2 1 ISBN-13: 978-0-13-604259-4 ISBN-10: 0-13-604259-7 For Loy, Gordon, Lucy, George, and Isaac \\u2014 S.J.R. For Kris, Isabella, and Juliet \\u2014 P.N. This page intentionally left blank Preface Arti\\ufb01cial Intelligence (AI) is a big \\ufb01eld, and this is a big book. We have tried to explore the full breadth of the \\ufb01eld, which encompasses logic, probability, and continuous mathematics; perception, reasoning, learning, and action; and everything from microelectronic devices to robotic planetary explorers. The book is also big because we go into some depth. The subtitle of this book is \\u201cA Modern Approach.\\u201d The intended meaning of this rather empty phrase is that we have tried to synthesize what is now known into a common frame- work, rather than trying to explain each sub\\ufb01eld of AI in its own historical context. We apologize to those whose sub\\ufb01elds are, as a result, less recognizable. New to this edition This edition captures the changes in AI that have taken place since the last edition in 2003. There have been important applications of AI technology, such as the widespread deploy- ment of practical speech recognition, machine translation, autonomous vehicles, and house- hold robotics. There have been algorithmic landmarks, such as the solution of the game of checkers. And there has been a great deal of theoretical progress, particularly in areas such as probabilistic reasoning, machine learning, and computer vision. Most important from our point of view is the continued evolution in how we think about the \\ufb01eld, and thus how we organize the book. The major changes are as follows: \\u2022 We place more emphasis on partially observable and nondeterministic environments, especially in the nonprobabilistic settings of search and planning. The concepts of belief state (a set of possible worlds) and state estimation (maintaining the belief state) are introduced in these settings; later in the book, we add probabilities. \\u2022 In addition to discussing the types of environments and types of agents, we now cover in more depth the types of representations that an agent can use. We distinguish among atomic representations (in which each state of the world is treated as a black box), factored representations (in which a state is a set of attribute/value pairs), and structured representations (in which the world consists of objects and relations between them). \\u2022 Our coverage of planning goes into more depth on contingent planning in partially observable environments and includes a new approach to hierarchical planning. \\u2022 We have added new material on \\ufb01rst-order probabilistic models, including open-universe models for cases where there is uncertainty as to what objects exist. \\u2022 We have completely rewritten the introductory machine-learning chapter, stressing a wider variety of more modern learning algorithms and placing them on a \\ufb01rmer theo- retical footing. \\u2022 We have expanded coverage of Web search and information extraction, and of tech- niques for learning from very large data sets. \\u2022 20% of the citations in this edition are to works published after 2003. \\u2022 We estimate that about 20% of the material is brand new. The remaining 80% re\\ufb02ects older work but has been largely rewritten to present a more uni\\ufb01ed picture of the \\ufb01eld. vii viii Preface Overview of the book The main unifying theme is the idea of an intelligent agent. We de\\ufb01ne AI as the study of agents that receive percepts from the environment and perform actions. Each such agent im- plements a function that maps percept sequences to actions, and we cover different ways to represent these functions, such as reactive agents, real-time planners, and decision-theoretic systems. We explain the role of learning as extending the reach of the designer into unknown environments, and we show how that role constrains agent design, favoring explicit knowl- edge representation and reasoning. We treat robotics and vision not as independently de\\ufb01ned problems, but as occurring in the service of achieving goals. We stress the importance of the task environment in determining the appropriate agent design. Our primary aim is to convey the ideas that have emerged over the past \\ufb01fty years of AI research and the past two millennia of related work. We have tried to avoid excessive formal- ity in the presentation of these ideas while retaining precision. We have included pseudocode algorithms to make the key ideas concrete; our pseudocode is described in Appendix B. This book is primarily intended for use in an undergraduate course or course sequence. The book has 27 chapters, each requiring about a week\\u2019s worth of lectures, so working through the whole book requires a two-semester sequence. A one-semester course can use selected chapters to suit the interests of the instructor and students. The book can also be used in a graduate-level course (perhaps with the addition of some of the primary sources suggested in the bibliographical notes). Sample syllabi are available at the book\\u2019s Web site, aima.cs.berkeley.edu. The only prerequisite is familiarity with basic concepts of computer science (algorithms, data structures, complexity) at a sophomore level. Freshman calculus and linear algebra are useful for some of the topics; the required mathematical back- ground is supplied in Appendix A. Exercises are given at the end of each chapter. Exercises requiring signi\\ufb01cant pro- gramming are marked with a keyboard icon. These exercises can best be solved by taking advantage of the code repository at aima.cs.berkeley.edu. Some of them are large enough to be considered term projects. A number of exercises require some investigation of the literature; these are marked with a book icon. Throughout the book, important points are marked with a pointing icon. We have in- cluded an extensive index of around 6,000 items to make it easy to \\ufb01nd things in the book. Wherever a new term is \\ufb01rst de\\ufb01ned, it is also marked in the margin. NEW TERM About the Web site aima.cs.berkeley.edu, the Web site for the book, contains \\u2022 implementations of the algorithms in the book in several programming languages, \\u2022 a list of over 1000 schools that have used the book, many with links to online course materials and syllabi, \\u2022 an annotated list of over 800 links to sites around the Web with useful AI content, \\u2022 a chapter-by-chapter list of supplementary material and links, \\u2022 instructions on how to join a discussion group for the book, Preface ix \\u2022 instructions on how to contact the authors with questions or comments, \\u2022 instructions on how to report errors in the book, in the likely event that some exist, and \\u2022 slides and other materials for instructors. About the cover The cover depicts the \\ufb01nal position from the decisive game 6 of the 1997 match between chess champion Garry Kasparov and program DEEP BLUE. Kasparov, playing Black, was forced to resign, making this the \\ufb01rst time a computer had beaten a world champion in a chess match. Kasparov is shown at the top. To his left is the Asimo humanoid robot and to his right is Thomas Bayes (1702\\u20131761), whose ideas about probability as a measure of belief underlie much of modern AI technology. Below that we see a Mars Exploration Rover, a robot that landed on Mars in 2004 and has been exploring the planet ever since. To the right is Alan Turing (1912\\u20131954), whose fundamental work de\\ufb01ned the \\ufb01elds of computer science in general and arti\\ufb01cial intelligence in particular. At the bottom is Shakey (1966\\u2013 1972), the \\ufb01rst robot to combine perception, world-modeling, planning, and learning. With Shakey is project leader Charles Rosen (1917\\u20132002). At the bottom right is Aristotle (384 B.C.\\u2013322 B.C.), who pioneered the study of logic; his work was state of the art until the 19th century (copy of a bust by Lysippos). At the bottom left, lightly screened behind the authors\\u2019 names, is a planning algorithm by Aristotle from De Motu Animalium in the original Greek. Behind the title is a portion of the CPSC Bayesian network for medical diagnosis (Pradhan et al., 1994). Behind the chess board is part of a Bayesian logic model for detecting nuclear explosions from seismic signals. Credits: Stan Honda/Getty (Kasparaov), Library of Congress (Bayes), NASA (Mars rover), National Museum of Rome (Aristotle), Peter Norvig (book), Ian Parker (Berkeley skyline), Shutterstock (Asimo, Chess pieces), Time Life/Getty (Shakey, Turing). Acknowledgments This book would not have been possible without the many contributors whose names did not make it to the cover. Jitendra Malik and David Forsyth wrote Chapter 24 (computer vision) and Sebastian Thrun wrote Chapter 25 (robotics). Vibhu Mittal wrote part of Chapter 22 (natural language). Nick Hay, Mehran Sahami, and Ernest Davis wrote some of the exercises. Zoran Duric (George Mason), Thomas C. Henderson (Utah), Leon Reznik (RIT), Michael Gourley (Central Oklahoma) and Ernest Davis (NYU) reviewed the manuscript and made helpful suggestions. We thank Ernie Davis in particular for his tireless ability to read multiple drafts and help improve the book. Nick Hay whipped the bibliography into shape and on deadline stayed up to 5:30 AM writing code to make the book better. Jon Barron formatted and improved the diagrams in this edition, while Tim Huang, Mark Paskin, and Cynthia Bruyns helped with diagrams and algorithms in previous editions. Ravi Mohan and Ciaran O\\u2019Reilly wrote and maintain the Java code examples on the Web site. John Canny wrote the robotics chapter for the \\ufb01rst edition and Douglas Edwards researched the historical notes. Tracy Dunkelberger, Allison Michael, Scott Disanno, and Jane Bonnell at Pearson tried their best to keep us on schedule and made many helpful suggestions. Most helpful of all has x Preface been Julie Sussman, P.P.A., who read every chapter and provided\"\n",
            "    },\n",
            "    {\n",
            "        \"Question\": \"Implement a basic decision-theoretic system using a programming language of your choice and demonstrate its application in a real-world scenario.\",\n",
            "        \"Type\": \"code\",\n",
            "        \"Difficulty\": \"hard\",\n",
            "        \"CLO\": \"Understand key components in the field of artificial intelligence\",\n",
            "        \"Topic\": [\n",
            "            \"Implement a basic decision-theoretic system using a programming language of your choice and demonstrate its application in a real-world scenario.\"\n",
            "        ],\n",
            "        \"text_chunk_ID\": 0,\n",
            "        \"text_chunk\": \"Arti\\ufb01cial Intelligence A Modern Approach Third Edition PRENTICE HALL SERIES IN ARTIFICIAL INTELLIGENCE Stuart Russell and Peter Norvig, Editors FORSYTH & PONCE Computer Vision: A Modern Approach GRAHAM ANSI Common Lisp JURAFSKY & MARTIN Speech and Language Processing, 2nd ed. NEAPOLITAN Learning Bayesian Networks RUSSELL & NORVIG Arti\\ufb01cial Intelligence: A Modern Approach, 3rd ed. Arti\\ufb01cial Intelligence A Modern Approach Third Edition Stuart J. Russell and Peter Norvig Contributing writers: Ernest Davis Douglas D. Edwards David Forsyth Nicholas J. Hay Jitendra M. Malik Vibhu Mittal Mehran Sahami Sebastian Thrun Upper Saddle River Boston Columbus San Francisco New York Indianapolis London Toronto Sydney Singapore Tokyo Montreal Dubai Madrid Hong Kong Mexico City Munich Paris Amsterdam Cape Town Vice President and Editorial Director, ECS: Marcia J. Horton Editor-in-Chief: Michael Hirsch Executive Editor: Tracy Dunkelberger Assistant Editor: Melinda Haggerty Editorial Assistant: Allison Michael Vice President, Production: Vince O\\u2019Brien Senior Managing Editor: Scott Disanno Production Editor: Jane Bonnell Senior Operations Supervisor: Alan Fischer Operations Specialist: Lisa McDowell Marketing Manager: Erin Davis Marketing Assistant: Mack Patterson Cover Designers: Kirsten Sims and Geoffrey Cassar Cover Images: Stan Honda/Getty, Library of Congress, NASA, National Museum of Rome, Peter Norvig, Ian Parker, Shutterstock, Time Life/Getty Interior Designers: Stuart Russell and Peter Norvig Copy Editor: Mary Lou Nohr Art Editor: Greg Dulles Media Editor: Daniel Sandin Media Project Manager: Danielle Leone Copyright c\\u20dd2010, 2003, 1995 by Pearson Education, Inc., Upper Saddle River, New Jersey 07458. All rights reserved. Manufactured in the United States of America. This publication is protected by Copyright and permissions should be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or likewise. To obtain permission(s) to use materials from this work, please submit a written request to Pearson Higher Education, Permissions Department, 1 Lake Street, Upper Saddle River, NJ 07458. The author and publisher of this book have used their best efforts in preparing this book. These efforts include the development, research, and testing of the theories and programs to determine their effectiveness. The author and publisher make no warranty of any kind, expressed or implied, with regard to these programs or the documentation contained in this book. The author and publisher shall not be liable in any event for incidental or consequential damages in connection with, or arising out of, the furnishing, performance, or use of these programs. Library of Congress Cataloging-in-Publication Data on File 10 9 8 7 6 5 4 3 2 1 ISBN-13: 978-0-13-604259-4 ISBN-10: 0-13-604259-7 For Loy, Gordon, Lucy, George, and Isaac \\u2014 S.J.R. For Kris, Isabella, and Juliet \\u2014 P.N. This page intentionally left blank Preface Arti\\ufb01cial Intelligence (AI) is a big \\ufb01eld, and this is a big book. We have tried to explore the full breadth of the \\ufb01eld, which encompasses logic, probability, and continuous mathematics; perception, reasoning, learning, and action; and everything from microelectronic devices to robotic planetary explorers. The book is also big because we go into some depth. The subtitle of this book is \\u201cA Modern Approach.\\u201d The intended meaning of this rather empty phrase is that we have tried to synthesize what is now known into a common frame- work, rather than trying to explain each sub\\ufb01eld of AI in its own historical context. We apologize to those whose sub\\ufb01elds are, as a result, less recognizable. New to this edition This edition captures the changes in AI that have taken place since the last edition in 2003. There have been important applications of AI technology, such as the widespread deploy- ment of practical speech recognition, machine translation, autonomous vehicles, and house- hold robotics. There have been algorithmic landmarks, such as the solution of the game of checkers. And there has been a great deal of theoretical progress, particularly in areas such as probabilistic reasoning, machine learning, and computer vision. Most important from our point of view is the continued evolution in how we think about the \\ufb01eld, and thus how we organize the book. The major changes are as follows: \\u2022 We place more emphasis on partially observable and nondeterministic environments, especially in the nonprobabilistic settings of search and planning. The concepts of belief state (a set of possible worlds) and state estimation (maintaining the belief state) are introduced in these settings; later in the book, we add probabilities. \\u2022 In addition to discussing the types of environments and types of agents, we now cover in more depth the types of representations that an agent can use. We distinguish among atomic representations (in which each state of the world is treated as a black box), factored representations (in which a state is a set of attribute/value pairs), and structured representations (in which the world consists of objects and relations between them). \\u2022 Our coverage of planning goes into more depth on contingent planning in partially observable environments and includes a new approach to hierarchical planning. \\u2022 We have added new material on \\ufb01rst-order probabilistic models, including open-universe models for cases where there is uncertainty as to what objects exist. \\u2022 We have completely rewritten the introductory machine-learning chapter, stressing a wider variety of more modern learning algorithms and placing them on a \\ufb01rmer theo- retical footing. \\u2022 We have expanded coverage of Web search and information extraction, and of tech- niques for learning from very large data sets. \\u2022 20% of the citations in this edition are to works published after 2003. \\u2022 We estimate that about 20% of the material is brand new. The remaining 80% re\\ufb02ects older work but has been largely rewritten to present a more uni\\ufb01ed picture of the \\ufb01eld. vii viii Preface Overview of the book The main unifying theme is the idea of an intelligent agent. We de\\ufb01ne AI as the study of agents that receive percepts from the environment and perform actions. Each such agent im- plements a function that maps percept sequences to actions, and we cover different ways to represent these functions, such as reactive agents, real-time planners, and decision-theoretic systems. We explain the role of learning as extending the reach of the designer into unknown environments, and we show how that role constrains agent design, favoring explicit knowl- edge representation and reasoning. We treat robotics and vision not as independently de\\ufb01ned problems, but as occurring in the service of achieving goals. We stress the importance of the task environment in determining the appropriate agent design. Our primary aim is to convey the ideas that have emerged over the past \\ufb01fty years of AI research and the past two millennia of related work. We have tried to avoid excessive formal- ity in the presentation of these ideas while retaining precision. We have included pseudocode algorithms to make the key ideas concrete; our pseudocode is described in Appendix B. This book is primarily intended for use in an undergraduate course or course sequence. The book has 27 chapters, each requiring about a week\\u2019s worth of lectures, so working through the whole book requires a two-semester sequence. A one-semester course can use selected chapters to suit the interests of the instructor and students. The book can also be used in a graduate-level course (perhaps with the addition of some of the primary sources suggested in the bibliographical notes). Sample syllabi are available at the book\\u2019s Web site, aima.cs.berkeley.edu. The only prerequisite is familiarity with basic concepts of computer science (algorithms, data structures, complexity) at a sophomore level. Freshman calculus and linear algebra are useful for some of the topics; the required mathematical back- ground is supplied in Appendix A. Exercises are given at the end of each chapter. Exercises requiring signi\\ufb01cant pro- gramming are marked with a keyboard icon. These exercises can best be solved by taking advantage of the code repository at aima.cs.berkeley.edu. Some of them are large enough to be considered term projects. A number of exercises require some investigation of the literature; these are marked with a book icon. Throughout the book, important points are marked with a pointing icon. We have in- cluded an extensive index of around 6,000 items to make it easy to \\ufb01nd things in the book. Wherever a new term is \\ufb01rst de\\ufb01ned, it is also marked in the margin. NEW TERM About the Web site aima.cs.berkeley.edu, the Web site for the book, contains \\u2022 implementations of the algorithms in the book in several programming languages, \\u2022 a list of over 1000 schools that have used the book, many with links to online course materials and syllabi, \\u2022 an annotated list of over 800 links to sites around the Web with useful AI content, \\u2022 a chapter-by-chapter list of supplementary material and links, \\u2022 instructions on how to join a discussion group for the book, Preface ix \\u2022 instructions on how to contact the authors with questions or comments, \\u2022 instructions on how to report errors in the book, in the likely event that some exist, and \\u2022 slides and other materials for instructors. About the cover The cover depicts the \\ufb01nal position from the decisive game 6 of the 1997 match between chess champion Garry Kasparov and program DEEP BLUE. Kasparov, playing Black, was forced to resign, making this the \\ufb01rst time a computer had beaten a world champion in a chess match. Kasparov is shown at the top. To his left is the Asimo humanoid robot and to his right is Thomas Bayes (1702\\u20131761), whose ideas about probability as a measure of belief underlie much of modern AI technology. Below that we see a Mars Exploration Rover, a robot that landed on Mars in 2004 and has been exploring the planet ever since. To the right is Alan Turing (1912\\u20131954), whose fundamental work de\\ufb01ned the \\ufb01elds of computer science in general and arti\\ufb01cial intelligence in particular. At the bottom is Shakey (1966\\u2013 1972), the \\ufb01rst robot to combine perception, world-modeling, planning, and learning. With Shakey is project leader Charles Rosen (1917\\u20132002). At the bottom right is Aristotle (384 B.C.\\u2013322 B.C.), who pioneered the study of logic; his work was state of the art until the 19th century (copy of a bust by Lysippos). At the bottom left, lightly screened behind the authors\\u2019 names, is a planning algorithm by Aristotle from De Motu Animalium in the original Greek. Behind the title is a portion of the CPSC Bayesian network for medical diagnosis (Pradhan et al., 1994). Behind the chess board is part of a Bayesian logic model for detecting nuclear explosions from seismic signals. Credits: Stan Honda/Getty (Kasparaov), Library of Congress (Bayes), NASA (Mars rover), National Museum of Rome (Aristotle), Peter Norvig (book), Ian Parker (Berkeley skyline), Shutterstock (Asimo, Chess pieces), Time Life/Getty (Shakey, Turing). Acknowledgments This book would not have been possible without the many contributors whose names did not make it to the cover. Jitendra Malik and David Forsyth wrote Chapter 24 (computer vision) and Sebastian Thrun wrote Chapter 25 (robotics). Vibhu Mittal wrote part of Chapter 22 (natural language). Nick Hay, Mehran Sahami, and Ernest Davis wrote some of the exercises. Zoran Duric (George Mason), Thomas C. Henderson (Utah), Leon Reznik (RIT), Michael Gourley (Central Oklahoma) and Ernest Davis (NYU) reviewed the manuscript and made helpful suggestions. We thank Ernie Davis in particular for his tireless ability to read multiple drafts and help improve the book. Nick Hay whipped the bibliography into shape and on deadline stayed up to 5:30 AM writing code to make the book better. Jon Barron formatted and improved the diagrams in this edition, while Tim Huang, Mark Paskin, and Cynthia Bruyns helped with diagrams and algorithms in previous editions. Ravi Mohan and Ciaran O\\u2019Reilly wrote and maintain the Java code examples on the Web site. John Canny wrote the robotics chapter for the \\ufb01rst edition and Douglas Edwards researched the historical notes. Tracy Dunkelberger, Allison Michael, Scott Disanno, and Jane Bonnell at Pearson tried their best to keep us on schedule and made many helpful suggestions. Most helpful of all has x Preface been Julie Sussman, P.P.A., who read every chapter and provided\"\n",
            "    },\n",
            "    {\n",
            "        \"Question\": \"Analyze the strengths and weaknesses of a real-world AI system, such as AlphaGo or DeepMind, and discuss recent trends in AI research.\",\n",
            "        \"Type\": \"subjective\",\n",
            "        \"Difficulty\": \"medium\",\n",
            "        \"CLO\": \"Understand key components in the field of artificial intelligence\",\n",
            "        \"Topic\": [\n",
            "            \"Discuss recent trends in AI and analyze case studies of AI systems to identify their strengths and weaknesses.\"\n",
            "        ],\n",
            "        \"text_chunk_ID\": 0,\n",
            "        \"text_chunk\": \"Arti\\ufb01cial Intelligence A Modern Approach Third Edition PRENTICE HALL SERIES IN ARTIFICIAL INTELLIGENCE Stuart Russell and Peter Norvig, Editors FORSYTH & PONCE Computer Vision: A Modern Approach GRAHAM ANSI Common Lisp JURAFSKY & MARTIN Speech and Language Processing, 2nd ed. NEAPOLITAN Learning Bayesian Networks RUSSELL & NORVIG Arti\\ufb01cial Intelligence: A Modern Approach, 3rd ed. Arti\\ufb01cial Intelligence A Modern Approach Third Edition Stuart J. Russell and Peter Norvig Contributing writers: Ernest Davis Douglas D. Edwards David Forsyth Nicholas J. Hay Jitendra M. Malik Vibhu Mittal Mehran Sahami Sebastian Thrun Upper Saddle River Boston Columbus San Francisco New York Indianapolis London Toronto Sydney Singapore Tokyo Montreal Dubai Madrid Hong Kong Mexico City Munich Paris Amsterdam Cape Town Vice President and Editorial Director, ECS: Marcia J. Horton Editor-in-Chief: Michael Hirsch Executive Editor: Tracy Dunkelberger Assistant Editor: Melinda Haggerty Editorial Assistant: Allison Michael Vice President, Production: Vince O\\u2019Brien Senior Managing Editor: Scott Disanno Production Editor: Jane Bonnell Senior Operations Supervisor: Alan Fischer Operations Specialist: Lisa McDowell Marketing Manager: Erin Davis Marketing Assistant: Mack Patterson Cover Designers: Kirsten Sims and Geoffrey Cassar Cover Images: Stan Honda/Getty, Library of Congress, NASA, National Museum of Rome, Peter Norvig, Ian Parker, Shutterstock, Time Life/Getty Interior Designers: Stuart Russell and Peter Norvig Copy Editor: Mary Lou Nohr Art Editor: Greg Dulles Media Editor: Daniel Sandin Media Project Manager: Danielle Leone Copyright c\\u20dd2010, 2003, 1995 by Pearson Education, Inc., Upper Saddle River, New Jersey 07458. All rights reserved. Manufactured in the United States of America. This publication is protected by Copyright and permissions should be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or likewise. To obtain permission(s) to use materials from this work, please submit a written request to Pearson Higher Education, Permissions Department, 1 Lake Street, Upper Saddle River, NJ 07458. The author and publisher of this book have used their best efforts in preparing this book. These efforts include the development, research, and testing of the theories and programs to determine their effectiveness. The author and publisher make no warranty of any kind, expressed or implied, with regard to these programs or the documentation contained in this book. The author and publisher shall not be liable in any event for incidental or consequential damages in connection with, or arising out of, the furnishing, performance, or use of these programs. Library of Congress Cataloging-in-Publication Data on File 10 9 8 7 6 5 4 3 2 1 ISBN-13: 978-0-13-604259-4 ISBN-10: 0-13-604259-7 For Loy, Gordon, Lucy, George, and Isaac \\u2014 S.J.R. For Kris, Isabella, and Juliet \\u2014 P.N. This page intentionally left blank Preface Arti\\ufb01cial Intelligence (AI) is a big \\ufb01eld, and this is a big book. We have tried to explore the full breadth of the \\ufb01eld, which encompasses logic, probability, and continuous mathematics; perception, reasoning, learning, and action; and everything from microelectronic devices to robotic planetary explorers. The book is also big because we go into some depth. The subtitle of this book is \\u201cA Modern Approach.\\u201d The intended meaning of this rather empty phrase is that we have tried to synthesize what is now known into a common frame- work, rather than trying to explain each sub\\ufb01eld of AI in its own historical context. We apologize to those whose sub\\ufb01elds are, as a result, less recognizable. New to this edition This edition captures the changes in AI that have taken place since the last edition in 2003. There have been important applications of AI technology, such as the widespread deploy- ment of practical speech recognition, machine translation, autonomous vehicles, and house- hold robotics. There have been algorithmic landmarks, such as the solution of the game of checkers. And there has been a great deal of theoretical progress, particularly in areas such as probabilistic reasoning, machine learning, and computer vision. Most important from our point of view is the continued evolution in how we think about the \\ufb01eld, and thus how we organize the book. The major changes are as follows: \\u2022 We place more emphasis on partially observable and nondeterministic environments, especially in the nonprobabilistic settings of search and planning. The concepts of belief state (a set of possible worlds) and state estimation (maintaining the belief state) are introduced in these settings; later in the book, we add probabilities. \\u2022 In addition to discussing the types of environments and types of agents, we now cover in more depth the types of representations that an agent can use. We distinguish among atomic representations (in which each state of the world is treated as a black box), factored representations (in which a state is a set of attribute/value pairs), and structured representations (in which the world consists of objects and relations between them). \\u2022 Our coverage of planning goes into more depth on contingent planning in partially observable environments and includes a new approach to hierarchical planning. \\u2022 We have added new material on \\ufb01rst-order probabilistic models, including open-universe models for cases where there is uncertainty as to what objects exist. \\u2022 We have completely rewritten the introductory machine-learning chapter, stressing a wider variety of more modern learning algorithms and placing them on a \\ufb01rmer theo- retical footing. \\u2022 We have expanded coverage of Web search and information extraction, and of tech- niques for learning from very large data sets. \\u2022 20% of the citations in this edition are to works published after 2003. \\u2022 We estimate that about 20% of the material is brand new. The remaining 80% re\\ufb02ects older work but has been largely rewritten to present a more uni\\ufb01ed picture of the \\ufb01eld. vii viii Preface Overview of the book The main unifying theme is the idea of an intelligent agent. We de\\ufb01ne AI as the study of agents that receive percepts from the environment and perform actions. Each such agent im- plements a function that maps percept sequences to actions, and we cover different ways to represent these functions, such as reactive agents, real-time planners, and decision-theoretic systems. We explain the role of learning as extending the reach of the designer into unknown environments, and we show how that role constrains agent design, favoring explicit knowl- edge representation and reasoning. We treat robotics and vision not as independently de\\ufb01ned problems, but as occurring in the service of achieving goals. We stress the importance of the task environment in determining the appropriate agent design. Our primary aim is to convey the ideas that have emerged over the past \\ufb01fty years of AI research and the past two millennia of related work. We have tried to avoid excessive formal- ity in the presentation of these ideas while retaining precision. We have included pseudocode algorithms to make the key ideas concrete; our pseudocode is described in Appendix B. This book is primarily intended for use in an undergraduate course or course sequence. The book has 27 chapters, each requiring about a week\\u2019s worth of lectures, so working through the whole book requires a two-semester sequence. A one-semester course can use selected chapters to suit the interests of the instructor and students. The book can also be used in a graduate-level course (perhaps with the addition of some of the primary sources suggested in the bibliographical notes). Sample syllabi are available at the book\\u2019s Web site, aima.cs.berkeley.edu. The only prerequisite is familiarity with basic concepts of computer science (algorithms, data structures, complexity) at a sophomore level. Freshman calculus and linear algebra are useful for some of the topics; the required mathematical back- ground is supplied in Appendix A. Exercises are given at the end of each chapter. Exercises requiring signi\\ufb01cant pro- gramming are marked with a keyboard icon. These exercises can best be solved by taking advantage of the code repository at aima.cs.berkeley.edu. Some of them are large enough to be considered term projects. A number of exercises require some investigation of the literature; these are marked with a book icon. Throughout the book, important points are marked with a pointing icon. We have in- cluded an extensive index of around 6,000 items to make it easy to \\ufb01nd things in the book. Wherever a new term is \\ufb01rst de\\ufb01ned, it is also marked in the margin. NEW TERM About the Web site aima.cs.berkeley.edu, the Web site for the book, contains \\u2022 implementations of the algorithms in the book in several programming languages, \\u2022 a list of over 1000 schools that have used the book, many with links to online course materials and syllabi, \\u2022 an annotated list of over 800 links to sites around the Web with useful AI content, \\u2022 a chapter-by-chapter list of supplementary material and links, \\u2022 instructions on how to join a discussion group for the book, Preface ix \\u2022 instructions on how to contact the authors with questions or comments, \\u2022 instructions on how to report errors in the book, in the likely event that some exist, and \\u2022 slides and other materials for instructors. About the cover The cover depicts the \\ufb01nal position from the decisive game 6 of the 1997 match between chess champion Garry Kasparov and program DEEP BLUE. Kasparov, playing Black, was forced to resign, making this the \\ufb01rst time a computer had beaten a world champion in a chess match. Kasparov is shown at the top. To his left is the Asimo humanoid robot and to his right is Thomas Bayes (1702\\u20131761), whose ideas about probability as a measure of belief underlie much of modern AI technology. Below that we see a Mars Exploration Rover, a robot that landed on Mars in 2004 and has been exploring the planet ever since. To the right is Alan Turing (1912\\u20131954), whose fundamental work de\\ufb01ned the \\ufb01elds of computer science in general and arti\\ufb01cial intelligence in particular. At the bottom is Shakey (1966\\u2013 1972), the \\ufb01rst robot to combine perception, world-modeling, planning, and learning. With Shakey is project leader Charles Rosen (1917\\u20132002). At the bottom right is Aristotle (384 B.C.\\u2013322 B.C.), who pioneered the study of logic; his work was state of the art until the 19th century (copy of a bust by Lysippos). At the bottom left, lightly screened behind the authors\\u2019 names, is a planning algorithm by Aristotle from De Motu Animalium in the original Greek. Behind the title is a portion of the CPSC Bayesian network for medical diagnosis (Pradhan et al., 1994). Behind the chess board is part of a Bayesian logic model for detecting nuclear explosions from seismic signals. Credits: Stan Honda/Getty (Kasparaov), Library of Congress (Bayes), NASA (Mars rover), National Museum of Rome (Aristotle), Peter Norvig (book), Ian Parker (Berkeley skyline), Shutterstock (Asimo, Chess pieces), Time Life/Getty (Shakey, Turing). Acknowledgments This book would not have been possible without the many contributors whose names did not make it to the cover. Jitendra Malik and David Forsyth wrote Chapter 24 (computer vision) and Sebastian Thrun wrote Chapter 25 (robotics). Vibhu Mittal wrote part of Chapter 22 (natural language). Nick Hay, Mehran Sahami, and Ernest Davis wrote some of the exercises. Zoran Duric (George Mason), Thomas C. Henderson (Utah), Leon Reznik (RIT), Michael Gourley (Central Oklahoma) and Ernest Davis (NYU) reviewed the manuscript and made helpful suggestions. We thank Ernie Davis in particular for his tireless ability to read multiple drafts and help improve the book. Nick Hay whipped the bibliography into shape and on deadline stayed up to 5:30 AM writing code to make the book better. Jon Barron formatted and improved the diagrams in this edition, while Tim Huang, Mark Paskin, and Cynthia Bruyns helped with diagrams and algorithms in previous editions. Ravi Mohan and Ciaran O\\u2019Reilly wrote and maintain the Java code examples on the Web site. John Canny wrote the robotics chapter for the \\ufb01rst edition and Douglas Edwards researched the historical notes. Tracy Dunkelberger, Allison Michael, Scott Disanno, and Jane Bonnell at Pearson tried their best to keep us on schedule and made many helpful suggestions. Most helpful of all has x Preface been Julie Sussman, P.P.A., who read every chapter and provided\"\n",
            "    },\n",
            "    {\n",
            "        \"Question\": \"Design and implement a simple expert system using a programming language of your choice and demonstrate its application in a real-world scenario.\",\n",
            "        \"Type\": \"code\",\n",
            "        \"Difficulty\": \"hard\",\n",
            "        \"CLO\": \"Understand key components in the field of artificial intelligence\",\n",
            "        \"Topic\": [\n",
            "            \"Design and implement a simple expert system using a programming language of your choice and demonstrate its application in a real-world scenario.\"\n",
            "        ],\n",
            "        \"text_chunk_ID\": 0,\n",
            "        \"text_chunk\": \"Arti\\ufb01cial Intelligence A Modern Approach Third Edition PRENTICE HALL SERIES IN ARTIFICIAL INTELLIGENCE Stuart Russell and Peter Norvig, Editors FORSYTH & PONCE Computer Vision: A Modern Approach GRAHAM ANSI Common Lisp JURAFSKY & MARTIN Speech and Language Processing, 2nd ed. NEAPOLITAN Learning Bayesian Networks RUSSELL & NORVIG Arti\\ufb01cial Intelligence: A Modern Approach, 3rd ed. Arti\\ufb01cial Intelligence A Modern Approach Third Edition Stuart J. Russell and Peter Norvig Contributing writers: Ernest Davis Douglas D. Edwards David Forsyth Nicholas J. Hay Jitendra M. Malik Vibhu Mittal Mehran Sahami Sebastian Thrun Upper Saddle River Boston Columbus San Francisco New York Indianapolis London Toronto Sydney Singapore Tokyo Montreal Dubai Madrid Hong Kong Mexico City Munich Paris Amsterdam Cape Town Vice President and Editorial Director, ECS: Marcia J. Horton Editor-in-Chief: Michael Hirsch Executive Editor: Tracy Dunkelberger Assistant Editor: Melinda Haggerty Editorial Assistant: Allison Michael Vice President, Production: Vince O\\u2019Brien Senior Managing Editor: Scott Disanno Production Editor: Jane Bonnell Senior Operations Supervisor: Alan Fischer Operations Specialist: Lisa McDowell Marketing Manager: Erin Davis Marketing Assistant: Mack Patterson Cover Designers: Kirsten Sims and Geoffrey Cassar Cover Images: Stan Honda/Getty, Library of Congress, NASA, National Museum of Rome, Peter Norvig, Ian Parker, Shutterstock, Time Life/Getty Interior Designers: Stuart Russell and Peter Norvig Copy Editor: Mary Lou Nohr Art Editor: Greg Dulles Media Editor: Daniel Sandin Media Project Manager: Danielle Leone Copyright c\\u20dd2010, 2003, 1995 by Pearson Education, Inc., Upper Saddle River, New Jersey 07458. All rights reserved. Manufactured in the United States of America. This publication is protected by Copyright and permissions should be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or likewise. To obtain permission(s) to use materials from this work, please submit a written request to Pearson Higher Education, Permissions Department, 1 Lake Street, Upper Saddle River, NJ 07458. The author and publisher of this book have used their best efforts in preparing this book. These efforts include the development, research, and testing of the theories and programs to determine their effectiveness. The author and publisher make no warranty of any kind, expressed or implied, with regard to these programs or the documentation contained in this book. The author and publisher shall not be liable in any event for incidental or consequential damages in connection with, or arising out of, the furnishing, performance, or use of these programs. Library of Congress Cataloging-in-Publication Data on File 10 9 8 7 6 5 4 3 2 1 ISBN-13: 978-0-13-604259-4 ISBN-10: 0-13-604259-7 For Loy, Gordon, Lucy, George, and Isaac \\u2014 S.J.R. For Kris, Isabella, and Juliet \\u2014 P.N. This page intentionally left blank Preface Arti\\ufb01cial Intelligence (AI) is a big \\ufb01eld, and this is a big book. We have tried to explore the full breadth of the \\ufb01eld, which encompasses logic, probability, and continuous mathematics; perception, reasoning, learning, and action; and everything from microelectronic devices to robotic planetary explorers. The book is also big because we go into some depth. The subtitle of this book is \\u201cA Modern Approach.\\u201d The intended meaning of this rather empty phrase is that we have tried to synthesize what is now known into a common frame- work, rather than trying to explain each sub\\ufb01eld of AI in its own historical context. We apologize to those whose sub\\ufb01elds are, as a result, less recognizable. New to this edition This edition captures the changes in AI that have taken place since the last edition in 2003. There have been important applications of AI technology, such as the widespread deploy- ment of practical speech recognition, machine translation, autonomous vehicles, and house- hold robotics. There have been algorithmic landmarks, such as the solution of the game of checkers. And there has been a great deal of theoretical progress, particularly in areas such as probabilistic reasoning, machine learning, and computer vision. Most important from our point of view is the continued evolution in how we think about the \\ufb01eld, and thus how we organize the book. The major changes are as follows: \\u2022 We place more emphasis on partially observable and nondeterministic environments, especially in the nonprobabilistic settings of search and planning. The concepts of belief state (a set of possible worlds) and state estimation (maintaining the belief state) are introduced in these settings; later in the book, we add probabilities. \\u2022 In addition to discussing the types of environments and types of agents, we now cover in more depth the types of representations that an agent can use. We distinguish among atomic representations (in which each state of the world is treated as a black box), factored representations (in which a state is a set of attribute/value pairs), and structured representations (in which the world consists of objects and relations between them). \\u2022 Our coverage of planning goes into more depth on contingent planning in partially observable environments and includes a new approach to hierarchical planning. \\u2022 We have added new material on \\ufb01rst-order probabilistic models, including open-universe models for cases where there is uncertainty as to what objects exist. \\u2022 We have completely rewritten the introductory machine-learning chapter, stressing a wider variety of more modern learning algorithms and placing them on a \\ufb01rmer theo- retical footing. \\u2022 We have expanded coverage of Web search and information extraction, and of tech- niques for learning from very large data sets. \\u2022 20% of the citations in this edition are to works published after 2003. \\u2022 We estimate that about 20% of the material is brand new. The remaining 80% re\\ufb02ects older work but has been largely rewritten to present a more uni\\ufb01ed picture of the \\ufb01eld. vii viii Preface Overview of the book The main unifying theme is the idea of an intelligent agent. We de\\ufb01ne AI as the study of agents that receive percepts from the environment and perform actions. Each such agent im- plements a function that maps percept sequences to actions, and we cover different ways to represent these functions, such as reactive agents, real-time planners, and decision-theoretic systems. We explain the role of learning as extending the reach of the designer into unknown environments, and we show how that role constrains agent design, favoring explicit knowl- edge representation and reasoning. We treat robotics and vision not as independently de\\ufb01ned problems, but as occurring in the service of achieving goals. We stress the importance of the task environment in determining the appropriate agent design. Our primary aim is to convey the ideas that have emerged over the past \\ufb01fty years of AI research and the past two millennia of related work. We have tried to avoid excessive formal- ity in the presentation of these ideas while retaining precision. We have included pseudocode algorithms to make the key ideas concrete; our pseudocode is described in Appendix B. This book is primarily intended for use in an undergraduate course or course sequence. The book has 27 chapters, each requiring about a week\\u2019s worth of lectures, so working through the whole book requires a two-semester sequence. A one-semester course can use selected chapters to suit the interests of the instructor and students. The book can also be used in a graduate-level course (perhaps with the addition of some of the primary sources suggested in the bibliographical notes). Sample syllabi are available at the book\\u2019s Web site, aima.cs.berkeley.edu. The only prerequisite is familiarity with basic concepts of computer science (algorithms, data structures, complexity) at a sophomore level. Freshman calculus and linear algebra are useful for some of the topics; the required mathematical back- ground is supplied in Appendix A. Exercises are given at the end of each chapter. Exercises requiring signi\\ufb01cant pro- gramming are marked with a keyboard icon. These exercises can best be solved by taking advantage of the code repository at aima.cs.berkeley.edu. Some of them are large enough to be considered term projects. A number of exercises require some investigation of the literature; these are marked with a book icon. Throughout the book, important points are marked with a pointing icon. We have in- cluded an extensive index of around 6,000 items to make it easy to \\ufb01nd things in the book. Wherever a new term is \\ufb01rst de\\ufb01ned, it is also marked in the margin. NEW TERM About the Web site aima.cs.berkeley.edu, the Web site for the book, contains \\u2022 implementations of the algorithms in the book in several programming languages, \\u2022 a list of over 1000 schools that have used the book, many with links to online course materials and syllabi, \\u2022 an annotated list of over 800 links to sites around the Web with useful AI content, \\u2022 a chapter-by-chapter list of supplementary material and links, \\u2022 instructions on how to join a discussion group for the book, Preface ix \\u2022 instructions on how to contact the authors with questions or comments, \\u2022 instructions on how to report errors in the book, in the likely event that some exist, and \\u2022 slides and other materials for instructors. About the cover The cover depicts the \\ufb01nal position from the decisive game 6 of the 1997 match between chess champion Garry Kasparov and program DEEP BLUE. Kasparov, playing Black, was forced to resign, making this the \\ufb01rst time a computer had beaten a world champion in a chess match. Kasparov is shown at the top. To his left is the Asimo humanoid robot and to his right is Thomas Bayes (1702\\u20131761), whose ideas about probability as a measure of belief underlie much of modern AI technology. Below that we see a Mars Exploration Rover, a robot that landed on Mars in 2004 and has been exploring the planet ever since. To the right is Alan Turing (1912\\u20131954), whose fundamental work de\\ufb01ned the \\ufb01elds of computer science in general and arti\\ufb01cial intelligence in particular. At the bottom is Shakey (1966\\u2013 1972), the \\ufb01rst robot to combine perception, world-modeling, planning, and learning. With Shakey is project leader Charles Rosen (1917\\u20132002). At the bottom right is Aristotle (384 B.C.\\u2013322 B.C.), who pioneered the study of logic; his work was state of the art until the 19th century (copy of a bust by Lysippos). At the bottom left, lightly screened behind the authors\\u2019 names, is a planning algorithm by Aristotle from De Motu Animalium in the original Greek. Behind the title is a portion of the CPSC Bayesian network for medical diagnosis (Pradhan et al., 1994). Behind the chess board is part of a Bayesian logic model for detecting nuclear explosions from seismic signals. Credits: Stan Honda/Getty (Kasparaov), Library of Congress (Bayes), NASA (Mars rover), National Museum of Rome (Aristotle), Peter Norvig (book), Ian Parker (Berkeley skyline), Shutterstock (Asimo, Chess pieces), Time Life/Getty (Shakey, Turing). Acknowledgments This book would not have been possible without the many contributors whose names did not make it to the cover. Jitendra Malik and David Forsyth wrote Chapter 24 (computer vision) and Sebastian Thrun wrote Chapter 25 (robotics). Vibhu Mittal wrote part of Chapter 22 (natural language). Nick Hay, Mehran Sahami, and Ernest Davis wrote some of the exercises. Zoran Duric (George Mason), Thomas C. Henderson (Utah), Leon Reznik (RIT), Michael Gourley (Central Oklahoma) and Ernest Davis (NYU) reviewed the manuscript and made helpful suggestions. We thank Ernie Davis in particular for his tireless ability to read multiple drafts and help improve the book. Nick Hay whipped the bibliography into shape and on deadline stayed up to 5:30 AM writing code to make the book better. Jon Barron formatted and improved the diagrams in this edition, while Tim Huang, Mark Paskin, and Cynthia Bruyns helped with diagrams and algorithms in previous editions. Ravi Mohan and Ciaran O\\u2019Reilly wrote and maintain the Java code examples on the Web site. John Canny wrote the robotics chapter for the \\ufb01rst edition and Douglas Edwards researched the historical notes. Tracy Dunkelberger, Allison Michael, Scott Disanno, and Jane Bonnell at Pearson tried their best to keep us on schedule and made many helpful suggestions. Most helpful of all has x Preface been Julie Sussman, P.P.A., who read every chapter and provided\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}